# MCMC Sampling using Hamiltonian Monte Carlo {#mcmc-config}

The `sample` method provides Bayesian inference over the model conditioned on data
using Hamiltonian Monte Carlo (HMC) sampling.  By default, the inference engine used is
the No-U-Turn sampler (NUTS), an adaptive form of Hamiltonian Monte Carlo sampling.
For details on HMC and NUTS, see the Stan Reference Manual chapter on
[MCMC Sampling](https://mc-stan.org/docs/reference-manual/hmc-chapter.html).

The full set of configuration options available for the `sample` method is
reported at the beginning of the sampler output file as csv comments.
When the example model `bernoulli.stan` is run via the command line
with all default arguments,
the resulting Stan csv file header comments show the complete set
of default configuration options:
```
# model = bernoulli_model
# method = sample (Default)
#   sample
#     num_samples = 1000 (Default)
#     num_warmup = 1000 (Default)
#     save_warmup = 0 (Default)
#     thin = 1 (Default)
#     adapt
#       engaged = 1 (Default)
#       gamma = 0.05 (Default)
#       delta = 0.8 (Default)
#       kappa = 0.75 (Default)
#       t0 = 10 (Default)
#       init_buffer = 75 (Default)
#       term_buffer = 50 (Default)
#       window = 25 (Default)
#     algorithm = hmc (Default)
#       hmc
#         engine = nuts (Default)
#           nuts
#             max_depth = 10 (Default)
#         metric = diag_e (Default)
#         metric_file =  (Default)
#         stepsize = 1 (Default)
#         stepsize_jitter = 0 (Default)
```

## Iterations

At every sampler iteration, the sampler returns a set of estimates
for all parameters and quantities of interest in the model.
During warmup, the NUTS algorithm adjusts the HMC algorithm parameters
`metric` and `stepsize` in order to efficiently sample from
_typical set_, the neighborhood substantial posterior probability mass
through which the Markov chain will travel in equilibrium.
After warmup, the fixed metric and stepsize are used to produce
a set of draws.

The following keyword-value arguments control the total number of iterations and
the number of draws written to the output file:

- `num_samples`
- `num_warmup`
- `save_warmup`
- `thin`

## Adaptation

The `adapt` keyword is used to specify non-default options for
the sampler adaptation schedule and settings.

Adaptation can be turned off by setting sub-argument `engaged` to value $0$.
If `engaged=0`, no adaptation will be done, and all other adaptation sub-arguments will be ignored.
Since the default argument is `engaged=1`, this keyword-value pair can be omitted from the command.

There are two sets of adaptation sub-arguments: step size optimization parameters and the warmup schedule.
These are described in detail in the Reference Manual section
[Automatic Parameter Tuning](https://mc-stan.org/docs/2_23/reference-manual/hmc-algorithm-parameters.html).

### step size optimization configuration

The following keyword-value arguments control the settings used to optimize the step size:

- `delta`  - The target Metropolis acceptance rate. The default value is $0.8$.
Its value must be strictly between $0$ and $1$.  Increasing the default value
forces the algorithm to use smaller step sizes. This can
improve sampling efficiency (effective sample size per iteration) at
the cost of increased iteration times. Raising the value of `delta`
will also allow some models that would otherwise get stuck to overcome
their blockages.  

- `gamma` - Adaptation regularization scale.
Must be a positive real number, default value is $0.05$. 
This is a parameter of the Nesterov dual-averaging algorithm.
We recommend always using the default value.

- `gamma` - Adaptation relaxation exponent.
Must be a positive real number, default value is $0.75$. 
This is a parameter of the Nesterov dual-averaging algorithm.
We recommend always using the default value.

- `t_0` - Adaptation iteration offset.
Must be a positive real number, default value is $10$. 
This is a parameter of the Nesterov dual-averaging algorithm.
We recommend always using the default value.


### Warmup schedule configuration

When adaptation is engaged, the warmup schedule is specified by sub-arguments,
all of which take positive integers as values:

- `init_buffer` - The number of iterations spent tuning the step size at the outset of adaptation.
- `window` - The initial number of iterations devoted to tune the metric, will be doubled successively.
- `term_buffer` - The number of iterations used to re-tune the step size once the metric has been tuned.

The specified values may be modified slightly in order to ensure alignment
between the warmup schedule and total number of warmup iterations.

The following figure is taken from the Stan Reference Manual,
where label "I" correspond to `init_buffer`, the initial "II" corresponds to `window`,
and the final "III" corresponds to `term_buffer`:

**Warmup Epochs Figure.** <a id="adaptation.figure"></a>
*Adaptation during warmup occurs in three stages: an initial fast
adaptation interval (I), a series of expanding slow adaptation
intervals (II), and a final fast adaptation interval (III). For HMC,
both the fast and slow intervals are used for adapting the step size,
while the slow intervals are used for learning the (co)variance
necessitated by the metric. Iteration numbering starts at 1 on the
left side of the figure and increases to the right.*

![](img/warmup-epochs.png)


## Algorithm

The `algorithm` keyword-value pair specifies the algorithm used to generate the sample.
There are two possible values:  `hmc`, which generates from an HMC-driven Markov chain;
and `fixed_param` which generates a new sample without changing the state of the Markov chain.
The default argument is `algorithm=hmc`.

If a model doesn't specify any parameters, as is the case for models which generate pseudo-data
via the transformed data and generated quantities blocks, then argument `algorithm=fixed_param`
is mandatory.

### HMC sampler engines

All HMC algorithms have three parameters:

- step size
- metric
- integration time - the number of steps taken along the Hamiltonian trajectory

See the Stan Reference Manual section on
[HMC algorithm parameters](https://mc-stan.org/docs/reference-manual/hmc-algorithm-parameters.html)
for further details.

CmdStan provides two HMC algorithm implementations, which are specified by keyword `engine` with
possible values:

- `nuts` - the No-U-Turn Sampler which dynamically determines the optimal integration time.
- `static` - an HMC sampler which uses a user-specified integration time.

The default argument is `engine=nuts`.
It takes one sub-argument, keyword `max_depth which takes a positive integer value.
The default argument is `max_depth=10`.

The NUTS sampler generates a proposal by starting at an initial position determined
by the parameters drawn in the last iteration. It then evolves the initial system both
forwards and backwards in time to form a balanced binary tree. The algorithm is iterative;
at each iteration the tree depth is increased by one, doubling the number of leapfrog steps
thus effectively doubling the computation time. 
The algorithm terminates in one of two ways: either
the NUTS criterion (i.e., a U-turn in Euclidean space on a subtree)
is satisfied for a new subtree or the completed tree;
or the depth of the completed tree hits the maximum depth allowed.

In the case where a model has a difficult posterior from which to sample,
`max_depth` should be increased to ensure that that the NUTS tree can grow as large as necessary.

When the argument `engine=static` is specified, 
the user must specify the integration time via keyword `int_time`
which takes as a value a positive number.
The default value is $2\pi$.

## Sampler Diagnostic File

The `output` keyword sub-argument `diagnostic_file=<filepath>`
specifies the location of the auxiliary output file which contains sampler information for each draw,
including the gradients on the unconstrained scale and log probabilities.
By default, no auxiliary output file is produced.

## Examples

The Quickstart Guide [MCMC Sampling chapter](#mcmc-intro) section on multiple chains
showed how to run multiple chains given a model and data, using the minimal required
command line options: the method, the name of the data file, and a chain-specific name for the output file.

To run 4 chains in parallel on Mac OS and Linux, the syntax in both bash and zsh is the same:
```
> for i in {1..4}
    do
      ./bernoulli sample data file=my_model.data.json \
                  output file=output_${i}.csv &
    done
```
The backslash (`\`) indicates a line continuation in Unix.
The expression `${i}` substitutes in the value of loop index variable `i`.
The ampersand (`&`) pushes each process into the background which allows the loop to continue
without waiting for the current chain to finish. 

On Windows the corresponding loop is:
```
>for /l %i in (1, 1, 4) do start /b bernoulli.exe sample ^
                                    data file=my_model.data.json my_data ^
                                    output file=output_%i.csv
```
The caret (`^`) indicates a line continuation in DOS.
The expression `%i` is the loop index.

In the following examples, we focus on just the nested sampler command for Unix.

### Running multiple chains with a specified RNG seed

For reproducibility, we specify the same RNG seed across all chains and use
the chain id argument to specify the RNG offset.

The RNG seed is specified by `random seed=<int>` and the offset is specified
by `id=<loop index>`, so the call to the sampler is:
```
./my_model sample data file=my_model.data.json \
            output file=output_${i}.csv \
            random seed=12345 id=${i}
```

### Changing the default warmup and sampling iterations

The number of warmup and sampling iterations are both set to default $1000$.
For well-specified models and data, the sampler may converge faster and this many
warmup iterations may be overkill.  Conversely, complex models which have difficult
posterior geometries may require more warmup iterations in order to arrive at good
values for the step size and metric.

The number of sampling iterations to runs depends on the effective sample size (EFF)
reported for each parameter and the desired precision of your estimates.
An EFF of at least 100 is required to make a viable estimate.  The precision of your
estimate is $\sqrt{N}; therefore every additional decimal place of accuracy increases
this by a factor of 10.

The warmup and sampling iteration keyword-value arguments must follow the `sample` keyword.
The call to the sampler which overrides the default warmup and sampling iterations is:

```
./my_model sample num_warmup=500 num_sampling=500 \
            data file=my_model.data.json \
            output file=output_${i}.csv
```

### Saving warmup draws

By default, warmup draws are not saved to the output file.
To override this, use the keyword-value argument `save_warmup=1`,
which must also be grouped with the other `sample` keyword sub-arguments.

```
./my_model sample num_warmup=500 num_sampling=500 save_warmup=1 \
            data file=my_model.data.json \
            output file=output_${i}.csv
```

### Initializing parameters

By default, all parameters are initialized to random draws from a uniform distribution over the range $[-2, 2]$.
To initialize some or all parameters to good starting points on the constrained scale from
a data file in JSON or Rdump format, use the keyword-value argument `init=<filepath>`:
```
./my_model sample init=my_param.inits.json data file=my_model.data.json \
            output file=output_${i}.csv
```

### Specifying the metric and stepsize

- as starting point for warmup

- instead of adaptation during warmup

- note on initialization


### Changing the NUTS-HMC adaptation parameters

The Stan User's Guide section on
[model conditioning and curvature](https://mc-stan.org/docs/stan-users-guide/model-conditioning-and-curvature.html)
provides a discussion of adaptation and stepsize issues.
The Stan Reference Manual section on
[HMC algorithm parameters](https://mc-stan.org/docs/reference-manual/hmc-algorithm-parameters.html)
explains the NUTS-HMC adaptation schedule and the tuning parameters for setting the step size.
The keyword-value arguments for these settings are grouped together under the `adapt` keyword
which itself is a sub-argument of the `sample` keyword.

Models with difficult posterior geometries may required increasing the `delta` argument
closer to $1$.

```
./my_model sample adapt delta=0.95 \
            data file=my_model.data.json \
            output file=output_${i}.csv
```

To skip adaptation altogether, use the keyword-value argument `engaged=0`.
Disabling adaptation disables both metric and stepsize adaptation, so a stepsize should be
provided along with a metric to enable efficient sampling.
Even with adaptation disabled, it is still advisable to run warmup iterations in order to reach the typical set.
To skip warmup altogether requires specifying both `num_warmup=0` and `adapt engaged=0`.
```
../my_model sample num_warmup=0 adapt engaged=0 \
            data file=my_model.data.json \
            output file=output_${i}.csv
```

### Increasing the tree-depth

Models with difficult posterior geometries may required increasing the `max_depth` argument from its default value $10$.
This requires specifying a series of keyword-argument pairs:

```
./my_model sample adapt delta=0.95 \
            algorithm=hmc engine=nuts max_depth=15 \
            data file=my_model.data.json \
            output file=output_${i}.csv
```

### Capturing Hamiltonian diagnostics

To get the gradients of all model parameters for each draw,
specify the `diagnostic_file=<filepath>` as part of the `output` arguments:
```
./my_model sample data file=my_model.data.json \
            output file=output_${i}.csv \
            diagnostic_file=diagnostics_${i}.csv
```

### Suppressing progress updates to the console

The keyword value pair `refresh=<int>` specifies the 
number of iterations between progress messages written to the terminal window.
The default value is 100 iterations.
The progress updates look like:
```
Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:  100 / 2000 [  5%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  300 / 2000 [ 15%]  (Warmup)
```

For simple models which fit quickly, such updates can be annoying;
to suppress them altogether, set `refresh=0`.
This turns off the `Iteration: ` messages; the configuration
and timing information are still written to the terminal.

For complicated models which take a long time to fit, setting
the refresh rate to a low number, e.g. 10 or even 1, provides a
way to more closely monitor the sampler.

```


