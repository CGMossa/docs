<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics Using Stan</title>
  <meta name="description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics Using Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics Using Stan" />
  
  <meta name="twitter:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="stan-for-bugs-appendix.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Bayesian Statistics with Stan</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="part-1-overview.html#part-1-overview"><i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Part 1: Overview</i></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="prior-distributions-and-models-for-data.html"><a href="prior-distributions-and-models-for-data.html"><i class="fa fa-check"></i><b>2</b> Prior Distributions and Models for Data</a></li>
<li class="chapter" data-level="3" data-path="simple-examples.html"><a href="simple-examples.html"><i class="fa fa-check"></i><b>3</b> Simple Examples</a></li>
<li class="chapter" data-level="4" data-path="bayesian-workflow-1.html"><a href="bayesian-workflow-1.html"><i class="fa fa-check"></i><b>4</b> Bayesian Workflow</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 2. Example Models</i></span></a></li>
<li class="chapter" data-level="5" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>5</b> Regression Models</a></li>
<li class="chapter" data-level="6" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>6</b> Time-Series Models</a></li>
<li class="chapter" data-level="7" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>7</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="8" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>8</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="9" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>9</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="10" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>10</b> Finite Mixtures</a></li>
<li class="chapter" data-level="11" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>11</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="12" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>12</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="13" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>13</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="14" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>14</b> Clustering Models</a></li>
<li class="chapter" data-level="15" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>15</b> Gaussian Processes</a></li>
<li class="chapter" data-level="16" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>16</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="17" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>17</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="18" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>18</b> Ordinary Differential Equations</a></li>
<li><a href="part-3-programming-techniques.html#part-3.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 3. Programming Techniques</i></a></li>
<li class="chapter" data-level="19" data-path="modeling-as-software-development.html"><a href="modeling-as-software-development.html"><i class="fa fa-check"></i><b>19</b> Modeling as Software Development</a></li>
<li class="chapter" data-level="20" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>20</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="21" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>21</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="22" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>22</b> User-Defined Functions</a></li>
<li class="chapter" data-level="23" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>23</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="24" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>24</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="25" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>25</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="26" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>26</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="27" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>27</b> Map-Reduce</a></li>
<li><a href="part-4-review-of-statistical-inference.html#part-4-review-of-statistical-inference"><i style="font-size: 110%; color:#990017;">Part 4: Review of Statistical Inference</i></a></li>
<li class="chapter" data-level="28" data-path="bayesian-data-analysis-1.html"><a href="bayesian-data-analysis-1.html"><i class="fa fa-check"></i><b>28</b> Bayesian Data Analysis</a></li>
<li class="chapter" data-level="29" data-path="mle-chapter.html"><a href="mle-chapter.html"><i class="fa fa-check"></i><b>29</b> Penalized Maximum Likelihood Point Estimation</a></li>
<li class="chapter" data-level="30" data-path="bayesian-point-estimation.html"><a href="bayesian-point-estimation.html"><i class="fa fa-check"></i><b>30</b> Bayesian Point Estimation</a></li>
<li class="chapter" data-level="31" data-path="vi-advanced-chapter.html"><a href="vi-advanced-chapter.html"><i class="fa fa-check"></i><b>31</b> Variational Inference</a></li>
<li><a href="appendices.html#appendices"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="" data-path="appendix-1-stan-program-style-guide.html"><a href="appendix-1-stan-program-style-guide.html"><i class="fa fa-check"></i>Appendix 1. Stan Program Style Guide</a></li>
<li class="chapter" data-level="" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i>Appendix 2. Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics Using Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1><i style="font-size: 110%; color:#990017;">References</i></h1>

<div id="refs" class="references">
<div>
<p>Aguilar, Omar, and Mike West. 2000. “Bayesian Dynamic Factor Models and Portfolio Allocation.” <em>Journal of Business &amp; Economic Statistics</em> 18 (3). Taylor &amp; Francis: 338–57.</p>
</div>
<div>
<p>Ahnert, Karsten, and Mario Mulansky. 2011. “Odeint—Solving Ordinary Differential Equations in C++.” <em>arXiv</em> 1110.3397.</p>
</div>
<div>
<p>Albert, J. H., and S. Chib. 1993. “Bayesian Analysis of Binary and Polychotomous Response Data.” <em>Journal of the American Statistical Association</em> 88: 669–79.</p>
</div>
<div>
<p>Barnard, John, Robert McCulloch, and Xiao-Li Meng. 2000. “Modeling Covariance Matrices in Terms of Standard Deviations and Correlations, with Application to Shrinkage.” <em>Statistica Sinica</em>, 1281–1311.</p>
</div>
<div>
<p>Betancourt, Michael. 2012. “A General Metric for Riemannian Manifold Hamiltonian Monte Carlo.” <em>arXiv</em> 1212.4693. <a href="http://arxiv.org/abs/1212.4693" class="uri">http://arxiv.org/abs/1212.4693</a>.</p>
</div>
<div>
<p>Betancourt, Michael, and Mark Girolami. 2013. “Hamiltonian Monte Carlo for Hierarchical Models.” <em>arXiv</em> 1312.0906. <a href="http://arxiv.org/abs/1312.0906" class="uri">http://arxiv.org/abs/1312.0906</a>.</p>
</div>
<div>
<p>Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. Springer New York.</p>
</div>
<div>
<p>Blei, David M., and John D. Lafferty. 2007. “A Correlated Topic Model of <em>Science</em>.” <em>The Annals of Applied Statistics</em> 1 (1): 17–37.</p>
</div>
<div>
<p>Blei, David M., Andrew Y. Ng, and Michael I. Jordan. 2003. “Latent Dirichlet Allocation.” <em>Journal of Machine Learning Research</em> 3: 993–1022.</p>
</div>
<div>
<p>Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and Jingchen Liu. 2013. “A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models.” <em>Psychometrika</em> 78 (4): 685–709.</p>
</div>
<div>
<p>Clayton, D. G. 1992. “Models for the Analysis of Cohort and Case-Control Studies with Inaccurately Measured Exposures.” In <em>Statistical Models for Longitudinal Studies of Exposure and Health</em>, edited by James H. Dwyer, Manning Feinleib, Peter Lippert, and Hans Hoffmeister, 301–31. New York: Oxford University Press.</p>
</div>
<div>
<p>Cohen, Scott D, and Alan C Hindmarsh. 1996. “CVODE, a Stiff/Nonstiff ODE Solver in C.” <em>Computers in Physics</em> 10 (2): 138–43.</p>
</div>
<div>
<p>Cook, Samantha R., Andrew Gelman, and Donald B Rubin. 2006. “Validation of Software for Bayesian Models Using Posterior Quantiles.” <em>Journal of Computational and Graphical Statistics</em> 15 (3): 675–92. <a href="https://doi.org/10.1198/106186006X136976" class="uri">https://doi.org/10.1198/106186006X136976</a>.</p>
</div>
<div>
<p>Cormack, R. M. 1964. “Estimates of Survival from the Sighting of Marked Animals.” <em>Biometrika</em> 51 (3/4): 429–38.</p>
</div>
<div>
<p>Curtis, S. McKay. 2010. “BUGS Code for Item Response Theory.” <em>Journal of Statistical Software</em> 36 (1). American Statistical Association: 1–34.</p>
</div>
<div>
<p>Dawid, A. P., and A. M. Skene. 1979. “Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm.” <em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em> 28 (1): 20–28.</p>
</div>
<div>
<p>Dempster, A. P., N. M. Laird, and D. B. Rubin. 1977. “Maximum Likelihood from Incomplete Data via the EM Algorithm.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 39 (1): 1–38.</p>
</div>
<div>
<p>Dormand, John R, and Peter J Prince. 1980. “A Family of Embedded Runge-Kutta Formulae.” <em>Journal of Computational and Applied Mathematics</em> 6 (1): 19–26.</p>
</div>
<div>
<p>Efron, B., and C. Morris. 1975. “Data Analysis Using Stein’s Estimator and Its Generalizations.” <em>Journal of the American Statistical Association</em> 70: 311–19.</p>
</div>
<div>
<p>Efron, Bradley. 2012. <em>Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction</em>. Institute of Mathematical Statistics Monographs. Cambridge Univesity Press.</p>
</div>
<div>
<p>Engle, Robert F. 1982. “Autoregressive Conditional Heteroscedasticity with Estimates of Variance of United Kingdom Inflation.” <em>Econometrica</em> 50: 987–1008.</p>
</div>
<div>
<p>Fonnesbeck, Chris, Anand Patil, David Huard, and John Salvatier. 2013. <em>PyMC User’s Guide</em>.</p>
</div>
<div>
<p>Gelman, A. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models.” <em>Bayesian Analysis</em> 1 (3): 515–34.</p>
</div>
<div>
<p>Gelman, Andrew. 2004. “Parameterization and Bayesian Modeling.” <em>Journal of the American Statistical Association</em> 99: 537–45.</p>
</div>
<div>
<p>Gelman, Andrew, J. B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third. London: Chapman &amp;Hall/CRC Press.</p>
</div>
<div>
<p>Gelman, Andrew, and Jennifer Hill. 2007. <em>Data Analysis Using Regression and Multilevel-Hierarchical Models</em>. Cambridge, United Kingdom: Cambridge University Press.</p>
</div>
<div>
<p>Gelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” <em>Annals of Applied Statistics</em> 2 (4): 1360–83.</p>
</div>
<div>
<p>Girolami, Mark, and Ben Calderhead. 2011. “Riemann Manifold Langevin and Hamiltonian Monte Carlo Methods.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 73 (2): 123–214.</p>
</div>
<div>
<p>Greene, William H. 2011. <em>Econometric Analysis</em>. 7th ed. Prentice-Hall.</p>
</div>
<div>
<p>Hoerl, Arthur E., and Robert W. Kennard. 1970. “Ridge Regression: Biased Estimation for Nonorthogonal Problems.” <em>Technometrics</em> 12 (1): 55–67.</p>
</div>
<div>
<p>Hoeting, Jennifer A., David Madigan, Adrian E Raftery, and Chris T. Volinsky. 1999. “Bayesian Model Averaging: A Tutorial.” <em>Statistical Science</em> 14 (4): 382–417.</p>
</div>
<div>
<p>Hoffman, Matthew D., and Andrew Gelman. 2011. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” <em>arXiv</em> 1111.4246. <a href="http://arxiv.org/abs/1111.4246" class="uri">http://arxiv.org/abs/1111.4246</a>.</p>
</div>
<div>
<p>———. 2014. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” <em>Journal of Machine Learning Research</em> 15: 1593–1623. <a href="http://jmlr.org/papers/v15/hoffman14a.html" class="uri">http://jmlr.org/papers/v15/hoffman14a.html</a>.</p>
</div>
<div>
<p>Hunt, Andrew, and David Thomas. 1999. <em>The Pragmatic Programmer</em>. Addison-Wesley.</p>
</div>
<div>
<p>James, W., and Charles Stein. 1961. “Estimation with Quadratic Loss.” In <em>Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability</em>, edited by Jerzey Neyman, 1:361–79. University of California Press.</p>
</div>
<div>
<p>Jarrett, R. G. 1979. “A Note on the Intervals Between Coal-Mining Disasters.” <em>Biometrika</em> 66 (1). Biometrika Trust: 191–93.</p>
</div>
<div>
<p>Jordan, Michael I, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. 1999. “An Introduction to Variational Methods for Graphical Models.” <em>Machine Learning</em> 37 (2). Springer: 183–233.</p>
</div>
<div>
<p>Kim, Sangjoon, Neil Shephard, and Siddhartha Chib. 1998. “Stochastic Volatility: Likelihood Inference and Comparison with ARCH Models.” <em>Review of Economic Studies</em> 65: 361–93.</p>
</div>
<div>
<p>Kucukelbir, Alp, Rajesh Ranganath, Andrew Gelman, and David M. Blei. 2015. “Automatic Variational Inference in Stan.” <em>arXiv</em> 1506.03431. <a href="http://arxiv.org/abs/1506.03431" class="uri">http://arxiv.org/abs/1506.03431</a>.</p>
</div>
<div>
<p>Lambert, Diane. 1992. “Zero-Inflated Poisson Regression, with an Application to Defects in Manufacturing.” <em>Technometrics</em> 34 (1).</p>
</div>
<div>
<p>Langford, John, Lihong Li, and Tong Zhang. 2009. “Sparse Online Learning via Truncated Gradient.” <em>Journal of Machine Learning Research</em> 10: 777–801.</p>
</div>
<div>
<p>Lewandowski, Daniel, Dorota Kurowicka, and Harry Joe. 2009. “Generating Random Correlation Matrices Based on Vines and Extended Onion Method.” <em>Journal of Multivariate Analysis</em> 100: 1989–2001.</p>
</div>
<div>
<p>Lincoln, F. C. 1930. “Calculating Waterfowl Abundance on the Basis of Banding Returns.” <em>United States Department of Agriculture Circular</em> 118: 1–4.</p>
</div>
<div>
<p>Lunn, David, Christopher Jackson, Nicky Best, Andrew Thomas, and David Spiegelhalter. 2012. <em>The BUGS Book: A Practical Introduction to Bayesian Analysis</em>. CRC Press/Chapman &amp; Hall.</p>
</div>
<div>
<p>Marsaglia, George. 1972. “Choosing a Point from the Surface of a Sphere.” <em>The Annals of Mathematical Statistics</em> 43 (2): 645–46.</p>
</div>
<div>
<p>McConnell, Steve. 2004. <em>Code Complete: A Practical Handbook of Software Construction</em>. Second. Microsoft Press.</p>
</div>
<div>
<p>Neal, Radford M. 1996a. <em>Bayesian Learning for Neural Networks</em>. Lecture Notes in Statistics 118. New York: Springer.</p>
</div>
<div>
<p>———. 1996b. “Sampling from Multimodal Distributions Using Tempered Transitions.” <em>Statistics and Computing</em> 6 (4): 353–66.</p>
</div>
<div>
<p>———. 1997. “Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification.” 9702. University of Toronto, Department of Statistics.</p>
</div>
<div>
<p>———. 2003. “Slice Sampling.” <em>Annals of Statistics</em> 31 (3): 705–67.</p>
</div>
<div>
<p>Papaspiliopoulos, Omiros, Gareth O. Roberts, and Martin Sköld. 2007. “A General Framework for the Parametrization of Hierarchical Models.” <em>Statistical Science</em> 22 (1): 59–73.</p>
</div>
<div>
<p>Petersen, C. G. J. 1896. “The Yearly Immigration of Young Plaice into the Limfjord from the German Sea.” <em>Report of the Danish Biological Station</em> 6: 5–84.</p>
</div>
<div>
<p>Piironen, Juho, and Aki Vehtari. 2016. “Projection Predictive Model Selection for Gaussian Processes.” In <em>Machine Learning for Signal Processing (Mlsp), 2016 Ieee 26th International Workshop on</em>. IEEE.</p>
</div>
<div>
<p>Powell, Michael J. D. 1970. “A Hybrid Method for Nonlinear Equations.” In <em>Numerical Methods for Nonlinear Algebraic Equations</em>, edited by P. Rabinowitz. Gordon; Breach.</p>
</div>
<div>
<p>Rasmussen, Carl Edward, and Christopher K. I. Williams. 2006. <em>Gaussian Processes for Machine Learning</em>. MIT Press.</p>
</div>
<div>
<p>Richardson, Sylvia, and Walter R. Gilks. 1993. “A Bayesian Approach to Measurement Error Problems in Epidemiology Using Conditional Independence Models.” <em>American Journal of Epidemiology</em> 138 (6): 430–42.</p>
</div>
<div>
<p>Rubin, Donald B. 1981. “Estimation in Parallel Randomized Experiments.” <em>Journal of Educational Statistics</em> 6: 377–401.</p>
</div>
<div>
<p>Schofield, Matthew R. 2007. “Hierarchical Capture-Recapture Models.” PhD thesis, Department of of Statistics, University of Otago, Dunedin.</p>
</div>
<div>
<p>Serban, Radu, and Alan C Hindmarsh. 2005. “CVODES: The Sensitivity-Enabled ODE Solver in SUNDIALS.” In <em>ASME 2005 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference</em>, 257–69. American Society of Mechanical Engineers.</p>
</div>
<div>
<p>Smith, Teresa C., David J. Spiegelhalter, and Andrew Thomas. 1995. “Bayesian Approaches to Random-Effects Meta-Analysis: A Comparative Study.” <em>Statistics in Medicine</em> 14 (24): 2685–99.</p>
</div>
<div>
<p>Swendsen, Robert H., and Jian-Sheng Wang. 1986. “Replica Monte Carlo Simulation of Spin Glasses.” <em>Physical Review Letters</em> 57: 2607–9.</p>
</div>
<div>
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society, Series B</em> 58 (1): 267–88.</p>
</div>
<div>
<p>Wainwright, Martin J, and Michael I Jordan. 2008. “Graphical Models, Exponential Families, and Variational Inference.” <em>Foundations and Trends in Machine Learning</em> 1 (1-2): 1–305.</p>
</div>
<div>
<p>Warn, David E., S. G. Thompson, and David J. Spiegelhalter. 2002. “Bayesian Random Effects Meta-Analysis of Trials with Binary Outcomes: Methods for the Absolute Risk Difference and Relative Risk Scales.” <em>Statistics in Medicine</em> 21: 1601–23.</p>
</div>
<div>
<p>Zellner, Arnold. 1962. “An Efficient Method of Estimating Seemingly Unrelated Regression Equations and Tests for Aggregation Bias.” <em>Journal of the American Statistical Association</em> 57: 348–68.</p>
</div>
<div>
<p>Zhang, Hao. 2004. “Inconsistent Estimation and Asymptotically Equal Interpolations in Model-Based Geostatistics.” <em>Journal of the American Statistical Association</em> 99 (465). Taylor &amp; Francis: 250–61.</p>
</div>
<div>
<p>Zou, Hui, and Trevor Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” <em>Journal of the Royal Statistical Society, Series B</em> 67 (2): 301–20.</p>
</div>
<div>
<p>Zyczkowski, K., and H.J. Sommers. 2001. “Induced Measures in the Space of Mixed Quantum States.” <em>Journal of Physics A: Mathematical and General</em> 34 (35). IOP Publishing: 7111.</p>
</div>
</div>
</div>














































































            </section>

          </div>
        </div>
      </div>
<a href="stan-for-bugs-appendix.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
