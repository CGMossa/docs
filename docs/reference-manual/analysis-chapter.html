<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Stan Reference Manual</title>
  <meta name="description" content="Stan reference manual specifying the syntax and semantics of the Stan programming language.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Stan Reference Manual" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://mc-stan.org/users/documentation" />
  <meta property="og:image" content="http://mc-stan.org/users/documentationimg/logo_tm.png" />
  <meta property="og:description" content="Stan reference manual specifying the syntax and semantics of the Stan programming language." />
  <meta name="github-repo" content="stan-dev/stan" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stan Reference Manual" />
  <meta name="twitter:site" content="@mc-stan" />
  <meta name="twitter:description" content="Stan reference manual specifying the syntax and semantics of the Stan programming language." />
  <meta name="twitter:image" content="http://mc-stan.org/users/documentationimg/logo_tm.png" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="hmc-chapter.html">
<link rel="next" href="optimization-algorithms-chapter.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="../stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Stan Reference Manual</li>

<li class="divider"></li>
<li><a href="index.html#overview"><i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Overview</i></a></li>
<li><a href="language.html#language"><i style="font-size: 110%; color:#990017;">Language</i></a></li>
<li class="chapter" data-level="1" data-path="character-encoding.html"><a href="character-encoding.html"><i class="fa fa-check"></i><b>1</b> Character Encoding</a></li>
<li class="chapter" data-level="2" data-path="includes-section.html"><a href="includes-section.html"><i class="fa fa-check"></i><b>2</b> Includes</a></li>
<li class="chapter" data-level="3" data-path="comments-section.html"><a href="comments-section.html"><i class="fa fa-check"></i><b>3</b> Comments</a></li>
<li class="chapter" data-level="4" data-path="whitespace.html"><a href="whitespace.html"><i class="fa fa-check"></i><b>4</b> Whitespace</a></li>
<li class="chapter" data-level="5" data-path="data-types-chapter.html"><a href="data-types-chapter.html"><i class="fa fa-check"></i><b>5</b> Data Types and Declarations</a></li>
<li class="chapter" data-level="6" data-path="expressions.html"><a href="expressions.html"><i class="fa fa-check"></i><b>6</b> Expressions</a></li>
<li class="chapter" data-level="7" data-path="statements.html"><a href="statements.html"><i class="fa fa-check"></i><b>7</b> Statements</a></li>
<li class="chapter" data-level="8" data-path="blocks-chapter.html"><a href="blocks-chapter.html"><i class="fa fa-check"></i><b>8</b> Program Blocks</a></li>
<li class="chapter" data-level="9" data-path="functions-chapter.html"><a href="functions-chapter.html"><i class="fa fa-check"></i><b>9</b> User-Defined Functions</a></li>
<li class="chapter" data-level="10" data-path="variable-transforms-chapter.html"><a href="variable-transforms-chapter.html"><i class="fa fa-check"></i><b>10</b> Constraint Transforms</a></li>
<li class="chapter" data-level="11" data-path="language-syntax.html"><a href="language-syntax.html"><i class="fa fa-check"></i><b>11</b> Language Syntax</a></li>
<li class="chapter" data-level="12" data-path="program-execution.html"><a href="program-execution.html"><i class="fa fa-check"></i><b>12</b> Program Execution</a></li>
<li class="chapter" data-level="13" data-path="deprecated-features-appendix.html"><a href="deprecated-features-appendix.html"><i class="fa fa-check"></i><b>13</b> Deprecated Features</a></li>
<li><a href="algorithms.html#algorithms"><i style="font-size: 110%; color:#990017;">Algorithms</i></a></li>
<li class="chapter" data-level="14" data-path="hmc-chapter.html"><a href="hmc-chapter.html"><i class="fa fa-check"></i><b>14</b> MCMC Sampling</a></li>
<li class="chapter" data-level="15" data-path="analysis-chapter.html"><a href="analysis-chapter.html"><i class="fa fa-check"></i><b>15</b> Posterior Analysis</a></li>
<li class="chapter" data-level="16" data-path="optimization-algorithms-chapter.html"><a href="optimization-algorithms-chapter.html"><i class="fa fa-check"></i><b>16</b> Optimization</a></li>
<li class="chapter" data-level="17" data-path="vi-algorithms-chapter.html"><a href="vi-algorithms-chapter.html"><i class="fa fa-check"></i><b>17</b> Variational Inference</a></li>
<li class="chapter" data-level="18" data-path="diagnostic-algorithms-chapter.html"><a href="diagnostic-algorithms-chapter.html"><i class="fa fa-check"></i><b>18</b> Diagnostic Mode</a></li>
<li><a href="usage.html#usage"><i style="font-size: 110%; color:#990017;">Usage</i></a></li>
<li class="chapter" data-level="19" data-path="reproducibility-chapter.html"><a href="reproducibility-chapter.html"><i class="fa fa-check"></i><b>19</b> Reproducibility</a></li>
<li class="chapter" data-level="20" data-path="licensing-appendix.html"><a href="licensing-appendix.html"><i class="fa fa-check"></i><b>20</b> Licenses and Dependencies</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan Reference Manual</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analysis.chapter" class="section level1">
<h1><span class="header-section-number">15</span> Posterior Analysis</h1>
<p>Stan uses Markov chain Monte Carlo (MCMC) techniques to generate
samples from the posterior distribution for full Bayesian inference.
Markov chain Monte Carlo (MCMC) methods were developed for situations
in which it is not straightforward to make independent draws
<span class="citation">Metropolis et al. (<a href="#ref-Metropolis:1953">1953</a>)</span>.</p>
<p>In addition to providing point estimates, Stan’s optimization algorithm
provides a Laplace approximation from which it is easy to draw
random values. Stan’s variational inference algorithm provides
draws from the variational approximation to the posterior. Both
of these outputs may be analyzed just as any other MCMC output,
despite the fact that it is atually independent draws.</p>
<div id="markov-chains" class="section level2">
<h2><span class="header-section-number">15.1</span> Markov Chains</h2>
<p>A <em>Markov chain</em> is a sequence of random variables <span class="math inline">\(\theta^{(1)}, \theta^{(2)},\ldots\)</span> where each variable is conditionally independent
of all other variables given the value of the previous value. Thus if
<span class="math inline">\(\theta = \theta^{(1)}, \theta^{(2)},\ldots, \theta^{(N)}\)</span>, then</p>
<p><span class="math display">\[
p(\theta) = p(\theta^{(1)}) \prod_{n=2}^N p(\theta^{(n)}|\theta^{(n-1)}).
\]</span></p>
<p>Stan uses Hamiltonian Monte Carlo to generate a next state in a manner
described in the <a href="hmc-chapter.html#hmc.chapter">Hamiltonian Monte Carlo chapter</a>.</p>
<p>The Markov chains Stan and other MCMC samplers generate are <em>ergodic</em>
in the sense required by the Markov chain central limit theorem,
meaning roughly that there is a reasonable chance of reaching
one value of <span class="math inline">\(\theta\)</span> from another. The Markov chains are also
<em>stationary</em>, meaning that the transition probabilities do not change at
different positions in the chain, so that for <span class="math inline">\(n, n&#39; \geq 0\)</span>, the
probability function <span class="math inline">\(p(\theta^{(n+1)}|\theta^{(n)})\)</span> is the same as
<span class="math inline">\(p(\theta^{(n&#39;+1)}|\theta^{(n&#39;)})\)</span> (following the convention of
overloading random and bound variables and picking out a probability
function by its arguments).</p>
<p>Stationary Markov chains have an <em>equilibrium distribution</em> on states
in which each has the same marginal probability function, so that
<span class="math inline">\(p(\theta^{(n)})\)</span> is the same probability function as
<span class="math inline">\(p(\theta^{(n+1)})\)</span>. In Stan, this equilibrium distribution
<span class="math inline">\(p(\theta^{(n)})\)</span> is the target density <span class="math inline">\(p(\theta)\)</span> defined by a Stan
program, which is typically a proper Bayesian posterior density
<span class="math inline">\(p(\theta | y)\)</span> defined on the log scale up to a constant.</p>
<p>Using MCMC methods introduces two difficulties that are not faced by
independent sample Monte Carlo methods. The first problem is
determining when a randomly initialized Markov chain has converged to
its equilibrium distribution. The second problem is that the draws
from a Markov chain may be correlated or even anti-correlated, and
thus the central limit theorem’s bound on estimation error no longer
applies. These problems are addressed in the next two sections.</p>
<p>Stan’s posterior analysis tools compute a number of summary
statistics, estimates, and diagnostics for Markov chain Monte Carlo
(MCMC) samples. Stan’s estimators and diagnostics are more robust in
the face of non-convergence, antithetical sampling, and long-term
Markov chain correlations than most of the other tools available. The
algorithms Stan uses to achieve this are described in this chapter.</p>
</div>
<div id="convergence" class="section level2">
<h2><span class="header-section-number">15.2</span> Convergence</h2>
<p>By definition, a Markov chain generates samples from the target
distribution only after it has converged to equilibrium (i.e.,
equilibrium is defined as being achieved when <span class="math inline">\(p(\theta^{(n)})\)</span> is the
target density). The following point cannot be expressed strongly
enough:</p>
<ul>
<li><p>In theory, <em>convergence is only guaranteed asymptotically</em> as the
number of draws grows without bound.</p></li>
<li><p>In practice, <em>diagnostics must be applied to monitor convergence</em>
for the finite number of draws actually available.</p></li>
</ul>
</div>
<div id="notation-for-samples-chains-and-draws" class="section level2">
<h2><span class="header-section-number">15.3</span> Notation for samples, chains, and draws</h2>
<p>To establish basic notation, suppose a target Bayesian posterior
density <span class="math inline">\(p(\theta | y)\)</span> given real-valued vectors of parameters
<span class="math inline">\(\theta\)</span> and real- and discrete-valued data <span class="math inline">\(y\)</span>.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
<p>An MCMC <em>sample</em> consists of a set of a sequence of <span class="math inline">\(M\)</span> Markov chains,
each consisting of an ordered sequence of <span class="math inline">\(N\)</span> <em>draws</em> from the
posterior.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> The sample
thus consists of <span class="math inline">\(M \times N\)</span> draws from the posterior.</p>
<div id="potential-scale-reduction" class="section level3">
<h3><span class="header-section-number">15.3.1</span> Potential Scale Reduction</h3>
<p>One way to monitor whether a chain has converged to the equilibrium
distribution is to compare its behavior to other randomly initialized
chains. This is the motivation for the <span class="citation">Gelman and Rubin (<a href="#ref-GelmanRubin:1992">1992</a>)</span> potential
scale reduction statistic, <span class="math inline">\(\hat{R}\)</span>. The <span class="math inline">\(\hat{R}\)</span> statistic
measures the ratio of the average variance of samples within each
chain to the variance of the pooled samples across chains; if all
chains are at equilibrium, these will be the same and <span class="math inline">\(\hat{R}\)</span> will
be one. If the chains have not converged to a common distribution,
the <span class="math inline">\(\hat{R}\)</span> statistic will be greater than one.</p>
<p>Gelman and Rubin’s recommendation is that the independent Markov
chains be initialized with diffuse starting values for the parameters
and sampled until all values for <span class="math inline">\(\hat{R}\)</span> are below 1.1. Stan
allows users to specify initial values for parameters and it is also
able to draw diffuse random initializations automatically satisfying
the declared parameter constraints.</p>
<p>The <span class="math inline">\(\hat{R}\)</span> statistic is defined for a set of <span class="math inline">\(M\)</span> Markov chains,
<span class="math inline">\(\theta_m\)</span>, each of which has <span class="math inline">\(N\)</span> samples <span class="math inline">\(\theta^{(n)}_m\)</span>. The
<em>between-chain variance</em> estimate is</p>
<p><span class="math display">\[
B
=
\frac{N}{M-1}
\,
\sum_{m=1}^M (\bar{\theta}^{(\bullet)}_{m}
                - \bar{\theta}^{(\bullet)}_{\bullet})^2,
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\bar{\theta}_m^{(\bullet)}
= \frac{1}{N} \sum_{n = 1}^N \theta_m^{(n)}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\bar{\theta}^{(\bullet)}_{\bullet}
= \frac{1}{M} \, \sum_{m=1}^M \bar{\theta}_m^{(\bullet)}.
\]</span></p>
<p>The <em>within-chain variance</em> is averaged over the chains,</p>
<p><span class="math display">\[
W = \frac{1}{M} \, \sum_{m=1}^M s_m^2,
\]</span></p>
<p>where</p>
<p><span class="math display">\[
s_m^2
=
\frac{1}{N-1}
\, \sum_{n=1}^N (\theta^{(n)}_m - \bar{\theta}^{(\bullet)}_m)^2.
\]</span></p>
<p>The <em>variance estimator</em> is a mixture of the within-chain and
cross-chain sample variances,</p>
<p><span class="math display">\[
\widehat{\mbox{var}}^{+}\!(\theta|y)
= \frac{N-1}{N}\, W \, + \, \frac{1}{N} \, B.
\]</span></p>
<p>Finally, the <em>potential scale reduction statistic</em> is defined by</p>
<p><span class="math display">\[
\hat{R}
\, = \,
\sqrt{\frac{\widehat{\mbox{var}}^{+}\!(\theta|y)}{W}}.
\]</span></p>
</div>
<div id="split-r-hat-for-detecting-non-stationarity" class="section level3">
<h3><span class="header-section-number">15.3.2</span> Split R-hat for Detecting Non-Stationarity</h3>
<p>Before Stan calculating the potential-scale-reduction statistic
<span class="math inline">\(\hat{R}\)</span>, each chain is split into two halves. This provides an
additional means to detect non-stationarity in the individual chains.
If one chain involves gradually increasing values and one involves
gradually decreasing values, they have not mixed well, but they can
have <span class="math inline">\(\hat{R}\)</span> values near unity. In this case, splitting each chain
into two parts leads to <span class="math inline">\(\hat{R}\)</span> values substantially greater than 1
because the first half of each chain has not mixed with the second
half.</p>
</div>
<div id="convergence-is-global" class="section level3">
<h3><span class="header-section-number">15.3.3</span> Convergence is Global</h3>
<p>A question that often arises is whether it is acceptable to monitor
convergence of only a subset of the parameters or generated
quantities. The short answer is “no,” but this is elaborated
further in this section.</p>
<p>For example, consider the value <code>lp__</code>, which is the log posterior
density (up to a constant).<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<p>It is thus a mistake to declare convergence in any practical sense if
<code>lp__</code> has not converged, because different chains are really in
different parts of the space. Yet measuring convergence for <code>lp__</code> is
particularly tricky, as noted below.</p>
<div id="asymptotics-and-transience-vs.equilibrium" class="section level4">
<h4><span class="header-section-number">15.3.3.1</span> Asymptotics and transience vs. equilibrium</h4>
<p>Markov chain convergence is a global property in the sense that it
does not depend on the choice of function of the parameters that is
monitored. There is no hard cutoff between pre-convergence
“transience” and post-convergence “equilibrium.” What happens is
that as the number of states in the chain approaches infinity, the
distribution of possible states in the chain approaches the target
distribution and in that limit the expected value of the Monte Carlo
estimator of any integrable function converges to the true
expectation. There is nothing like warmup here, because in the limit,
the effects of initial state are completely washed out.</p>
</div>
<div id="multivariate-convergence-of-functions" class="section level4">
<h4><span class="header-section-number">15.3.3.2</span> Multivariate convergence of functions</h4>
<p>The <span class="math inline">\(\hat{R}\)</span> statistic considers the composition of a Markov chain
and a function, and if the Markov chain has converged then each Markov
chain and function composition will have converged. Multivariate
functions converge when all of their margins have converged by the
Cramer-Wold theorem.</p>
<p>The transformation from unconstrained space to constrained space is
just another function, so does not effect convergence.</p>
<p>Different functions may have different autocorrelations, but if the
Markov chain has equilibrated then all Markov chain plus function
compositions should be consistent with convergence. Formally, any
function that appears inconsistent is of concern and although it would
be unreasonable to test every function, <code>lp__</code> and other
measured quantities should at least be consistent.</p>
<p>The obvious difference in <code>lp__</code> is that it tends to vary
quickly with position and is consequently susceptible to outliers.</p>
</div>
<div id="finite-numbers-of-states" class="section level4">
<h4><span class="header-section-number">15.3.3.3</span> Finite numbers of states</h4>
<p>The question is what happens for finite numbers of states? If we can
prove a strong geometric ergodicity property (which depends on the
sampler and the target distribution), then one can show that there
exists a finite time after which the chain forgets its initial state
with a large probability. This is both the autocorrelation time and
the warmup time. But even if you can show it exists and is finite
(which is nigh impossible) you can’t compute an actual value
analytically.</p>
<p>So what we do in practice is hope that the finite number of draws is
large enough for the expectations to be reasonably accurate. Removing
warmup iterations improves the accuracy of the expectations but there
is no guarantee that removing any finite number of samples will be
enough.</p>
</div>
<div id="why-inconsistent-r-hat" class="section level4">
<h4><span class="header-section-number">15.3.3.4</span> Why inconsistent R-hat?</h4>
<p>Firstly, as noted above, for any finite number of draws, there will
always be some residual effect of the initial state, which typically
manifests as some small (or large if the autocorrelation time is huge)
probability of having a large outlier. Functions robust to such
outliers (say, quantiles) will appear more stable and have better
<span class="math inline">\(\hat{R}\)</span>. Functions vulnerable to such outliers may show fragility.</p>
<p>Secondly, use of the <span class="math inline">\(\hat{R}\)</span> statistic makes very strong
assumptions. In particular, it assumes that the functions being
considered are Gaussian or it only uses the first two moments and
assumes some kind of independence. The point is that strong
assumptions are made that do not always hold. In particular, the
distribution for the log posterior density (<code>lp__</code>) almost
never looks Gaussian, instead it features long tails that can lead to
large <span class="math inline">\(\hat{R}\)</span> even in the large <span class="math inline">\(N\)</span> limit. Tweaks to <span class="math inline">\(\hat{R}\)</span>,
such as using quantiles in place of raw values, have the flavor of
making the samples of interest more Gaussian and hence the <span class="math inline">\(\hat{R}\)</span>
statistic more accurate.</p>
</div>
<div id="final-words-on-convergence-monitoring" class="section level4">
<h4><span class="header-section-number">15.3.3.5</span> Final words on convergence monitoring</h4>
<p>“Convergence” is a global property and holds for all integrable
functions at once, but employing the <span class="math inline">\(\hat{R}\)</span> statistic requires
additional assumptions and thus may not work for all functions equally
well.</p>
<p>Note that if you just compare the expectations between chains then we
can rely on the Markov chain asymptotics for Gaussian distributions
and can apply the standard tests.</p>
</div>
</div>
</div>
<div id="effective-sample-size.section" class="section level2">
<h2><span class="header-section-number">15.4</span> Effective Sample Size</h2>
<p>The second technical difficulty posed by MCMC methods is that the
samples will typically be autocorrelated (or anticorrelated) within a
chain. This increases the uncertainty of the estimation of posterior
quantities of interest, such as means, variances, or quantiles; see
<span class="citation">Geyer (<a href="#ref-Geyer:2011">2011</a>)</span>.</p>
<p>Stan estimates an effective sample size for each parameter, which
plays the role in the Markov chain Monte Carlo central limit theorem
(MCMC CLT) as the number of independent draws plays in the standard
central limit theorem (CLT).</p>
<p>Unlike most packages, the particular calculations used by Stan follow
those for split-<span class="math inline">\(\hat{R}\)</span>, which involve both cross-chain (mean) and
within-chain calculations (autocorrelation); see <span class="citation">Gelman et al. (<a href="#ref-GelmanEtAl:2013">2013</a>)</span>.</p>
<div id="definition-of-effective-sample-size" class="section level3">
<h3><span class="header-section-number">15.4.1</span> Definition of Effective Sample Size</h3>
<p>The amount by which autocorrelation within the chains increases
uncertainty in estimates can be measured by effective sample size (ESS).
Given independent samples, the central limit theorem
bounds uncertainty in estimates based on the number of samples <span class="math inline">\(N\)</span>.
Given dependent samples, the number of independent samples is replaced
with the effective sample size <span class="math inline">\(N_{\mathrm{eff}}\)</span>, which is
the number of independent samples with the same estimation power as
the <span class="math inline">\(N\)</span> autocorrelated samples. For example, estimation error is
proportional to <span class="math inline">\(1 / \sqrt{N_{\mathrm{eff}}}\)</span> rather than
<span class="math inline">\(1/\sqrt{N}\)</span>.</p>
<p>The effective sample size of a sequence is defined in terms of the
autocorrelations within the sequence at different lags. The
autocorrelation <span class="math inline">\(\rho_t\)</span> at lag <span class="math inline">\(t \geq 0\)</span> for a chain with joint
probability function <span class="math inline">\(p(\theta)\)</span> with mean <span class="math inline">\(\mu\)</span> and variance
<span class="math inline">\(\sigma^2\)</span> is defined to be</p>
<p><span class="math display">\[
\rho_t
=
\frac{1}{\sigma^2} \, \int_{\Theta} (\theta^{(n)} - \mu)
(\theta^{(n+t)} - \mu) \, p(\theta) \, d\theta.
\]</span></p>
<p>This is the correlation between the two chains offset by <span class="math inline">\(t\)</span> positions
(i.e., a lag in time-series terminology). Because we know
<span class="math inline">\(\theta^{(n)}\)</span> and <span class="math inline">\(\theta^{(n+t)}\)</span> have the same marginal
distribution in an MCMC setting, multiplying the two difference terms
and reducing yields</p>
<p><span class="math display">\[
\rho_t
= \frac{1}{\sigma^2}
\, \int_{\Theta}
      \theta^{(n)} \, \theta^{(n+t)} \, p(\theta)
   \, d\theta.
\]</span></p>
<p>The effective sample size of <span class="math inline">\(N\)</span> samples generated by a process with
autocorrelations <span class="math inline">\(\rho_t\)</span> is defined by
<span class="math display">\[
N_{\mathrm{eff}}
\ = \
\frac{N}{\sum_{t = -\infty}^{\infty} \rho_t}
\ = \
\frac{N}{1 + 2 \sum_{t = 1}^{\infty} \rho_t}.
\]</span></p>
<p>Effective sample size <span class="math inline">\(N_{\mathrm{eff}}\)</span> can be larger than <span class="math inline">\(N\)</span> in
case of antithetic Markov chains, which have negative autocorrelations
on odd lags. The no-U-turn sampling (NUTS) algorithm used in Stan can
produce <span class="math inline">\(N_{\mathrm{eff}}&gt;N\)</span> for parameters which have close to
Gaussian posterior and little dependency on other parameters.</p>
</div>
<div id="estimation-of-effective-sample-size" class="section level3">
<h3><span class="header-section-number">15.4.2</span> Estimation of Effective Sample Size</h3>
<p>In practice, the probability function in question cannot be tractably
integrated and thus the autocorrelation cannot be calculated, nor the
effective sample size. Instead, these quantities must be estimated
from the samples themselves. The rest of this section describes a
autocorrelations and split-<span class="math inline">\(\hat{R}\)</span> based effective sample
size estimator, based on multiple chains. As before, each chain
<span class="math inline">\(\theta_m\)</span> will be assumed to be of length <span class="math inline">\(N\)</span>.</p>
<p>Stan carries out the autocorrelation computations for all lags
simultaneously using Eigen’s fast Fourier transform (FFT) package with
appropriate padding; see <span class="citation">Geyer (<a href="#ref-Geyer:2011">2011</a>)</span> for more detail on using FFT for
autocorrelation calculations. The autocorrelation estimates
<span class="math inline">\(\hat{\rho}_{t,m}\)</span> at lag <span class="math inline">\(t\)</span> from multiple chains <span class="math inline">\(m \in (1,\ldots,M)\)</span> are combined with within-sample variance estimate <span class="math inline">\(W\)</span>
and multi-chain variance estimate <span class="math inline">\(\widehat{\mbox{var}}^{+}\)</span>
introduced in the previous section to compute the combined
autocorrelation at lag <span class="math inline">\(t\)</span> as</p>
<p><span class="math display">\[
\hat{\rho}_t
= 1 - \frac{\displaystyle W
              - \textstyle \frac{1}{M}\sum_{m=1}^M \hat{\rho}_{t,m}}
        {\widehat{\mbox{var}}^{+}}.
\]</span></p>
<p>If the chains have not converged, the variance estimator
<span class="math inline">\(\widehat{\mbox{var}}^{+}\)</span> will overestimate variance, leading to an
overestimate of autocorrelation and an underestimate effective sample
size.</p>
<p>Because of the noise in the correlation estimates <span class="math inline">\(\hat{\rho}_t\)</span> as
<span class="math inline">\(t\)</span> increases, a typical truncated sum of <span class="math inline">\(\hat{\rho}_t\)</span> is used.
Negative autocorrelations may occur only on odd lags and by summing
over pairs starting from lag 0, the paired autocorrelation is
guaranteed to be positive, monotone and convex modulo estimator noise
<span class="citation">Geyer (<a href="#ref-Geyer:1992">1992</a>)</span>, <span class="citation">Geyer (<a href="#ref-Geyer:2011">2011</a>)</span>. Stan uses Geyer’s initial monotone
sequence criterion. The effective sample size estimator is defined as</p>
<p><span class="math display">\[
\hat{N}_{\mathrm{eff}} = \frac{M \cdot N}{\hat{\tau}},
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\hat{\tau} = 1 + 2 \sum_{t=1}^{2m+1} \hat{\rho}_t = -1 + 2 \sum_{t&#39;=0}^{m} \hat{P}_{t&#39;},
\]</span></p>
<p>where <span class="math inline">\(\hat{P}_{t&#39;}=\hat{\rho}_{2t&#39;}+\hat{\rho}_{2t&#39;+1}\)</span>. Initial
positive sequence estimators is obtained by choosing the largest <span class="math inline">\(m\)</span>
such that <span class="math inline">\(\hat{P}_{t&#39;}&gt;0, \quad t&#39; = 1,\ldots,m\)</span>. The initial monotone
sequence is obtained by further reducing <span class="math inline">\(\hat{P}_{t&#39;}\)</span> to the minimum
of the preceding ones so that the estimated sequence is monotone.</p>
</div>
<div id="estimation-of-mcmc-standard-error" class="section level3">
<h3><span class="header-section-number">15.4.3</span> Estimation of MCMC Standard Error</h3>
<p>The posterior standard deviation of a parameter <span class="math inline">\(\theta_n\)</span> conditioned
on observed data <span class="math inline">\(y\)</span> is just the standard deviation of the posterior
density <span class="math inline">\(p(\theta_n | y)\)</span>. This is estimated by the standard
deviation of the combined posterior draws across chains,</p>
<p><span class="math display">\[
\hat{\sigma}_n = \mathrm{sd}(\theta^{(1)}_n, \ldots, \theta^{(m)}_n).
\]</span></p>
<p>The previous section showed how to estimate <span class="math inline">\(N_{\mathrm{eff}}\)</span> for a
parameter <span class="math inline">\(\theta_n\)</span> based on multiple chains of posterior draws.</p>
<p>The mean of the posterior draws of <span class="math inline">\(\theta_n\)</span>
<span class="math display">\[
\hat{\theta}_n
= \mathrm{mean}(\theta^{(1)}_n, \ldots, \theta^{(m)}_n)
\]</span></p>
<p>is treated as an estimator of the true posterior mean,</p>
<p><span class="math display">\[
\mathbb{E}[\theta_n \mid y]
\ = \
\int_{-\infty}^{\infty}
    \, \theta \, p(\theta | y)
\, \mathrm{d}\theta_n,
\]</span></p>
<p>based the observed data <span class="math inline">\(y\)</span>.</p>
<p>The standard error for the estimator <span class="math inline">\(\hat{\theta}_n\)</span> is given by the
posterior standard deviation divided by the square root of the
effective sample size. This standard error is itself estimated as
<span class="math inline">\(\hat{\sigma}_n / \sqrt{N_{\mathrm{eff}}}\)</span>. The smaller the standard
error, the closer the estimate <span class="math inline">\(\hat{\theta}_n\)</span> is expected to be to
the true value. This is just the MCMC CLT applied to an estimator;
see <span class="citation">Geyer (<a href="#ref-Geyer:2011">2011</a>)</span> for more details of the MCMC central limit theorem.</p>
</div>
<div id="thinning-samples" class="section level3">
<h3><span class="header-section-number">15.4.4</span> Thinning Samples</h3>
<p>In the typical situation, the autocorrelation, <span class="math inline">\(\rho_t\)</span>, decreases as
the lag, <span class="math inline">\(t\)</span>, increases. When this happens, thinning the samples will
reduce the autocorrelation.</p>
<p>For instance, consider generating one thousand posterior draws in one
of the following two ways.</p>
<ul>
<li><p>Generate 1000 draws after convergence and save all of them.</p></li>
<li><p>Generate 10,000 draws after convergence and save every tenth draw.</p></li>
</ul>
<p>Even though both produce a sample consisting one thousand draws, the
second approach with thinning can produce a higher effective sample
size. That’s because the autocorrelation <span class="math inline">\(\rho_t\)</span> for the thinned
sequence is equivalent to <span class="math inline">\(\rho_{10t}\)</span> in the unthinned sequence, so
the sum of the autocorrelations will be lower and thus the effective
sample size higher.</p>
<p>Now contrast the second approach above with the unthinned alternative,</p>
<ul>
<li>Generate 10,000 draws after convergence and save every draw.</li>
</ul>
<p>This will have a higher effective sample than the thinned sample
consisting of every tenth drawn. Therefore, it should be emphasized
that <em>the only reason to thin a sample is to reduce memory
requirements</em>.</p>

</div>
</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-Metropolis:1953">
<p>Metropolis, N., A. Rosenbluth, M. Rosenbluth, M. Teller, and E. Teller. 1953. “Equations of State Calculations by Fast Computing Machines.” <em>Journal of Chemical Physics</em> 21: 1087–92.</p>
</div>
<div id="ref-GelmanRubin:1992">
<p>Gelman, Andrew, and Donald B. Rubin. 1992. “Inference from Iterative Simulation Using Multiple Sequences.” <em>Statistical Science</em> 7 (4): 457–72.</p>
</div>
<div id="ref-Geyer:2011">
<p>Geyer, Charles J. 2011. “Introduction to Markov Chain Monte Carlo.” In <em>Handbook of Markov Chain Monte Carlo</em>, edited by Steve Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng, 3–48. Chapman; Hall/CRC.</p>
</div>
<div id="ref-GelmanEtAl:2013">
<p>Gelman, Andrew, J. B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third. London: Chapman &amp;Hall/CRC Press.</p>
</div>
<div id="ref-Geyer:1992">
<p>Geyer, Charles J. 1992. “Practical Markov Chain Monte Carlo.” <em>Statistical Science</em>, 473–83.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="25">
<li id="fn25"><p>Using vectors simplifies high level exposition at the expense of collapsing structure.<a href="analysis-chapter.html#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p>The structure is assumed to be rectangular; in the
future, this needs to be generalized to ragged samples.<a href="analysis-chapter.html#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>The <code>lp__</code> value also represents the
potential energy in the Hamiltonian system and is rate bounded by the
randomly supplied kinetic energy each iteration, which follows a
Chi-square distribution in the number of parameters.<a href="analysis-chapter.html#fnref27" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hmc-chapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="optimization-algorithms-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": false,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
