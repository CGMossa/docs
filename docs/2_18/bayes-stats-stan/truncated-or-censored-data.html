<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics Using Stan</title>
  <meta name="description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics Using Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics Using Stan" />
  
  <meta name="twitter:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="floating-point-arithmetic.html">
<link rel="next" href="mixture-modeling-chapter.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Bayesian Statistics with Stan</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="part-1-bayesian-workflow.html#part-1-bayesian-workflow"><i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Part 1: Bayesian Workflow</i></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="fake-data-simulation.html"><a href="fake-data-simulation.html"><i class="fa fa-check"></i><b>2</b> Fake-data Simulation</a></li>
<li class="chapter" data-level="3" data-path="prior-distributions-and-models-for-data.html"><a href="prior-distributions-and-models-for-data.html"><i class="fa fa-check"></i><b>3</b> Prior Distributions and Models for Data</a></li>
<li class="chapter" data-level="4" data-path="some-self-contained-examples.html"><a href="some-self-contained-examples.html"><i class="fa fa-check"></i><b>4</b> Some Self-Contained Examples</a></li>
<li class="chapter" data-level="5" data-path="workflow-in-action.html"><a href="workflow-in-action.html"><i class="fa fa-check"></i><b>5</b> Workflow in Action</a></li>
<li class="chapter" data-level="6" data-path="modeling-as-software-development.html"><a href="modeling-as-software-development.html"><i class="fa fa-check"></i><b>6</b> Modeling as Software Development</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 2. Example Models</i></span></a></li>
<li class="chapter" data-level="7" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>7</b> Regression Models</a></li>
<li class="chapter" data-level="8" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>8</b> Time-Series Models</a></li>
<li class="chapter" data-level="9" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>9</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="10" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>10</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="11" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>11</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="12" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>12</b> Finite Mixtures</a></li>
<li class="chapter" data-level="13" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>13</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="14" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>14</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="15" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>15</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="16" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>16</b> Clustering Models</a></li>
<li class="chapter" data-level="17" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>17</b> Gaussian Processes</a></li>
<li class="chapter" data-level="18" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>18</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="19" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>19</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="20" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>20</b> Ordinary Differential Equations</a></li>
<li><a href="part-3-programming-techniques.html#part-3.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 3. Programming Techniques</i></a></li>
<li class="chapter" data-level="21" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>21</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="22" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>22</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="23" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>23</b> User-Defined Functions</a></li>
<li class="chapter" data-level="24" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>24</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="25" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>25</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="26" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>26</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="27" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>27</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="28" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>28</b> Map-Reduce</a></li>
<li><a href="part-4-review-of-statistical-inference.html#part-4-review-of-statistical-inference"><i style="font-size: 110%; color:#990017;">Part 4: Review of Statistical Inference</i></a></li>
<li class="chapter" data-level="29" data-path="bayesian-data-analysis-1.html"><a href="bayesian-data-analysis-1.html"><i class="fa fa-check"></i><b>29</b> Bayesian Data Analysis</a></li>
<li class="chapter" data-level="30" data-path="mle-chapter.html"><a href="mle-chapter.html"><i class="fa fa-check"></i><b>30</b> Penalized Maximum Likelihood Point Estimation</a></li>
<li class="chapter" data-level="31" data-path="bayesian-point-estimation.html"><a href="bayesian-point-estimation.html"><i class="fa fa-check"></i><b>31</b> Bayesian Point Estimation</a></li>
<li class="chapter" data-level="32" data-path="vi-advanced-chapter.html"><a href="vi-advanced-chapter.html"><i class="fa fa-check"></i><b>32</b> Variational Inference</a></li>
<li><a href="appendices.html#appendices"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="" data-path="appendix-1-stan-program-style-guide.html"><a href="appendix-1-stan-program-style-guide.html"><i class="fa fa-check"></i>Appendix 1. Stan Program Style Guide</a></li>
<li class="chapter" data-level="" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i>Appendix 2. Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics Using Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="truncated-or-censored-data" class="section level1">
<h1><span class="header-section-number">11</span> Truncated or Censored Data</h1>
<p>Data in which measurements have been truncated or censored can be
coded in Stan following their respective probability models.</p>
<div id="truncation.section" class="section level2">
<h2><span class="header-section-number">11.1</span> Truncated Distributions</h2>
<p>Truncation in Stan is restricted to univariate distributions for which
the corresponding log cumulative distribution function (cdf) and log
complementary cumulative distribution (ccdf) functions are available.
See the reference manual section on truncated distributions for more
information on truncated distributions, cdfs, and ccdfs.</p>
</div>
<div id="truncated-data.section" class="section level2">
<h2><span class="header-section-number">11.2</span> Truncated Data</h2>
<p>Truncated data are data for which measurements are only reported if
they fall above a lower bound, below an upper bound, or between a
lower and upper bound.</p>
<p>Truncated data may be modeled in Stan using truncated distributions.
For example, suppose the truncated data are <span class="math inline">\(y_n\)</span> with an upper
truncation point of <span class="math inline">\(U = 300\)</span> so that <span class="math inline">\(y_n &lt; 300\)</span>. In Stan, this
data can be modeled as following a truncated normal distribution for
the observations as follows.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  real U;
  real&lt;upper=U&gt; y[N];
}
parameters {
  real mu;
  real&lt;lower=0&gt; sigma;
}
model {
  for (n in 1:N)
    y[n] ~ normal(mu, sigma) T[,U];
}</code></pre>
<p>The model declares an upper bound <code>U</code> as data and constrains
the data for <code>y</code> to respect the constraint; this will be checked
when the data are loaded into the model before sampling begins.</p>
<p>This model implicitly uses an improper flat prior on the scale and
location parameters; these could be given priors in the model using
sampling statements.</p>
<div id="constraints-and-out-of-bounds-returns" class="section level3 unnumbered">
<h3>Constraints and Out-of-Bounds Returns</h3>
<p>If the sampled variate in a truncated distribution lies outside of
the truncation range, the probability is zero, so the log probability
will evaluate to <span class="math inline">\(-\infty\)</span>. For instance, if variate <code>y</code> is
sampled with the statement.</p>
<pre><code>for (n in 1:N)
  y[n] ~ normal(mu, sigma) T[L,U];</code></pre>
<p>then if the value of <code>y[n]</code> is less than the value of <code>L</code>
or greater than the value of <code>U</code>, the sampling statement produces
a zero-probability estimate. For user-defined truncation, this
zeroing outside of truncation bounds must be handled explicitly.</p>
<p>To avoid variables straying outside of truncation bounds, appropriate
constraints are required. For example, if <code>y</code> is a parameter in
the above model, the declaration should constrain it to fall between
the values of <code>L</code> and <code>U</code>.</p>
<pre><code>parameters {
  real&lt;lower=L,upper=U&gt; y[N];
  ...</code></pre>
<p>If in the above model, <code>L</code> or <code>U</code> is a parameter and
<code>y</code> is data, then <code>L</code> and <code>U</code> must be appropriately
constrained so that all data are in range and the value of <code>L</code> is
less than that of <code>U</code> (if they are equal, the parameter range
collapses to a single point and the Hamiltonian dynamics used by
the sampler break down). The following declarations ensure the bounds
are well behaved.</p>
<pre><code>parameters {
  real&lt;upper=min(y)&gt; L; // L &lt; y[n]
  real&lt;lower=fmax(L, max(y))&gt; U; // L &lt; U; y[n] &lt; U</code></pre>
<p>For pairs of real numbers, the function <code>fmax</code> is used
rather than <code>max</code>.</p>
</div>
<div id="unknown-truncation-points" class="section level3 unnumbered">
<h3>Unknown Truncation Points</h3>
<p>If the truncation points are unknown, they may be estimated as
parameters. This can be done with a slight rearrangement of the
variable declarations from the model in the previous section with
known truncation points.</p>
<pre><code>data {
  int&lt;lower=1&gt; N;
  real y[N];
}
parameters {
  real&lt;upper = min(y)&gt; L;
  real&lt;lower = max(y)&gt; U;
  real mu;
  real&lt;lower=0&gt; sigma;
}
model {
  L ~ ...;
  U ~ ...;
  for (n in 1:N)
    y[n] ~ normal(mu, sigma) T[L,U];
}</code></pre>
<p>Here there is a lower truncation point <code>L</code> which is declared to
be less than or equal to the minimum value of <code>y</code>. The upper
truncation point <code>U</code> is declared to be larger than the maximum
value of <code>y</code>. This declaration, although dependent on the data,
only enforces the constraint that the data fall within the truncation
bounds. With <code>N</code> declared as type <code>int&lt;lower=1&gt;</code>, there must be
at least one data point. The constraint that <code>L</code> is less than
<code>U</code> is enforced indirectly, based on the non-empty data.</p>
<p>The ellipses where the priors for the bounds <code>L</code> and <code>U</code>
should go should be filled in with a an informative prior in
order for this model to not concentrate <code>L</code> strongly around
<code>min(y)</code> and <code>U</code> strongly around <code>max(y)</code>.</p>
</div>
</div>
<div id="censored-data" class="section level2">
<h2><span class="header-section-number">11.3</span> Censored Data</h2>
<p>Censoring hides values from points that are too large, too small, or
both. Unlike with truncated data, the number of data points that were
censored is known. The textbook example is the household scale which
does not report values above 300 pounds.</p>
<div id="estimating-censored-values" class="section level3 unnumbered">
<h3>Estimating Censored Values</h3>
<p>One way to model censored data is to treat the censored data as
missing data that is constrained to fall in the censored range of
values. Since Stan does not allow unknown values in its arrays or
matrices, the censored values must be represented explicitly, as in the
following right-censored case.</p>
<pre><code>data {
  int&lt;lower=0&gt; N_obs;
  int&lt;lower=0&gt; N_cens;
  real y_obs[N_obs];
  real&lt;lower=max(y_obs)&gt; U;
}
parameters {
  real&lt;lower=U&gt; y_cens[N_cens];
  real mu;
  real&lt;lower=0&gt; sigma;
}
model {
  y_obs ~ normal(mu, sigma);
  y_cens ~ normal(mu, sigma);
}</code></pre>
<p>Because the censored data array <code>y_cens</code> is declared to be a parameter, it
will be sampled along with the location and scale parameters <code>mu</code>
and <code>sigma</code>. Because the censored data array <code>y_cens</code> is
declared to have values of type <code>real&lt;lower=U&gt;</code>, all imputed values
for censored data will be greater than <code>U</code>. The imputed censored
data affects the location and scale parameters through the last
sampling statement in the model.</p>
</div>
<div id="integrating-out-censored-values" class="section level3 unnumbered">
<h3>Integrating out Censored Values</h3>
<p>Although it is wrong to ignore the censored values in estimating
location and scale, it is not necessary to impute values. Instead,
the values can be integrated out. Each censored data point has a
probability of</p>
<p><span class="math display">\[
\mbox{Pr}[y &gt; U]
= \int_U^{\infty} \mathsf{normal}(y|\mu,\sigma) \, dy
= 1 - \Phi\left(\frac{y - \mu}{\sigma}\right),
\]</span></p>
<p>where <span class="math inline">\(\Phi()\)</span> is the standard normal cumulative distribution function.
With <span class="math inline">\(M\)</span> censored observations, the total probability on the log scale
is
<span class="math display">\[
\log \prod_{m=1}^M \mbox{Pr}[y_m &gt; U]
= \log \left( 1 - \Phi\left(\frac{y - \mu}{\sigma}\right)\right)^{M}
= M \, `normal_lccdf`(y | \mu, \sigma),
\]</span></p>
<p>where <code>normal_lccdf</code> is the log of complementary CDF
(Stan provides <code>&lt;distr&gt;_lccdf</code> for each distribution
implemented in Stan).</p>
<p>The following right-censored model assumes
that the censoring point is known, so it is declared as data.</p>
<pre><code>data {
  int&lt;lower=0&gt; N_obs;
  int&lt;lower=0&gt; N_cens;
  real y_obs[N_obs];
  real&lt;lower=max(y_obs)&gt; U;
}
parameters {
  real mu;
  real&lt;lower=0&gt; sigma;
}
model {
  y_obs ~ normal(mu, sigma);
  target += N_cens * normal_lccdf(U | mu, sigma);
}</code></pre>
<p>For the observed values in <code>y_obs</code>, the normal sampling model is
used without truncation. The log probability is directly incremented
using the calculated log cumulative normal probability of the censored
data items.</p>
<p>For the left-censored data the CDF (<code>normal_lcdf</code>) has to be
used instead of complementary CDF. If the censoring point variable
(<code>L</code>) is unknown, its declaration should be moved from the data
to the parameters block.</p>
<pre><code>data {
  int&lt;lower=0&gt; N_obs;
  int&lt;lower=0&gt; N_cens;
  real y_obs[N_obs];
}
parameters {
  real&lt;upper=min(y_obs)&gt; L;
  real mu;
  real&lt;lower=0&gt; sigma;
}
model {
  L ~ normal(mu, sigma);
  y_obs ~ normal(mu, sigma);
  target += N_cens * normal_lcdf(L | mu, sigma);
}</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="floating-point-arithmetic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixture-modeling-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
