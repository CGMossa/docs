<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics Using Stan</title>
  <meta name="description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics Using Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics Using Stan" />
  
  <meta name="twitter:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="appendix-1-stan-program-style-guide.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Bayesian Statistics with Stan</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="part-1-bayesian-workflow.html#part-1-bayesian-workflow"><i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Part 1: Bayesian Workflow</i></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="fake-data-simulation.html"><a href="fake-data-simulation.html"><i class="fa fa-check"></i><b>2</b> Fake-data Simulation</a></li>
<li class="chapter" data-level="3" data-path="prior-distributions-and-models-for-data.html"><a href="prior-distributions-and-models-for-data.html"><i class="fa fa-check"></i><b>3</b> Prior Distributions and Models for Data</a></li>
<li class="chapter" data-level="4" data-path="some-self-contained-examples.html"><a href="some-self-contained-examples.html"><i class="fa fa-check"></i><b>4</b> Some Self-Contained Examples</a></li>
<li class="chapter" data-level="5" data-path="workflow-in-action.html"><a href="workflow-in-action.html"><i class="fa fa-check"></i><b>5</b> Workflow in Action</a></li>
<li class="chapter" data-level="6" data-path="modeling-as-software-development.html"><a href="modeling-as-software-development.html"><i class="fa fa-check"></i><b>6</b> Modeling as Software Development</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 2. Example Models</i></span></a></li>
<li class="chapter" data-level="7" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>7</b> Regression Models</a></li>
<li class="chapter" data-level="8" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>8</b> Time-Series Models</a></li>
<li class="chapter" data-level="9" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>9</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="10" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>10</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="11" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>11</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="12" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>12</b> Finite Mixtures</a></li>
<li class="chapter" data-level="13" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>13</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="14" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>14</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="15" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>15</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="16" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>16</b> Clustering Models</a></li>
<li class="chapter" data-level="17" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>17</b> Gaussian Processes</a></li>
<li class="chapter" data-level="18" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>18</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="19" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>19</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="20" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>20</b> Ordinary Differential Equations</a></li>
<li><a href="part-3-programming-techniques.html#part-3.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 3. Programming Techniques</i></a></li>
<li class="chapter" data-level="21" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>21</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="22" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>22</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="23" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>23</b> User-Defined Functions</a></li>
<li class="chapter" data-level="24" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>24</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="25" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>25</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="26" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>26</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="27" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>27</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="28" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>28</b> Map-Reduce</a></li>
<li><a href="part-4-review-of-statistical-inference.html#part-4-review-of-statistical-inference"><i style="font-size: 110%; color:#990017;">Part 4: Review of Statistical Inference</i></a></li>
<li class="chapter" data-level="29" data-path="bayesian-data-analysis-1.html"><a href="bayesian-data-analysis-1.html"><i class="fa fa-check"></i><b>29</b> Bayesian Data Analysis</a></li>
<li class="chapter" data-level="30" data-path="mle-chapter.html"><a href="mle-chapter.html"><i class="fa fa-check"></i><b>30</b> Penalized Maximum Likelihood Point Estimation</a></li>
<li class="chapter" data-level="31" data-path="bayesian-point-estimation.html"><a href="bayesian-point-estimation.html"><i class="fa fa-check"></i><b>31</b> Bayesian Point Estimation</a></li>
<li class="chapter" data-level="32" data-path="vi-advanced-chapter.html"><a href="vi-advanced-chapter.html"><i class="fa fa-check"></i><b>32</b> Variational Inference</a></li>
<li><a href="appendices.html#appendices"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="" data-path="appendix-1-stan-program-style-guide.html"><a href="appendix-1-stan-program-style-guide.html"><i class="fa fa-check"></i>Appendix 1. Stan Program Style Guide</a></li>
<li class="chapter" data-level="" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i>Appendix 2. Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics Using Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stan-for-bugs.appendix" class="section level1 unnumbered">
<h1>Appendix 2. Transitioning from BUGS</h1>
<p>From the outside, Stan and BUGS<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a>
are similar—they use statistically-themed modeling languages
(which are similar but with some differences; see below), they can be
called from R, running some specified number of chains to some
specified length, producing posterior simulations that can be assessed
using standard convergence diagnostics. This is not a coincidence:
in designing Stan: we wanted to keep many of the useful features of
Bugs.</p>
<p>To start, take a look at the files of translated BUGS models at
. These are 40 or so models from the BUGS
example volumes, all translated and tested (to provide the same
answers as BUGS) in Stan. For any particular model you want to fit,
you can look for similar structures in these examples.</p>
<div id="some-differences-in-how-bugs-and-stan-work" class="section level2">
<h2><span class="header-section-number">32.12</span> Some Differences in How BUGS and Stan Work</h2>
<ul>
<li>BUGS is interpreted; Stan is compiled in two steps, first a
model is translated to templated C++ and then to a
platform-specific executable. Stan, unlike BUGS, allows the user
to directly program in C++, but we do not describe how to do this in
this Stan manual (see the getting started with C++ section of
 for more information on using Stan directly
from C++).</li>
<li>BUGS performs MCMC updating one scalar parameter at a time
(with some exceptions such as JAGS’s implementation of regression
and generalized linear models and some conjugate multivariate
parameters), using conditional distributions (Gibbs sampling) where
possible and otherwise using adaptive rejection sampling, slice
sampling, and Metropolis jumping. BUGS figures out the dependence
structure of the joint distribution as specified in its modeling
language and uses this information to compute only what it needs at
each step. Stan moves in the entire space of all the parameters
using Hamiltonian Monte Carlo (more precisely, the no-U-turn
sampler), thus avoiding some difficulties that occur with
one-dimension-at-a-time sampling in high dimensions but at the cost
of requiring the computation of the entire log density at each step.</li>
<li>BUGS tunes its adaptive jumping (if necessary) during its
warmup phase (traditionally referred to as “burn-in”). Stan uses
its warmup phase to tune the no-U-turn sampler (NUTS).</li>
<li>The BUGS modeling language is not directly executable. Rather,
BUGS parses its model to determine the posterior density and then
decides on a sampling scheme. In contrast, the statements in a Stan
model are directly executable: they translate exactly into C++ code
that is used to compute the log posterior density (which in turn is
used to compute the gradient).</li>
<li>In BUGS, the order in which statements are written does not
matter. They are executed according to the directed graphical model
so that variables are always defined when needed. A side effect of
the direct execution of Stan’s modeling language is that statements
execute in the order in which they are written. For instance, the
following Stan program, which sets <code>mu</code> before using it to
sample <code>y</code>.</li>
</ul>
<pre><code>mu = a + b * x;
y ~ normal(mu,sigma);</code></pre>
<p>It translates to the following C++ code.</p>
<pre><code>mu = a + b * x;
lp += normal_log(mu,sigma);</code></pre>
<p>Contrast this with the Stan program</p>
<pre><code>y ~ normal(mu,sigma)
mu = a + b * x</code></pre>
<p>This program is well formed, but is almost certainly
a coding error, because it attempts to use <code>mu</code> before
it is set. It translates to the following C++ code.</p>
<pre><code>lp += normal_log(mu,sigma);
mu = a + b * x;</code></pre>
<p>The direct translation to the imperative language of C++ code
highlights the potential error of using <code>mu</code> in the first
statement.
\[8pt]
To trap these kinds of errors, variables are initialized to the
special not-a-number (<code>NaN</code>) value. If <code>NaN</code> is passed to a
log probability function, it will raise a domain exception, which will
in turn be reported by the sampler. The sampler will reject the
sample out of hand as if it had zero probability.</p>
<ul>
<li>Stan uses its own C++ algorithmic differentiation packages to
compute the gradient of the log density (up to a proportion).
Gradients are required during the Hamiltonian dynamics simulations
within the leapfrog algorithm of the Hamiltonian Monte Carlo and
NUTS samplers. BUGS computes the log density but not its
gradient.</li>
<li>Both BUGS and Stan are semi-automatic in that they run by
themselves with no outside tuning required. Nevertheless, the user
needs to pick the number of chains and number of iterations per
chain. We usually pick 4 chains and start with 10 iterations per
chain (to make sure there are no major bugs and to approximately
check the timing), then go to 100, 1000, or more iterations as
necessary. Compared to Gibbs or Metropolis, Hamiltonian Monte Carlo
can take longer per iteration (as it typically takes many “leapfrog
steps” within each iteration), but the iterations typically have lower
autocorrelation. So Stan might work fine with 1000 iterations in an
example where BUGS would require 100,000 for good mixing. We
recommend monitoring potential scale reduction statistics (<span class="math inline">\(\hat{R}\)</span>)
and the effective sample size to judge when to stop (stopping when
<span class="math inline">\(\hat{R}\)</span> values do not counter-indicate convergence and when enough
effective samples have been collected).</li>
<li>WinBUGS is closed source. OpenBUGS and JAGS are both licensed
under the Gnu Public License (GPL), otherwise known as copyleft due
to the restrictions it places on derivative works. Stan is licensed
under the much more liberal new BSD license.</li>
<li>Like WinBUGS, OpenBUGS and JAGS, Stan can be run directly from
the command line or through common analytics platforms like R,
Python, Julia, MATLAB, Mathematica, and the command line.</li>
<li>Like OpenBUGS and JAGS, Stan can be run on Linux, Mac, and
Windows platforms.</li>
</ul>
</div>
<div id="some-differences-in-the-modeling-languages" class="section level2">
<h2><span class="header-section-number">32.13</span> Some Differences in the Modeling Languages</h2>
<ul>
<li>The BUGS modeling language follows an R-like syntax in which
line breaks are meaningful. Stan follows the rules of C, in which
line breaks are equivalent to spaces, and each statement ends in a
semicolon. For example:</li>
</ul>
<pre><code>y ~ normal(mu, sigma);</code></pre>
<p>and</p>
<pre><code>for (i in 1:n) y[i] ~ normal(mu, sigma);</code></pre>
<p>Or, equivalently (recall that a line break is just another form of whitespace),</p>
<pre><code>for (i in 1:n)
  y[i] ~ normal(mu, sigma);</code></pre>
<p>and also equivalently,</p>
<pre><code>for (i in 1:n) {
  y[i] ~ normal(mu, sigma);
}</code></pre>
<p>There’s a semicolon after the model statement but not after the
brackets indicating the body of the for loop.</p>
<ul>
<li><p>Another C thing: In Stan, variables can have names constructed
using letters, numbers, and the underscore (<code>_</code>) symbol, but
nothing else (and a variable name cannot begin with a number).
BUGS variables can also include the dot, or period (<code>.</code>) symbol.</p></li>
<li><p>In Stan, the second argument to the “normal” function is the
standard deviation (i.e., the scale), not the variance (as in {}) and not the inverse-variance (i.e.,
precision) (as in BUGS). Thus a normal with mean 1 and standard
deviation 2 is <code>normal(1,2)</code>, not <code>normal(1,4)</code> or
<code>normal(1,0.25)</code>.</p></li>
<li><p>Similarly, the second argument to the “multivariate normal”
function is the covariance matrix and not the inverse covariance matrix
(i.e., the precision matrix) (as in BUGS). The same is true for
the “multivariate student” distribution.</p></li>
<li><p>The distributions have slightly different names:
| BUGS | Stan |
|:——–:|:————:|
| <code>dnorm</code> | <code>normal</code> |
| <code>dbinom</code> | <code>binomial</code> |
| <code>dpois</code> | <code>poisson</code> |
| … | … |</p></li>
<li>Stan, unlike BUGS, allows intermediate quantities, in the form
of local variables, to be reassigned. For example, the following is
legal and meaningful (if possibly inefficient) Stan code.</li>
</ul>
<pre><code>{
  total = 0;
  for (i in 1:n){
    theta[i] ~ normal(total, sigma);
    total = total + theta[i];
  }
}</code></pre>
<p>In BUGS, the above model would not be legal because the variable
<code>total</code> is defined more than once. But in Stan, the loop is
executed in order, so <code>total</code> is overwritten in each step.</p>
<ul>
<li><p>Stan uses explicit declarations. Variables are declared with
base type integer or real, and vectors, matrices, and arrays have
specified dimensions. When variables are bounded, we give that
information also. For data and transformed parameters, the bounds
are used for error checking. For parameters, the constraints
are critical to sampling as they determine the geometry over which
the Hamiltonian is simulated.</p></li>
<li><p>In Stan, variables can be declared as data, transformed data,
parameters, transformed parameters, or generated quantities. They
can also be declared as local variables within blocks. For more
information, see the part of this manual devoted to the Stan
programming language and examine at the example models.</p></li>
<li>Stan allows all sorts of tricks with vector and matrix operations
which can make Stan models more compact. For example, arguments to
probability functions may be vectorized,<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a>
allowing</li>
</ul>
<pre><code>for (i in 1:n)
  y[i] ~ normal(mu[i], sigma[i]);</code></pre>
<p>to be expressed more compactly as</p>
<pre><code>y ~ normal(mu, sigma);</code></pre>
<p>The vectorized form is also more efficient because Stan can unfold the
computation of the chain rule during algorithmic differentiation.</p>
<ul>
<li>Stan also allows for arrays of vectors and matrices.
For example, in a hierarchical model might have a vector of <code>K</code>
parameters for each of <code>J</code> groups; this can be declared using</li>
</ul>
<pre><code>vector[K] theta[J];</code></pre>
<p>Then <code>theta[j]</code> is an expression denoting a <code>K</code>-vector and
may be used in the code just like any other vector variable.</p>
<p>An alternative encoding would be with a two-dimensional array, as in</p>
<pre><code>real theta[J,K];</code></pre>
<p>The vector version can have some advantages, both in convenience and
in computational speed for some operations.
\[6pt]
A third encoding would use a matrix:</p>
<pre><code>matrix[J,K] theta;</code></pre>
<p>but in this case, <code>theta[j]</code> is a row vector, not a vector, and
accessing it as a vector is less efficient than with an array of
vectors. The transposition operator, as in <code>theta[j]'</code>, may be
used to convert the row vector <code>theta[j]</code> to a (column) vector.
Column vector and row vector types are not interchangeable everywhere
in Stan; see the function signature declarations in the programming
language section of this manual.</p>
<ul>
<li><p>Stan supports general conditional statements using a standard
if-else syntax. For example, a zero-inflated (or -deflated) Poisson
mixture model is defined using the if-else syntax as described in
the <a href="mixture-modeling-chapter.html#zero-inflated.section">zero inflation section</a>.</p></li>
<li><p>Stan supports general while loops using a standard syntax.
While loops give Stan full Turing equivalent computational power.
They are useful for defining iterative functions with complex
termination conditions. As an illustration of their syntax,
the for-loop</p></li>
</ul>
<pre><code>model {
    ....
    for (n in 1:N) {
        ... do something with n ....
    }
}</code></pre>
<p>may be recoded using the following while loop.</p>
<pre><code>model {
    int n;
    ...
    n = 1;
    while (n &lt;= N) {
        ... do something with n ...
        n = n + 1;
    }
}</code></pre>
</div>
<div id="some-differences-in-the-statistical-models-that-are-allowed" class="section level2">
<h2><span class="header-section-number">32.14</span> Some Differences in the Statistical Models that are Allowed</h2>
<ul>
<li><p>Stan does not yet support declaration of discrete parameters.
Discrete data variables are supported. Inference is supported
for discrete parameters as described in the mixture and latent
discrete parameters chapters of the manual.</p></li>
<li><p>Stan has some distributions on covariance matrices that do not
exist in BUGS, including a uniform distribution over correlation
matrices which may be rescaled, and the priors based on C-vines
defined in <span class="citation">Lewandowski, Kurowicka, and Joe (<a href="#ref-LewandowskiKurowickaJoe:2009">2009</a>)</span>. In particular, the
Lewandowski et al. prior allows the correlation matrix to be shrunk
toward the unit matrix while the scales are given independent priors.</p></li>
<li>In BUGS you need to define all variables. In Stan, if you
declare but don’t define a parameter it implicitly has a flat prior
(on the scale in which the parameter is defined). For example, if
you have a parameter <code>p</code> declared as</li>
</ul>
<pre><code>real&lt;lower = 0, upper = 1&gt; p;</code></pre>
<p>and then have no sampling statement for <code>p</code> in the <code>model</code>
block, then you are implicitly assigning a uniform <span class="math inline">\([0,1]\)</span> prior on
<code>p</code>.</p>
<p>On the other hand, if you have a parameter <code>theta</code> declared with</p>
<pre><code>real theta;</code></pre>
<p>and have no sampling statement for <code>theta</code> in the <code>model</code> block, then
you are implicitly assigning an improper uniform prior on
<span class="math inline">\((-\infty,\infty)\)</span> to <code>theta</code>.</p>
<ul>
<li>BUGS models are always proper (being constructed as a product
of proper marginal and conditional densities). Stan models can be
improper. Here is the simplest improper Stan model:</li>
</ul>
<pre><code>parameters {
  real theta;
}
model { }</code></pre>
<ul>
<li><p>Although parameters in Stan models may have improper priors, we
do not want improper <em>posterior</em> distributions, as we are trying to
use these distributions for Bayesian inference. There is no general
way to check if a posterior distribution is improper. But if all
the priors are proper, the posterior will be proper also.</p></li>
<li>Each statement in a Stan model is directly translated into the C++ code for
computing the log posterior. Thus, for example, the following pair of statements is
legal in a Stan model:</li>
</ul>
<pre><code>y ~ normal(0,1);
y ~ normal(2,3);</code></pre>
<p>The second line here does <em>not</em> simply overwrite the first;
rather, <em>both</em> statements contribute to the density function that
is evaluated. The above two lines have the effect of including the
product, <span class="math inline">\(\mathsf{normal}(y|0,1) * \mathsf{normal}(y|2,3)\)</span>, into the
density function.</p>
<p>For a perhaps more confusing example, consider the following two lines in a Stan model:</p>
<pre><code>x ~ normal(0.8 * y, sigma);
y ~ normal(0.8 * x, sigma);</code></pre>
<p>At first, this might look like a joint normal distribution with a
correlation of 0.8. But it is not. The above are <em>not</em> interpreted
as conditional entities; rather, they are factors in the joint
density. Multiplying them gives, <span class="math inline">\(\mathsf{normal}(x|0.8y,\sigma) \times \mathsf{normal}(y|0.8x,\sigma)\)</span>, which is what it is (you can
work out the algebra) but it is not the joint distribution where the
conditionals have regressions with slope 0.8.</p>
<ul>
<li><p>With censoring and truncation, Stan uses the censored-data or
truncated-data likelihood—this is not always done in BUGS. All of
the approaches to censoring and truncation discussed in
<span class="citation">Gelman et al. (<a href="#ref-GelmanEtAl:2013">2013</a>)</span> and <span class="citation">Gelman and Hill (<a href="#ref-GelmanHill:2007">2007</a>)</span> may be implemented in Stan
directly as written.</p></li>
<li><p>Stan, like BUGS, can benefit from human intervention in the
form of reparameterization. More on this topic to come.</p></li>
</ul>
</div>
<div id="some-differences-when-running-from-r" class="section level2">
<h2><span class="header-section-number">32.15</span> Some Differences when Running from R</h2>
<ul>
<li><p>Stan can be set up from within R using two lines of code.
Follow the instructions for running Stan from R on the
<a href="http://mc-stan.org">Stan web site</a>. You don’t need to separately download
Stan and RStan. Installing RStan will automatically set up Stan.
When RStan moves to CRAN, it will get even easier.</p></li>
<li><p>In practice we typically run the same Stan model repeatedly. If
you pass RStan the result of a previously fitted model the model will
not need be recompiled. An example is given on the running
Stan from R pages available from the <a href="http://mc-stan.org">Stan web site</a>.</p></li>
<li><p>When you run Stan, it saves various conditions including
starting values, some control variables for the tuning and running
of the no-U-turn sampler, and the initial random seed. You can
specify these values in the Stan call and thus achieve exact
replication if desired. (This can be useful for debugging.)</p></li>
<li><p>When running BUGS from R, you need to send exactly the data
that the model needs. When running RStan, you can include extra
data, which can be helpful when playing around with models. For
example, if you remove a variable <code>x</code> from the model, you can keep
it in the data sent from R, thus allowing you to quickly alter the
Stan model without having to also change the calling information in
your R script.</p></li>
<li><p>As in R2WinBUGS and R2jags, after running the Stan model, you
can quickly summarize using <code>plot()</code> and <code>print()</code>. You
can access the simulations themselves using various extractor
functions, as described in the RStan documentation.</p></li>
<li><p>Various information about the sampler, such as number of
leapfrog steps, log probability, and step size, is available through
extractor functions. These can be useful for understanding what is
going wrong when the algorithm is slow to converge.</p></li>
</ul>
</div>
<div id="the-stan-community" class="section level2">
<h2><span class="header-section-number">32.16</span> The Stan Community</h2>
<ul>
<li>Stan, like WinBUGS, OpenBUGS, and JAGS, has an active community,
which you can access via the user’s mailing list and the developer’s
mailing list; see the <a href="http://mc-stan.org">Stan web site</a> for information on
subscribing and posting and to look at archives.</li>
</ul>

</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-LewandowskiKurowickaJoe:2009">
<p>Lewandowski, Daniel, Dorota Kurowicka, and Harry Joe. 2009. “Generating Random Correlation Matrices Based on Vines and Extended Onion Method.” <em>Journal of Multivariate Analysis</em> 100: 1989–2001.</p>
</div>
<div id="ref-GelmanEtAl:2013">
<p>Gelman, Andrew, J. B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third. London: Chapman &amp;Hall/CRC Press.</p>
</div>
<div id="ref-GelmanHill:2007">
<p>Gelman, Andrew, and Jennifer Hill. 2007. <em>Data Analysis Using Regression and Multilevel-Hierarchical Models</em>. Cambridge, United Kingdom: Cambridge University Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="56">
<li id="fn56"><p>Except where otherwise noted, we use “BUGS” to refer to WinBUGS, OpenBUGS, and JAGS, indiscriminately.<a href="stan-for-bugs-appendix.html#fnref56" class="footnote-back">↩</a></p></li>
<li id="fn57"><p>Most distributions have
been vectorized, but currently the truncated versions may not exist
and may not be vectorized.<a href="stan-for-bugs-appendix.html#fnref57" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="appendix-1-stan-program-style-guide.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
