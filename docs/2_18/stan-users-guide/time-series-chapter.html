<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Stan User’s Guide</title>
  <meta name="description" content="Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Stan User’s Guide" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stan User’s Guide" />
  
  <meta name="twitter:description" content="Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regression-models.html">
<link rel="next" href="missing-data-and-partially-known-parameters.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Stan User's Guide</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 1. Example Models</i></a></li>
<li class="chapter" data-level="1" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>1</b> Regression Models</a></li>
<li class="chapter" data-level="2" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>2</b> Time-Series Models</a></li>
<li class="chapter" data-level="3" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>3</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="4" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>4</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="5" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="6" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>6</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="7" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>7</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="8" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>8</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="9" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>9</b> Clustering Models</a></li>
<li class="chapter" data-level="10" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>10</b> Gaussian Processes</a></li>
<li class="chapter" data-level="11" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>11</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="12" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>12</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="13" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>13</b> Ordinary Differential Equations</a></li>
<li><a href="part-2-programming-techniques.html#part-2.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 2. Programming Techniques</i></a></li>
<li class="chapter" data-level="14" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>14</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="15" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>15</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="16" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>16</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="17" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>17</b> User-Defined Functions</a></li>
<li class="chapter" data-level="18" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>18</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="19" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>19</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="20" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>20</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="21" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>21</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="22" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>22</b> Map-Reduce</a></li>
<li><a href="appendices-part.html#appendices.part"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="23" data-path="stan-program-style-guide.html"><a href="stan-program-style-guide.html"><i class="fa fa-check"></i><b>23</b> Stan Program Style Guide</a></li>
<li class="chapter" data-level="24" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i><b>24</b> Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan User’s Guide</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="time-series.chapter" class="section level1">
<h1><span class="header-section-number">2</span> Time-Series Models</h1>
<p>Times series data come arranged in temporal order. This chapter
presents two kinds of time series models, regression-like models such
as autoregressive and moving average models, and hidden Markov models.</p>
<p>The <a href="gaussian-processes-chapter.html#gaussian-processes.chapter">Gaussian processes chapter</a> presents
Gaussian processes, which may also be used for time-series (and
spatial) data.</p>
<div id="autoregressive.section" class="section level2">
<h2><span class="header-section-number">2.1</span> Autoregressive Models</h2>
<p>A first-order autoregressive model (AR(1)) with normal noise takes
each point <span class="math inline">\(y_n\)</span> in a sequence <span class="math inline">\(y\)</span> to be generated according to</p>
<p><span class="math display">\[
y_n \sim \mathsf{normal}(\alpha + \beta y_{n-1}, \sigma).
\]</span></p>
<p>That is, the expected value of <span class="math inline">\(y_n\)</span> is <span class="math inline">\(\alpha + \beta y_{n-1}\)</span>, with
noise scaled as <span class="math inline">\(\sigma\)</span>.</p>
<div id="ar1-models" class="section level3 unnumbered">
<h3>AR(1) Models</h3>
<p>With improper flat priors on the regression coefficients <span class="math inline">\(\alpha\)</span> and
<span class="math inline">\(\beta\)</span> and on the positively-constrained noise scale (<span class="math inline">\(\sigma\)</span>), the
Stan program for the AR(1) model is as follows.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
}
parameters {
  real alpha;
  real beta;
  real&lt;lower=0&gt; sigma;
}
model {
  for (n in 2:N)
    y[n] ~ normal(alpha + beta * y[n-1], sigma);
}</code></pre>
<p>The first observed data point, <code>y[1]</code>, is not modeled here
because there is nothing to condition on; instead, it acts to
condition <code>y[2]</code>. This model also uses an improper prior for
<code>sigma</code>, but there is no obstacle to adding an informative prior
if information is available on the scale of the changes in <code>y</code>
over time, or a weakly informative prior to help guide inference if
rough knowledge of the scale of <code>y</code> is available.</p>
<div id="slicing-for-efficiency" class="section level4 unnumbered">
<h4>Slicing for Efficiency</h4>
<p>Although perhaps a bit more difficult to read, a much more efficient
way to write the above model is by slicing the vectors, with the model
above being replaced with the one-liner</p>
<pre><code>model {
  y[2:N] ~ normal(alpha + beta * y[1:(N - 1)], sigma);
}</code></pre>
<p>The left-hand side slicing operation pulls out the last <span class="math inline">\(N-1\)</span>
elements and the right-hand side version pulls out the first <span class="math inline">\(N-1\)</span>.</p>
</div>
</div>
<div id="extensions-to-the-ar1-model" class="section level3 unnumbered">
<h3>Extensions to the AR(1) Model</h3>
<p>Proper priors of a range of different families may be added for the
regression coefficients and noise scale. The normal noise model can
be changed to a Student-<span class="math inline">\(t\)</span> distribution or any other distribution
with unbounded support. The model could also be made hierarchical if
multiple series of observations are available.</p>
<p>To enforce the estimation of a stationary AR(1) process, the slope
coefficient <code>beta</code> may be constrained with bounds as follows.</p>
<pre><code>real&lt;lower=-1,upper=1&gt; beta;</code></pre>
<p>In practice, such a constraint is not recommended. If the data are not well fit by a
stationary model it is best to know this.
Stationary parameter estimates can be encouraged with a prior favoring
values of <code>beta</code> near zero.</p>
</div>
<div id="ar2-models" class="section level3 unnumbered">
<h3>AR(2) Models</h3>
<p>Extending the order of the model is also straightforward. For
example, an AR(2) model could be coded with the second-order
coefficient <code>gamma</code> and the following model statement.</p>
<pre><code>for (n in 3:N)
  y[n] ~ normal(alpha + beta*y[n-1] + gamma*y[n-2], sigma);</code></pre>
</div>
<div id="ark-models" class="section level3 unnumbered">
<h3>AR(<span class="math inline">\(K\)</span>) Models</h3>
<p>A general model where the order is itself given as data can be coded
by putting the coefficients in an array and computing the linear
predictor in a loop.</p>
<pre><code>data {
  int&lt;lower=0&gt; K;
  int&lt;lower=0&gt; N;
  real y[N];
}
parameters {
  real alpha;
  real beta[K];
  real sigma;
}
model {
  for (n in (K+1):N) {
    real mu = alpha;
    for (k in 1:K)
      mu += beta[k] * y[n-k];
    y[n] ~ normal(mu, sigma);
  }
}</code></pre>
</div>
<div id="arch1-models" class="section level3 unnumbered">
<h3>ARCH(1) Models</h3>
<p>Econometric and financial time-series models usually assume
heteroscedasticity: hey allow the scale of the noise terms
defining the series to vary over time.
The simplest such model is the autoregressive conditional
heteroscedasticity (ARCH) model <span class="citation">Engle (<a href="#ref-Engle:1982">1982</a>)</span>. Unlike the
autoregressive model AR(1), which modeled the mean of the series as
varying over time but left the noise term fixed, the ARCH(1) model
takes the scale of the noise terms to vary over time but leaves the
mean term fixed. Models could be defined where both the
mean and scale vary over time; the econometrics literature presents a
wide range of time-series modeling choices.</p>
<p>The ARCH(1) model is typically presented as the following sequence of
equations, where <span class="math inline">\(r_t\)</span> is the observed return at time point <span class="math inline">\(t\)</span>
and <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha_0\)</span>, and <span class="math inline">\(\alpha_1\)</span> are unknown regression coefficient parameters.</p>
<p><span class="math display">\[
\begin{array}{rcl}
r_t &amp; = &amp; \mu + a_t
\\[2pt]
a_t &amp; = &amp; \sigma_t \epsilon_t
\\[2pt]
\epsilon_t &amp; \sim &amp; \mathsf{normal}(0,1)
\\[2pt]
\sigma^2_t &amp; = &amp; \alpha_0 + \alpha_1 a_{t-1}^2
\end{array}
\]</span></p>
<p>In order to ensure the noise terms <span class="math inline">\(\sigma^2_t\)</span> are positive, the
scale coefficients are constrained to be positive, <span class="math inline">\(\alpha_0, \alpha_1 &gt; 0\)</span>. To ensure stationarity of the time series, the slope is
constrained to to be less than one, i.e., <span class="math inline">\(\alpha_1 &lt; 1\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>The ARCH(1) model may be coded directly in Stan as follows.</p>
<pre><code>data {
  int&lt;lower=0&gt; T;   // number of time points
  real r[T];        // return at time t
}
parameters {
  real mu;                       // average return
  real&lt;lower=0&gt; alpha0;          // noise intercept
  real&lt;lower=0,upper=1&gt; alpha1;  // noise slope
}
model {
  for (t in 2:T)
    r[t] ~ normal(mu, sqrt(alpha0 + alpha1 * pow(r[t-1] - mu,2)));
}</code></pre>
<p>The loop in the model is defined so that the return at time <span class="math inline">\(t=1\)</span> is
not modeled; the model in the next section shows how to model the
return at <span class="math inline">\(t=1\)</span>. The model can be vectorized to be more efficient;
the model in the next section provides an example.</p>
</div>
</div>
<div id="modeling-temporal-heteroscedasticity" class="section level2">
<h2><span class="header-section-number">2.2</span> Modeling Temporal Heteroscedasticity</h2>
<p>A set of variables is homoscedastic if their variances are all the
same; the variables are heteroscedastic if they do not all have the
same variance. Heteroscedastic time-series models allow the noise
term to vary over time.</p>
<div id="garch11-models" class="section level3 unnumbered">
<h3>GARCH(1,1) Models</h3>
<p>The basic generalized autoregressive conditional heteroscedasticity
(GARCH) model, GARCH(1,1), extends the ARCH(1) model by including the
squared previous difference in return from the mean at time <span class="math inline">\(t-1\)</span> as a
predictor of volatility at time <span class="math inline">\(t\)</span>, defining</p>
<p><span class="math display">\[
\sigma^2_t = \alpha_0 + \alpha_1 a^2_{t-1} + \beta_1 \sigma^2_{t-1}.
\]</span></p>
<p>To ensure the scale term is positive and the resulting time series
stationary, the coefficients must all satisfy <span class="math inline">\(\alpha_0, \alpha_1, \beta_1 &gt; 0\)</span> and the slopes <span class="math inline">\(\alpha_1 + \beta_1 &lt; 1\)</span>.</p>
<pre><code>data {
  int&lt;lower=0&gt; T;
  real r[T];
  real&lt;lower=0&gt; sigma1;
}
parameters {
  real mu;
  real&lt;lower=0&gt; alpha0;
  real&lt;lower=0,upper=1&gt; alpha1;
  real&lt;lower=0,upper=(1-alpha1)&gt; beta1;
}
transformed parameters {
  real&lt;lower=0&gt; sigma[T];
  sigma[1] = sigma1;
  for (t in 2:T)
    sigma[t] = sqrt(alpha0
                     + alpha1 * pow(r[t-1] - mu, 2)
                     + beta1 * pow(sigma[t-1], 2));
}
model {
  r ~ normal(mu, sigma);
}</code></pre>
<p>To get the recursive definition of the volatility regression off the
ground, the data declaration includes a non-negative value
<code>sigma1</code> for the scale of the noise at <span class="math inline">\(t = 1\)</span>.</p>
<p>The constraints are coded directly on the parameter declarations.
This declaration is order-specific in that the constraint on <code>beta1</code>
depends on the value of <code>alpha1</code>.</p>
<p>A transformed parameter array of non-negative values <code>sigma</code> is
used to store the scale values at each time point. The definition of
these values in the transformed parameters block is where the
regression is now defined. There is an intercept <code>alpha0</code>, a
slope <code>alpha1</code> for the squared difference in return from the mean
at the previous time, and a slope <code>beta1</code> for the previous noise
scale squared. Finally, the whole regression is inside the
<code>sqrt</code> function because Stan requires scale (deviation) parameters (not
variance parameters) for the normal distribution.</p>
<p>With the regression in the transformed parameters block, the model
reduces a single vectorized sampling statement. Because <code>r</code> and
<code>sigma</code> are of length <code>T</code>, all of the data are modeled
directly.</p>
</div>
</div>
<div id="moving-average-models" class="section level2">
<h2><span class="header-section-number">2.3</span> Moving Average Models</h2>
<p>A moving average model uses previous errors as predictors for future
outcomes. For a moving average model of order <span class="math inline">\(Q\)</span>, <span class="math inline">\(\mbox{MA}(Q)\)</span>,
there is an overall mean parameter <span class="math inline">\(\mu\)</span> and regression coefficients
<span class="math inline">\(\theta_q\)</span> for previous error terms. With <span class="math inline">\(\epsilon_t\)</span> being the
noise at time <span class="math inline">\(t\)</span>, the model for outcome <span class="math inline">\(y_t\)</span> is defined by
<span class="math display">\[
y_t = \mu + \theta_1 \epsilon_{t-1} + \cdots + \theta_Q \epsilon_{t-Q}
+ \epsilon_t,
\]</span>
with the noise term <span class="math inline">\(\epsilon_t\)</span> for outcome <span class="math inline">\(y_t\)</span> modeled as
normal,
<span class="math display">\[
\epsilon_t \sim \mathsf{normal}(0,\sigma).
\]</span>
In a proper Bayesian model, the parameters <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\theta\)</span>, and
<span class="math inline">\(\sigma\)</span> must all be given priors.</p>
<div id="ma2-example" class="section level3 unnumbered">
<h3>MA(2) Example</h3>
<p>An <span class="math inline">\(\mbox{MA}(2)\)</span> model can be coded in Stan as follows.</p>
<pre><code>data {
  int&lt;lower=3&gt; T;  // number of observations
  vector[T] y;     // observation at time T
}
parameters {
  real mu;              // mean
  real&lt;lower=0&gt; sigma;  // error scale
  vector[2] theta;      // lag coefficients
}
transformed parameters {
  vector[T] epsilon;    // error terms
  epsilon[1] = y[1] - mu;
  epsilon[2] = y[2] - mu - theta[1] * epsilon[1];
  for (t in 3:T)
    epsilon[t] = ( y[t] - mu
                    - theta[1] * epsilon[t - 1]
                    - theta[2] * epsilon[t - 2] );
}
model {
  mu ~ cauchy(0, 2.5);
  theta ~ cauchy(0, 2.5);
  sigma ~ cauchy(0, 2.5);
  for (t in 3:T)
    y[t] ~ normal(mu
                  + theta[1] * epsilon[t - 1]
                  + theta[2] * epsilon[t - 2],
                  sigma);
}</code></pre>
<p>The error terms <span class="math inline">\(\epsilon_t\)</span> are defined as transformed parameters in
terms of the observations and parameters. The definition of the
sampling statement (defining the likelihood) follows the definition,
which can only be applied to <span class="math inline">\(y_n\)</span> for <span class="math inline">\(n &gt; Q\)</span>. In this example, the
parameters are all given Cauchy (half-Cauchy for <span class="math inline">\(\sigma\)</span>) priors,
although other priors can be used just as easily.</p>
<p>This model could be improved in terms of speed by vectorizing the
sampling statement in the model block. Vectorizing the calculation of
the <span class="math inline">\(\epsilon_t\)</span> could also be sped up by using a dot product instead
of a loop.</p>
</div>
<div id="vectorized-maq-model" class="section level3 unnumbered">
<h3>Vectorized MA(Q) Model}</h3>
<p>A general <span class="math inline">\(\mbox{MA}(Q)\)</span> model with a vectorized sampling probability
may be defined as follows.</p>
<pre><code>data {
  int&lt;lower=0&gt; Q;  // num previous noise terms
  int&lt;lower=3&gt; T;  // num observations
  vector[T] y;     // observation at time t
}
parameters {
  real mu;              // mean
  real&lt;lower=0&gt; sigma;  // error scale
  vector[Q] theta;      // error coeff, lag -t
}
transformed parameters {
  vector[T] epsilon;    // error term at time t
  for (t in 1:T) {
    epsilon[t] = y[t] - mu;
    for (q in 1:min(t - 1, Q))
      epsilon[t] = epsilon[t] - theta[q] * epsilon[t - q];
  }
}
model {
  vector[T] eta;
  mu ~ cauchy(0, 2.5);
  theta ~ cauchy(0, 2.5);
  sigma ~ cauchy(0, 2.5);
  for (t in 1:T) {
    eta[t] = mu;
    for (q in 1:min(t - 1, Q))
      eta[t] = eta[t] + theta[q] * epsilon[t - q];
  }
  y ~ normal(eta, sigma);
}</code></pre>
<p>Here all of the data are modeled, with missing terms just dropped from
the regressions as in the calculation of the error terms. Both models
converge quickly and mix well at convergence, with the
vectorized model being faster (per iteration, not to
converge — they compute the same model).</p>
</div>
</div>
<div id="autoregressive-moving-average-models" class="section level2">
<h2><span class="header-section-number">2.4</span> Autoregressive Moving Average Models</h2>
<p>Autoregressive moving-average models (ARMA), combine the predictors
of the autoregressive model and the moving average model. An
ARMA(1,1) model, with a single state of history, can be encoded in
Stan as follows.</p>
<pre><code>data {
  int&lt;lower=1&gt; T;            // num observations
  real y[T];                 // observed outputs
}
parameters {
  real mu;                   // mean coeff
  real phi;                  // autoregression coeff
  real theta;                // moving avg coeff
  real&lt;lower=0&gt; sigma;       // noise scale
}
model {
  vector[T] nu;              // prediction for time t
  vector[T] err;             // error for time t
  nu[1] = mu + phi * mu;    // assume err[0] == 0
  err[1] = y[1] - nu[1];
  for (t in 2:T) {
    nu[t] = mu + phi * y[t-1] + theta * err[t-1];
    err[t] = y[t] - nu[t];
  }
  mu ~ normal(0, 10);         // priors
  phi ~ normal(0, 2);
  theta ~ normal(0, 2);
  sigma ~ cauchy(0, 5);
  err ~ normal(0, sigma);    // likelihood
}</code></pre>
<p>The data are declared in the same way as the other time-series
regressions and the parameters are documented in the code.</p>
<p>In the model block, the local vector <code>nu</code> stores the predictions
and <code>err</code> the errors. These are computed similarly to the
errors in the moving average models described in the previous section.</p>
<p>The priors are weakly informative for stationary processes. The
likelihood only involves the error term, which is efficiently
vectorized here.</p>
<p>Often in models such as these, it is desirable to inspect the
calculated error terms. This could easily be accomplished in Stan by
declaring <code>err</code> as a transformed parameter, then defining it the
same way as in the model above. The vector <code>nu</code> could still be a
local variable, only now it will be in the transformed parameter block.</p>
<p>Wayne Folta suggested encoding the model without local vector
variables as follows.</p>
<pre><code>model {
  real err;
  mu ~ normal(0, 10);
  phi ~ normal(0, 2);
  theta ~ normal(0, 2);
  sigma ~ cauchy(0, 5);
  err = y[1] - mu + phi * mu;
  err ~ normal(0, sigma);
  for (t in 2:T) {
    err = y[t] - (mu + phi * y[t-1] + theta * err);
    err ~ normal(0, sigma);
  }
}</code></pre>
<p>This approach to ARMA models illustrates how local
variables, such as <code>err</code> in this case, can be reused in Stan.
Folta’s approach could be extended to higher order moving-average
models by storing more than one error term as a local variable and
reassigning them in the loop.</p>
<p>Both encodings are fast. The original encoding has the advantage
of vectorizing the normal distribution, but it uses a bit more memory.
A halfway point would be to vectorize just <code>err</code>.</p>
<div id="identifiability-and-stationarity" class="section level3 unnumbered">
<h3>Identifiability and Stationarity</h3>
<p>MA and ARMA models are not identifiable if the roots of the
characteristic polynomial for the MA part lie inside the unit circle,
so it’s necessary to add the following constrain<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<pre><code>real&lt;lower = -1, upper = 1&gt; theta;</code></pre>
<p>When the model is run without the constraint, using synthetic data
generated from the model, the simulation can sometimes find modes for
(<code>theta</code>, <code>phi</code>) outside the <span class="math inline">\([-1,1]\)</span> interval, which
creates a multiple mode problem in the posterior and also causes the
NUTS tree depth to get large (often above 10). Adding the
constraint both improves the accuracy of the posterior and
dramatically reduces the tree depth, which speeds up the simulation
considerably (typically by much more than an order of magnitude).</p>
<p>Further, unless one thinks that the process is really non-stationary,
it’s worth adding the following constraint to ensure stationarity.</p>
<pre><code>real&lt;lower = -1, upper = 1&gt; phi;</code></pre>
</div>
</div>
<div id="stochastic-volatility-models" class="section level2">
<h2><span class="header-section-number">2.5</span> Stochastic Volatility Models</h2>
<p>Stochastic volatility models treat the volatility (i.e., variance) of
a return on an asset, such as an option to buy a security, as
following a latent stochastic process in discrete time
<span class="citation">Kim, Shephard, and Chib (<a href="#ref-KimShephardChib:1998">1998</a>)</span>. The data consist of mean corrected
(i.e., centered) returns <span class="math inline">\(y_t\)</span> on an underlying asset at <span class="math inline">\(T\)</span> equally
spaced time points. Kim et al. formulate a typical stochastic
volatility model using the following regression-like equations, with a
latent parameter <span class="math inline">\(h_t\)</span> for the log volatility, along with parameters
<span class="math inline">\(\mu\)</span> for the mean log volatility, and <span class="math inline">\(\phi\)</span> for the persistence of
the volatility term. The variable <span class="math inline">\(\epsilon_t\)</span> represents the
white-noise shock (i.e., multiplicative error) on the asset return at
time <span class="math inline">\(t\)</span>, whereas <span class="math inline">\(\delta_t\)</span> represents the shock on volatility at
time <span class="math inline">\(t\)</span>.
<span class="math display">\[
y_t = \epsilon_t \exp(h_t / 2),
\]</span>
<span class="math display">\[
h_{t+1} = \mu + \phi (h_t - \mu) + \delta_t \sigma
\]</span>
<span class="math display">\[
h_1 \sim \mathsf{normal}\left( \mu, \frac{\sigma}{\sqrt{1 - \phi^2}} \right)
\]</span>
<span class="math display">\[
\epsilon_t \sim \mathsf{normal}(0,1); \ \ \ \ \  \delta_t \sim \mathsf{normal}(0,1)
\]</span></p>
<p>Rearranging the first line, <span class="math inline">\(\epsilon_t = y_t \exp(-h_t / 2)\)</span>,
allowing the sampling distribution for <span class="math inline">\(y_t\)</span> to be written as
<span class="math display">\[
y_t \sim \mathsf{normal}(0,\exp(h_t/2)).
\]</span>
The recurrence equation for <span class="math inline">\(h_{t+1}\)</span> may be combined with the
scaling and sampling of <span class="math inline">\(\delta_t\)</span> to yield the sampling distribution
<span class="math display">\[
h_t \sim \mathsf{normal}(\mu + \phi(h_t - \mu), \sigma).
\]</span>
This formulation can be directly encoded, as shown in the following
Stan model.</p>
<pre><code>data {
  int&lt;lower=0&gt; T;   // # time points (equally spaced)
  vector[T] y;      // mean corrected return at time t
}
parameters {
  real mu;                     // mean log volatility
  real&lt;lower=-1,upper=1&gt; phi;  // persistence of volatility
  real&lt;lower=0&gt; sigma;         // white noise shock scale
  vector[T] h;                 // log volatility at time t
}
model {
  phi ~ uniform(-1, 1);
  sigma ~ cauchy(0, 5);
  mu ~ cauchy(0, 10);
  h[1] ~ normal(mu, sigma / sqrt(1 - phi * phi));
  for (t in 2:T)
    h[t] ~ normal(mu + phi * (h[t - 1] -  mu), sigma);
  for (t in 1:T)
    y[t] ~ normal(0, exp(h[t] / 2));
}</code></pre>
<p>Compared to the Kim et al. formulation, the Stan model adds priors
for the parameters <span class="math inline">\(\phi\)</span>, <span class="math inline">\(\sigma\)</span>, and <span class="math inline">\(\mu\)</span>. The shock
terms <span class="math inline">\(\epsilon_t\)</span> and <span class="math inline">\(\delta_t\)</span> do not appear explicitly in the
model, although they could be calculated efficiently in a generated
quantities block.</p>
<p>The posterior of a stochastic volatility model such as this one
typically has high posterior variance. For example, simulating 500
data points from the above model with <span class="math inline">\(\mu = -1.02\)</span>, <span class="math inline">\(\phi = 0.95\)</span>,
and <span class="math inline">\(\sigma = 0.25\)</span> leads to 95% posterior intervals for <span class="math inline">\(\mu\)</span> of
<span class="math inline">\((-1.23, -0.54)\)</span>, for <span class="math inline">\(\phi\)</span> of <span class="math inline">\((0.82,0.98 )\)</span> and for <span class="math inline">\(\sigma\)</span> of
<span class="math inline">\((0.16,0.38)\)</span>.</p>
<p>The samples using NUTS show a high degree of autocorrelation among the
samples, both for this model and the stochastic volatility model
evaluated in <span class="citation">(Hoffman and Gelman <a href="#ref-Hoffman-Gelman:2011">2011</a>, <a href="#ref-Hoffman-Gelman:2014">2014</a>)</span>.
Using a non-diagonal mass
matrix provides faster convergence and more effective samples than a
diagonal mass matrix, but will not scale to large values of <span class="math inline">\(T\)</span>.</p>
<p>It is relatively straightforward to speed up the effective samples per
second generated by this model by one or more orders of magnitude.
First, the sampling statements for return <span class="math inline">\(y\)</span> is easily vectorized to</p>
<pre><code>y ~ normal(0, exp(h / 2));</code></pre>
<p>This speeds up the iterations, but does not change the effective
sample size because the underlying parameterization and log
probability function have not changed. Mixing is improved by by
reparameterizing in terms of a standardized volatility, then
rescaling. This requires a standardized parameter <code>h_std</code> to be
declared instead of <code>h</code>.</p>
<pre><code>parameters {
  ...
  vector[T] h_std;             // std log volatility time t</code></pre>
<p>The original value of <code>h</code> is then defined in a transformed
parameter block.</p>
<pre><code>transformed parameters {
  vector[T] h = h_std * sigma;  // now h ~ normal(0, sigma)
  h[1] /= sqrt(1 - phi * phi);  // rescale h[1]
  h += mu;
  for (t in 2:T)
    h[t] += phi * (h[t-1] - mu);
}</code></pre>
<p>The first assignment rescales <code>h_std</code> to have a
<span class="math inline">\(\mathsf{normal}(0,\sigma)\)</span> distribution and temporarily assigns it to
<code>h</code>. The second assignment rescales <code>h[1]</code> so that its
prior differs from that of <code>h[2]</code> through <code>h[T]</code>. The next
assignment supplies a <code>mu</code> offset, so that <code>h[2]</code> through
<code>h[T]</code> are now distributed <span class="math inline">\(\mathsf{normal}(\mu,\sigma)\)</span>; note
that this shift must be done after the rescaling of <code>h[1]</code>. The
final loop adds in the moving average so that <code>h[2]</code> through
<code>h[T]</code> are appropriately modeled relative to <code>phi</code> and
<code>mu</code>.</p>
<p>As a final improvement, the sampling statement for <code>h[1]</code> and
loop for sampling <code>h[2]</code> to <code>h[T]</code> are replaced with a
single vectorized standard normal sampling statement.</p>
<pre><code>model {
  ...
  h_std ~ std_normal();</code></pre>
<p>Although the original model can take hundreds and sometimes thousands
of iterations to converge, the reparameterized model reliably
converges in tens of iterations. Mixing is also dramatically
improved, which results in higher effective sample sizes per
iteration. Finally, each iteration runs in roughly a quarter of the
time of the original iterations.</p>
</div>
<div id="hmms.section" class="section level2">
<h2><span class="header-section-number">2.6</span> Hidden Markov Models</h2>
<p>A hidden Markov model (HMM) generates a sequence of <span class="math inline">\(T\)</span> output
variables <span class="math inline">\(y_t\)</span> conditioned on a parallel sequence of latent
categorical state variables <span class="math inline">\(z_t \in \{1,\ldots, K\}\)</span>. These
``hidden&quot; state variables are assumed to form a Markov chain so that
<span class="math inline">\(z_t\)</span> is conditionally independent of other variables given <span class="math inline">\(z_{t-1}\)</span>.
This Markov chain is parameterized by a transition matrix <span class="math inline">\(\theta\)</span>
where <span class="math inline">\(\theta_k\)</span> is a <span class="math inline">\(K\)</span>-simplex for <span class="math inline">\(k \in \{1,\ldots, K\}\)</span>. The
probability of transitioning to state <span class="math inline">\(z_t\)</span> from state <span class="math inline">\(z_{t-1}\)</span> is
<span class="math display">\[
z_t \sim \mathsf{Categorical}(\theta_{z[t-1]}).
\]</span>
The output <span class="math inline">\(y_t\)</span> at time <span class="math inline">\(t\)</span> is generated conditionally independently
based on the latent state <span class="math inline">\(z_t\)</span>.</p>
<p>This section describes HMMs with a simple categorical model for
outputs <span class="math inline">\(y_t \in \{1,\ldots,V\}\)</span>. The categorical distribution for
latent state <span class="math inline">\(k\)</span> is parameterized by a <span class="math inline">\(V\)</span>-simplex <span class="math inline">\(\phi_k\)</span>. The
observed output <span class="math inline">\(y_t\)</span> at time <span class="math inline">\(t\)</span> is generated based on the hidden
state indicator <span class="math inline">\(z_t\)</span> at time <span class="math inline">\(t\)</span>,
<span class="math display">\[
y_t \sim \mathsf{Categorical}(\phi_{z[t]}).
\]</span>
In short, HMMs form a discrete mixture model where the mixture
component indicators form a latent Markov chain.</p>
<div id="supervised-parameter-estimation" class="section level3 unnumbered">
<h3>Supervised Parameter Estimation</h3>
<p>In the situation where the hidden states are known, the following
naive model can be used to fit the parameters <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>.</p>
<pre><code>data {
  int&lt;lower=1&gt; K;  // num categories
  int&lt;lower=1&gt; V;  // num words
  int&lt;lower=0&gt; T;  // num instances
  int&lt;lower=1,upper=V&gt; w[T]; // words
  int&lt;lower=1,upper=K&gt; z[T]; // categories
  vector&lt;lower=0&gt;[K] alpha;  // transit prior
  vector&lt;lower=0&gt;[V] beta;   // emit prior
}
parameters {
  simplex[K] theta[K];  // transit probs
  simplex[V] phi[K];    // emit probs
}
model {
  for (k in 1:K)
    theta[k] ~ dirichlet(alpha);
  for (k in 1:K)
    phi[k] ~ dirichlet(beta);
  for (t in 1:T)
    w[t] ~ categorical(phi[z[t]]);
  for (t in 2:T)
    z[t] ~ categorical(theta[z[t - 1]]);
}</code></pre>
<p>Explicit Dirichlet priors have been provided for <span class="math inline">\(\theta_k\)</span> and
<span class="math inline">\(\phi_k\)</span>; dropping these two statements would implicitly take the
prior to be uniform over all valid simplexes.</p>
</div>
<div id="start-state-and-end-state-probabilities" class="section level3 unnumbered">
<h3>Start-State and End-State Probabilities</h3>
<p>Although workable, the above description of HMMs is incomplete because
the start state <span class="math inline">\(z_1\)</span> is not modeled (the index runs from 2 to <span class="math inline">\(T\)</span>).
If the data are conceived as a subsequence of a long-running process,
the probability of <span class="math inline">\(z_1\)</span> should be set to the stationary state
probabilities in the Markov chain. In this case, there is no distinct
end to the data, so there is no need to model the probability that the
sequence ends at <span class="math inline">\(z_T\)</span>.</p>
<p>An alternative conception of HMMs is as models of finite-length
sequences. For example, human language sentences have distinct
starting distributions (usually a capital letter) and ending
distributions (usually some kind of punctuation). The simplest way to
model the sequence boundaries is to add a new latent state <span class="math inline">\(K+1\)</span>,
generate the first state from a categorical distribution with
parameter vector <span class="math inline">\(\theta_{K+1}\)</span>, and restrict the transitions so that
a transition to state <span class="math inline">\(K+1\)</span> is forced to occur at the end of the
sentence and is prohibited elsewhere.</p>
</div>
<div id="calculating-sufficient-statistics" class="section level3 unnumbered">
<h3>Calculating Sufficient Statistics</h3>
<p>The naive HMM estimation model presented above can be sped up
dramatically by replacing the loops over categorical distributions
with a single multinomial distribution.</p>
<p>The data are declared as before. The transformed data block
computes the sufficient statistics for estimating the transition and
emission matrices.</p>
<pre><code>transformed data {
  int&lt;lower=0&gt; trans[K, K];
  int&lt;lower=0&gt; emit[K, V];
  for (k1 in 1:K)
    for (k2 in 1:K)
      trans[k1, k2] = 0;
  for (t in 2:T)
    trans[z[t - 1], z[t]] += 1;
  for (k in 1:K)
    for (v in 1:V)
      emit[k,v] = 0;
  for (t in 1:T)
    emit[z[t], w[t]] += 1;
}</code></pre>
<p>The likelihood component of the model based on looping over the input
is replaced with multinomials as follows.</p>
<pre><code>model {
  ...
  for (k in 1:K)
    trans[k] ~ multinomial(theta[k]);
  for (k in 1:K)
    emit[k] ~ multinomial(phi[k]);
}</code></pre>
<p>In a continuous HMM with normal emission probabilities could be sped
up in the same way by computing sufficient statistics.</p>
</div>
<div id="analytic-posterior" class="section level3 unnumbered">
<h3>Analytic Posterior</h3>
<p>With the Dirichlet-multinomial HMM, the posterior can be computed analytically because the Dirichlet is the conjugate prior to the multinomial. The following example illustrates how a Stan model can define the posterior analytically. This is possible in the Stan language because the model only needs to define the conditional probability of the parameters given the data up to a proportion, which can be done by defining the (unnormalized) joint probability or the (unnormalized) conditional posterior, or anything in between.</p>
<p>The model has the same data and parameters as the previous models, but
now computes the posterior Dirichlet parameters in the transformed
data block.</p>
<pre><code>transformed data {
  vector&lt;lower=0&gt;[K] alpha_post[K];
  vector&lt;lower=0&gt;[V] beta_post[K];
  for (k in 1:K)
    alpha_post[k] = alpha;
  for (t in 2:T)
    alpha_post[z[t-1], z[t]] += 1;
  for (k in 1:K)
    beta_post[k] = beta;
  for (t in 1:T)
    beta_post[z[t], w[t]] += 1;
}</code></pre>
<p>The posterior can now be written analytically as follows.</p>
<pre><code>model {
  for (k in 1:K)
    theta[k] ~ dirichlet(alpha_post[k]);
  for (k in 1:K)
    phi[k] ~ dirichlet(beta_post[k]);
}</code></pre>
</div>
<div id="semisupervised-estimation" class="section level3 unnumbered">
<h3>Semisupervised Estimation</h3>
<p>HMMs can be estimated in a fully unsupervised fashion without any data
for which latent states are known. The resulting posteriors are
typically extremely multimodal. An intermediate solution is to use
semisupervised estimation, which is based on a combination of
supervised and unsupervised data. Implementing this estimation
strategy in Stan requires calculating the probability of an output
sequence with an unknown state sequence. This is a marginalization
problem, and for HMMs, it is computed with the so-called forward
algorithm.</p>
<p>In Stan, the forward algorithm is coded as follows. First, two additional data variable are declared for the unsupervised data.</p>
<pre><code>data {
  ...
  int&lt;lower=1&gt; T_unsup;  // num unsupervised items
  int&lt;lower=1,upper=V&gt; u[T_unsup]; // unsup words
  ...</code></pre>
<p>The model for the supervised data does not change; the unsupervised
data are handled with the following Stan implementation of the forward
algorithm.</p>
<pre><code>model {
 ...
  {
    real acc[K];
    real gamma[T_unsup, K];
    for (k in 1:K)
      gamma[1, k] = log(phi[k, u[1]]);
    for (t in 2:T_unsup) {
      for (k in 1:K) {
        for (j in 1:K)
          acc[j] = gamma[t-1, j] + log(theta[j, k]) + log(phi[k, u[t]]);
        gamma[t, k] = log_sum_exp(acc);
      }
    }
    target += log_sum_exp(gamma[T_unsup]);
  }</code></pre>
<p>The forward values <code>gamma[t,~k]</code> are defined to be the log
marginal probability of the inputs <code>u[1],...,u[t]</code> up to time
<code>t</code> and the latent state being equal to <code>k</code> at time
<code>t</code>; the previous latent states are marginalized out. The first
row of <code>gamma</code> is initialized by setting <code>gamma[1,~k]</code> equal
to the log probability of latent state <code>k</code> generating the first
output <code>u[1]</code>; as before, the probability of the first latent
state is not itself modeled. For each subsequent time <code>t</code> and
output <code>j</code>, the value <code>acc[j]</code> is set to the probability of
the latent state at time <code>t-1</code> being <code>j</code>, plus the log
transition probability from state <code>j</code> at time <code>t-1</code> to state
<code>k</code> at time <code>t</code>, plus the log probability of the output
<code>u[t]</code> being generated by state <code>k</code>. The
<code>log_sum_exp</code> operation just multiplies the probabilities for
each prior state <code>j</code> on the log scale in an arithmetically stable
way.</p>
<p>The brackets provide the scope for the local variables <code>acc</code> and
<code>gamma</code>; these could have been declared earlier, but it is
clearer to keep their declaration near their use.</p>
</div>
<div id="predictive-inference" class="section level3 unnumbered">
<h3>Predictive Inference</h3>
<p>Given the transition and emission parameters, <span class="math inline">\(\theta_{k, k&#39;}\)</span> and
<span class="math inline">\(\phi_{k,v}\)</span> and an observation sequence <span class="math inline">\(u_1,\ldots,u_T \in \{ 1,\ldots,V \}\)</span>, the Viterbi (dynamic programming) algorithm
computes the state sequence which is most likely to have generated the
observed output <span class="math inline">\(u\)</span>.</p>
<p>The Viterbi algorithm can be coded in Stan in the generated quantities
block as follows. The predictions here is the most likely state
sequence <code>y_star[1], ..., y_star[T_unsup]</code> underlying the
array of observations <code>u[1], ..., u[T_unsup]</code>. Because this
sequence is determined from the transition probabilities
<code>theta</code> and emission probabilities <code>phi</code>, it may be
different from sample to sample in the posterior.</p>
<pre><code>generated quantities {
  int&lt;lower=1,upper=K&gt; y_star[T_unsup];
  real log_p_y_star;
  {
    int back_ptr[T_unsup, K];
    real best_logp[T_unsup, K];
    real best_total_logp;
    for (k in 1:K)
      best_logp[1, k] = log(phi[k, u[1]]);
    for (t in 2:T_unsup) {
      for (k in 1:K) {
        best_logp[t, k] = negative_infinity();
        for (j in 1:K) {
          real logp;
          logp = best_logp[t-1, j]
                  + log(theta[j, k]) + log(phi[k, u[t]]);
          if (logp &gt; best_logp[t, k]) {
            back_ptr[t, k] = j;
            best_logp[t, k] = logp;
          }
        }
      }
    }
    log_p_y_star = max(best_logp[T_unsup]);
    for (k in 1:K)
      if (best_logp[T_unsup, k] == log_p_y_star)
        y_star[T_unsup] = k;
    for (t in 1:(T_unsup - 1))
      y_star[T_unsup - t] = back_ptr[T_unsup - t + 1,
                                      y_star[T_unsup - t + 1]];
  }
}</code></pre>
<p>The bracketed block is used to make the three variables
<code>back_ptr</code>, <code>best_logp</code>, and <code>best_total_logp</code>
local so they will not be output. The variable <code>y_star</code> will
hold the label sequence with the highest probability given the input
sequence <code>u</code>. Unlike the forward algorithm, where the
intermediate quantities were total probability, here they consist of
the maximum probability <code>best_logp[t,~k]</code> for the sequence up to
time <code>t</code> with final output category <code>k</code> for time <code>t</code>,
along with a backpointer to the source of the link. Following the
backpointers from the best final log probability for the final time
<code>t</code> yields the optimal state sequence.</p>
<p>This inference can be run for the same unsupervised outputs <code>u</code>
as are used to fit the semisupervised model. The above code can be
found in the same model file as the unsupervised fit. This is the
Bayesian approach to inference, where the data being reasoned about is
used in a semisupervised way to train the model. It is not
`<code>cheating&quot; because the underlying states for</code>u` are never
observed — they are just estimated along with all of the other
parameters.</p>
<p>If the outputs <code>u</code> are not used for semisupervised estimation but
simply as the basis for prediction, the result is equivalent to what
is represented in the BUGS modeling language via the cut operation.
That is, the model is fit independently of <code>u</code>, then those
parameters used to find the most likely state to have generated
<code>u</code>.</p>

</div>
</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-Engle:1982">
<p>Engle, Robert F. 1982. “Autoregressive Conditional Heteroscedasticity with Estimates of Variance of United Kingdom Inflation.” <em>Econometrica</em> 50: 987–1008.</p>
</div>
<div id="ref-KimShephardChib:1998">
<p>Kim, Sangjoon, Neil Shephard, and Siddhartha Chib. 1998. “Stochastic Volatility: Likelihood Inference and Comparison with ARCH Models.” <em>Review of Economic Studies</em> 65: 361–93.</p>
</div>
<div id="ref-Hoffman-Gelman:2011">
<p>Hoffman, Matthew D., and Andrew Gelman. 2011. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” <em>arXiv</em> 1111.4246. <a href="http://arxiv.org/abs/1111.4246" class="uri">http://arxiv.org/abs/1111.4246</a>.</p>
</div>
<div id="ref-Hoffman-Gelman:2014">
<p>Hoffman, Matthew D., and Andrew Gelman. 2011. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” <em>arXiv</em> 1111.4246. <a href="http://arxiv.org/abs/1111.4246" class="uri">http://arxiv.org/abs/1111.4246</a>.</p> 2014. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” <em>Journal of Machine Learning Research</em> 15: 1593–1623. <a href="http://jmlr.org/papers/v15/hoffman14a.html" class="uri">http://jmlr.org/papers/v15/hoffman14a.html</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>The intercept in this model is <span class="math inline">\(\alpha / (1 - \beta)\)</span>. An alternative parameterization in terms of an intercept <span class="math inline">\(\gamma\)</span> suggested Mark Scheuerell on GitHub is <span class="math inline">\(y_n \sim \mathsf{normal}(\alpha + \gamma \cdot (y_{n-1} - \alpha), \sigma)\)</span>.<a href="time-series-chapter.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>In practice, it can be useful to remove the constraint to test whether a non-stationary set of coefficients provides a better fit to the data. It can also be useful to add a trend term to the model, because an unfitted trend will manifest as non-stationarity.<a href="time-series-chapter.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>This subsection is a lightly edited comment of Jonathan Gilligan’s on GitHub; see <a href="time-series-chapter.html#fnref9" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="missing-data-and-partially-known-parameters.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
