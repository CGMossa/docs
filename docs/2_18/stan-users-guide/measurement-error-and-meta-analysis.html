<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Stan User’s Guide</title>
  <meta name="description" content="Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Stan User’s Guide" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stan User’s Guide" />
  
  <meta name="twitter:description" content="Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="mixture-modeling-chapter.html">
<link rel="next" href="latent-discrete-chapter.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Stan User's Guide</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 1. Example Models</i></a></li>
<li class="chapter" data-level="1" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>1</b> Regression Models</a></li>
<li class="chapter" data-level="2" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>2</b> Time-Series Models</a></li>
<li class="chapter" data-level="3" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>3</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="4" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>4</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="5" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="6" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>6</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="7" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>7</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="8" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>8</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="9" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>9</b> Clustering Models</a></li>
<li class="chapter" data-level="10" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>10</b> Gaussian Processes</a></li>
<li class="chapter" data-level="11" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>11</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="12" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>12</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="13" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>13</b> Ordinary Differential Equations</a></li>
<li><a href="part-2-programming-techniques.html#part-2.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 2. Programming Techniques</i></a></li>
<li class="chapter" data-level="14" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>14</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="15" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>15</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="16" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>16</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="17" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>17</b> User-Defined Functions</a></li>
<li class="chapter" data-level="18" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>18</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="19" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>19</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="20" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>20</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="21" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>21</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="22" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>22</b> Map-Reduce</a></li>
<li><a href="appendices-part.html#appendices.part"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="23" data-path="stan-program-style-guide.html"><a href="stan-program-style-guide.html"><i class="fa fa-check"></i><b>23</b> Stan Program Style Guide</a></li>
<li class="chapter" data-level="24" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i><b>24</b> Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan User’s Guide</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="measurement-error-and-meta-analysis" class="section level1">
<h1><span class="header-section-number">6</span> Measurement Error and Meta-Analysis</h1>
<p>Most quantities used in statistical models arise from measurements.
Most of these measurements are taken with some error. When the
measurement error is small relative to the quantity being measured,
its effect on a model is usually small. When measurement error is
large relative to the quantity being measured, or when precise
relations can be estimated being measured quantities, it is useful to
introduce an explicit model of measurement error. One kind of
measurement error is rounding.</p>
<p>Meta-analysis plays out statistically much like measurement error
models, where the inferences drawn from multiple data sets are
combined to do inference over all of them. Inferences for each data
set are treated as providing a kind of measurement error with respect
to true parameter values.</p>
<div id="bayesian-measurement-error-model" class="section level2">
<h2><span class="header-section-number">6.1</span> Bayesian Measurement Error Model</h2>
<p>A Bayesian approach to measurement error can be formulated directly by
treating the true quantities being measured as missing data
<span class="citation">(Clayton <a href="#ref-Clayton:1992">1992</a>; Richardson and Gilks <a href="#ref-RichardsonGilks:1993">1993</a>)</span>. This requires a model of
how the measurements are derived from the true values.</p>
<div id="regression-with-measurement-error" class="section level3 unnumbered">
<h3>Regression with Measurement Error</h3>
<p>Before considering regression with measurement error, first consider a
linear regression model where the observed data for <span class="math inline">\(N\)</span> cases includes
a predictor <span class="math inline">\(x_n\)</span> and outcome <span class="math inline">\(y_n\)</span>. In Stan, a linear regression for
<span class="math inline">\(y\)</span> based on <span class="math inline">\(x\)</span> with a slope and intercept is modeled as follows.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;       // number of cases
  vector[N] x;          // predictor (covariate)
  vector[N] y;          // outcome (variate)
}
parameters {
  real alpha;           // intercept
  real beta;            // slope
  real&lt;lower=0&gt; sigma;  // outcome noise
}
model {
  y ~ normal(alpha + beta * x, sigma);
  alpha ~ normal(0, 10);
  beta ~ normal(0, 10);
  sigma ~ cauchy(0, 5);
}</code></pre>
<p>Now suppose that the true values of the predictors <span class="math inline">\(x_n\)</span> are not known, but for each <span class="math inline">\(n\)</span>, a measurement <span class="math inline">\(x^{\mathrm meas}_n\)</span> of <span class="math inline">\(x_n\)</span> is available. If the error in measurement can be modeled, the measured value <span class="math inline">\(x^{\mathrm{meas}}_n\)</span> can be modeled in terms of the true value <span class="math inline">\(x_n\)</span> plus measurement noise. The true value <span class="math inline">\(x_n\)</span> is treated as missing data and estimated along with other quantities in the model. A simple approach is to assume the measurement error is normal with known deviation <span class="math inline">\(\tau\)</span>. This leads to the following regression model with constant measurement error.</p>
<pre><code>data {
  ...
  real x_meas[N];     // measurement of x
  real&lt;lower=0&gt; tau;  // measurement noise
}
parameters {
  real x[N];          // unknown true value
  real mu_x;          // prior location
  real sigma_x;       // prior scale
  ...
}
model {
  x ~ normal(mu_x, sigma_x);  // prior
  x_meas ~ normal(x, tau);    // measurement model
  y ~ normal(alpha + beta * x, sigma);
  ...
}</code></pre>
<p>The regression coefficients <code>alpha</code> and <code>beta</code> and
regression noise scale <code>sigma</code> are the same as before, but now
<code>x</code> is declared as a parameter rather than as data. The data are
now <code>x_meas</code>, which is a measurement of the true <code>x</code> value
with noise scale <code>tau</code>. The model then specifies that the
measurement error for <code>x_meas[n]</code> given true value <code>x[n]</code>
is normal with deviation <code>tau</code>. Furthermore, the true values
<code>x</code> are given a hierarchical prior here.</p>
<p>In cases where the measurement errors are not normal, richer
measurement error models may be specified. The prior on the true
values may also be enriched. For instance, <span class="citation">Clayton (<a href="#ref-Clayton:1992">1992</a>)</span>
introduces an exposure model for the unknown (but noisily measured)
risk factors <span class="math inline">\(x\)</span> in terms of known (without measurement error) risk
factors <span class="math inline">\(c\)</span>. A simple model would regress <span class="math inline">\(x_n\)</span> on the covariates
<span class="math inline">\(c_n\)</span> with noise term <span class="math inline">\(\upsilon\)</span>,
<span class="math display">\[
x_n \sim \mathsf{normal}(\gamma^{\top}c, \upsilon).
\]</span>
This can be coded in Stan just like any other regression. And, of
course, other exposure models can be provided.</p>
</div>
<div id="rounding" class="section level3 unnumbered">
<h3>Rounding</h3>
<p>A common form of measurement error arises from rounding measurements.
Rounding may be done in many ways, such as rounding weights to the
nearest milligram, or to the nearest pound; rounding may even be done
by rounding down to the nearest integer.</p>
<p>Exercise 3.5(b) from <span class="citation">Gelman et al. (<a href="#ref-GelmanEtAl:2013">2013</a>)</span> provides an example.</p>

<p>Letting <span class="math inline">\(z_n\)</span> be the unrounded measurement for <span class="math inline">\(y_n\)</span>, the problem
as stated assumes the likelihood</p>
<p><span class="math display">\[
z_n \sim \mathsf{normal}(\mu, \sigma).
\]</span></p>
<p>The rounding process entails that <span class="math inline">\(z_n \in (y_n - 0.5, y_n + 0.5)\)</span>.
The probability mass function for the discrete observation <span class="math inline">\(y\)</span> is then given
by marginalizing out the unrounded measurement, producing the likelihood
<span class="math display">\[
p(y_n \, | \, \mu, \sigma)
=
\int_{y_n - 0.5}^{y_n + 0.5}
\
\mathsf{normal}(z_n \, | \, \mu, \sigma)
\
\mathrm{d}z_n
=
\Phi\!\left(\frac{y_n + 0.5 - \mu}{\sigma}\right)
-
\Phi\!\left(\frac{y_n - 0.5 - \mu}{\sigma}\right).
\]</span>
Gelman’s answer for this problem took the noninformative prior to be
uniform in the variance <span class="math inline">\(\sigma^2\)</span> on the log scale, which yields (due
to the Jacobian adjustment), the prior density
<span class="math display">\[
p(\mu, \sigma^2) \propto \frac{1}{\sigma^2}.
\]</span>
The posterior after observing <span class="math inline">\(y = (10, 10, 12, 11, 9)\)</span> can be
calculated by Bayes’s rule as</p>
<p><span class="math display">\[
\begin{array}{rcl}
p(\mu, \sigma^2 \, | \, y)
&amp; \propto &amp;
p(\mu, \sigma^2) \ p(y \, | \, \mu, \sigma^2)
\\[6pt]
&amp;  \propto &amp;
\frac{1}{\sigma^2}
\
\prod_{n=1}^5
\left(
\Phi\!\left(\frac{y_n + 0.5 - \mu}{\sigma}\right)
-
\Phi\!\left(\frac{y_n - 0.5 - \mu}{\sigma}\right)
\right).
\end{array}
\]</span></p>
<p>The Stan code simply follows the mathematical definition, providing an
example of the direct definition of a probability function up to a
proportion.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
}
parameters {
  real mu;
  real&lt;lower=0&gt; sigma_sq;
}
transformed parameters {
  real&lt;lower=0&gt; sigma;
  sigma = sqrt(sigma_sq);
}
model {
  target += -2 * log(sigma);
  for (n in 1:N)
    target += log(Phi((y[n] + 0.5 - mu) / sigma)
                  - Phi((y[n] - 0.5 - mu) / sigma));
}</code></pre>
<p>Alternatively, the model may be defined with latent parameters for the
unrounded measurements <span class="math inline">\(z_n\)</span>. The Stan code in this case uses the
likelihood for <span class="math inline">\(z_n\)</span> directly while respecting the constraint <span class="math inline">\(z_n \in (y_n - 0.5, y_n + 0.5)\)</span>. Because Stan does not allow varying upper-
and lower-bound constraints on the elements of a vector (or array),
the parameters are declared to be the rounding error <span class="math inline">\(y - z\)</span>, and
then <span class="math inline">\(z\)</span> is defined as a transformed parameter.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
}
parameters {
  real mu;
  real&lt;lower=0&gt; sigma_sq;
  vector&lt;lower=-0.5, upper=0.5&gt;[N] y_err;
}
transformed parameters {
  real&lt;lower=0&gt; sigma;
  vector[N] z;
  sigma = sqrt(sigma_sq);
  z = y + y_err;
}
model {
  target += -2 * log(sigma);
  z ~ normal(mu, sigma);
}</code></pre>
<p>This explicit model for the unrounded measurements <span class="math inline">\(z\)</span> produces the
same posterior for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> as the previous model that
marginalizes <span class="math inline">\(z\)</span> out. Both approaches mix well, but the latent
parameter version is about twice as efficient in terms of effective
samples per iteration, as well as providing a posterior for the
unrounded parameters.</p>
</div>
</div>
<div id="meta-analysis" class="section level2">
<h2><span class="header-section-number">6.2</span> Meta-Analysis</h2>
<p>Meta-analysis aims to pool the data from several studies, such as the
application of a tutoring program in several schools or treatment
using a drug in several clinical trials.</p>
<p>The Bayesian framework is particularly convenient for meta-analysis,
because each previous study can be treated as providing a noisy
measurement of some underlying quantity of interest. The model then
follows directly from two components, a prior on the underlying
quantities of interest and a measurement-error style model for each of
the studies being analyzed.</p>
<div id="treatment-effects-in-controlled-studies" class="section level3 unnumbered">
<h3>Treatment Effects in Controlled Studies</h3>
<p>Suppose the data in question arise from a total of <span class="math inline">\(M\)</span> studies
providing paired binomial data for a treatment and control group. For
instance, the data might be post-surgical pain reduction under a treatment
of ibuprofen <span class="citation">Warn, Thompson, and Spiegelhalter (<a href="#ref-WarnThompsonSpiegelhalter:2002">2002</a>)</span> or mortality after
myocardial infarction under a treatment of beta blockers
<span class="citation">(Gelman et al. <a href="#ref-GelmanEtAl:2013">2013</a>, Section 5.6)</span>.</p>
<div id="data" class="section level4 unnumbered">
<h4>Data</h4>
<p>The clinical data consists of <span class="math inline">\(J\)</span> trials, each with <span class="math inline">\(n^t\)</span> treatment cases, <span class="math inline">\(n^c\)</span> control cases, <span class="math inline">\(r^t\)</span> successful outcomes among those treated and <span class="math inline">\(r^c\)</span> successful outcomes among those in the control group. This data can be declared in Stan as follows.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<pre><code>data {
  int&lt;lower=0&gt; J;
  int&lt;lower=0&gt; n_t[J];  // num cases, treatment
  int&lt;lower=0&gt; r_t[J];  // num successes, treatment
  int&lt;lower=0&gt; n_c[J];  // num cases, control
  int&lt;lower=0&gt; r_c[J];  // num successes, control
}</code></pre>
</div>
<div id="converting-to-log-odds-and-standard-error" class="section level4 unnumbered">
<h4>Converting to Log Odds and Standard Error</h4>
<p>Although the clinical trial data are binomial in its raw format, it may
be transformed to an unbounded scale by considering the log odds ratio
<span class="math display">\[
y_j = \log \left( \frac{r^t_j / (n^t_j - r^t_j)}
                       {r^c_j / (n^c_j - r^c_j)} \right)
\ \ = \ \
\log \left( \frac{r^t_j}{n^t_j - r^t_j} \right)
-
\log \left( \frac{r^c_j}{n^c_j - r^c_j} \right)
\]</span>
and corresponding standard errors
<span class="math display">\[
\sigma_j = \sqrt{
\frac{1}{r^T_i}
+ \frac{1}{n^T_i - r^T_i}
+ \frac{1}{r^C_i}
+ \frac{1}{n^C_i - r^C_i}
}.
\]</span></p>
<p>The log odds and standard errors can be defined in a transformed
parameter block, though care must be taken not to use integer
division.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<pre><code>transformed data {
  real y[J];
  real&lt;lower=0&gt; sigma[J];
  for (j in 1:J)
    y[j] = log(r_t[j]) - log(n_t[j] - r_t[j])
            - (log(r_c[j]) - log(n_c[j] - r_c[j]);
  for (j in 1:J)
    sigma[j] = sqrt(1 / r_t[j] + 1 / (n_t[j] - r_t[j])
                     + 1 / r_c[j] + 1 / (n_c[j] - r_c[j]));
}</code></pre>
<p>This definition will be problematic if any of the success counts is
zero or equal to the number of trials.
If that arises, a direct binomial model will be required or other
transforms must be used than the unregularized sample log odds.</p>
</div>
<div id="non-hierarchical-model" class="section level4 unnumbered">
<h4>Non-Hierarchical Model</h4>
<p>With the transformed data in hand, two standard forms of meta-analysis
can be applied. The first is a so-called “fixed effects” model,
which assumes a single parameter for the global odds ratio. This
model is coded in Stan as follows.</p>
<pre><code>parameters {
  real theta;  // global treatment effect, log odds
}
model {
  y ~ normal(theta, sigma);
}</code></pre>
<p>The sampling statement for <code>y</code> is vectorized; it has the same
effect as the following.</p>
<pre><code>  for (j in 1:J)
    y[j] ~ normal(theta, sigma[j]);</code></pre>
<p>It is common to include a prior for <code>theta</code> in this model, but it
is not strictly necessary for the model to be proper because <code>y</code>
is fixed and <span class="math inline">\(\mathsf{normal}(y|\mu,\sigma) = \mathsf{normal}(\mu|y,\sigma)\)</span>.</p>
</div>
<div id="hierarchical-model" class="section level4 unnumbered">
<h4>Hierarchical Model</h4>
<p>To model so-called “random effects,” where the treatment effect may
vary by clinical trial, a hierarchical model can be used. The
parameters include per-trial treatment effects and the hierarchical
prior parameters, which will be estimated along with other unknown
quantities.</p>
<pre><code>parameters {
  real theta[J];      // per-trial treatment effect
  real mu;            // mean treatment effect
  real&lt;lower=0&gt; tau;  // deviation of treatment effects
}
model {
  y ~ normal(theta, sigma);
  theta ~ normal(mu, tau);
  mu ~ normal(0, 10);
  tau ~ cauchy(0, 5);
}</code></pre>
<p>Although the vectorized sampling statement for <code>y</code> appears
unchanged, the parameter <code>theta</code> is now a vector. The sampling
statement for <code>theta</code> is also vectorized, with the
hyperparameters <code>mu</code> and <code>tau</code> themselves being given wide
priors compared to the scale of the data.</p>
<p><span class="citation">Rubin (<a href="#ref-Rubin:1981">1981</a>)</span> provided a hierarchical Bayesian meta-analysis of
the treatment effect of Scholastic Aptitude Test (SAT) coaching in
eight schools based on the sample treatment effect and standard error
in each school.</p>
</div>
<div id="extensions-and-alternatives" class="section level4 unnumbered">
<h4>Extensions and Alternatives</h4>
<p><span class="citation">Smith, Spiegelhalter, and Thomas (<a href="#ref-SmithSpiegelhalterThomas:1995">1995</a>)</span> and <span class="citation">(Gelman et al. <a href="#ref-GelmanEtAl:2013">2013</a>, Section 19.4)</span>
provides meta-analyses based directly on binomial data.
<span class="citation">Warn, Thompson, and Spiegelhalter (<a href="#ref-WarnThompsonSpiegelhalter:2002">2002</a>)</span> consider the modeling
implications of using alternatives to the log-odds ratio in
transforming the binomial data.</p>
<p>If trial-specific predictors are available, these can be included
directly in a regression model for the per-trial treatment effects
<span class="math inline">\(\theta_j\)</span>.</p>

</div>
</div>
</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-Clayton:1992">
<p>Clayton, D. G. 1992. “Models for the Analysis of Cohort and Case-Control Studies with Inaccurately Measured Exposures.” In <em>Statistical Models for Longitudinal Studies of Exposure and Health</em>, edited by James H. Dwyer, Manning Feinleib, Peter Lippert, and Hans Hoffmeister, 301–31. New York: Oxford University Press.</p>
</div>
<div id="ref-RichardsonGilks:1993">
<p>Richardson, Sylvia, and Walter R. Gilks. 1993. “A Bayesian Approach to Measurement Error Problems in Epidemiology Using Conditional Independence Models.” <em>American Journal of Epidemiology</em> 138 (6): 430–42.</p>
</div>
<div id="ref-GelmanEtAl:2013">
<p>Gelman, Andrew, J. B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third. London: Chapman &amp;Hall/CRC Press.</p>
</div>
<div id="ref-WarnThompsonSpiegelhalter:2002">
<p>Warn, David E., S. G. Thompson, and David J. Spiegelhalter. 2002. “Bayesian Random Effects Meta-Analysis of Trials with Binary Outcomes: Methods for the Absolute Risk Difference and Relative Risk Scales.” <em>Statistics in Medicine</em> 21: 1601–23.</p>
</div>
<div id="ref-Rubin:1981">
<p>Rubin, Donald B. 1981. “Estimation in Parallel Randomized Experiments.” <em>Journal of Educational Statistics</em> 6: 377–401.</p>
</div>
<div id="ref-SmithSpiegelhalterThomas:1995">
<p>Smith, Teresa C., David J. Spiegelhalter, and Andrew Thomas. 1995. “Bayesian Approaches to Random-Effects Meta-Analysis: A Comparative Study.” <em>Statistics in Medicine</em> 14 (24): 2685–99.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="12">
<li id="fn12"><p>Stan’s integer constraints are not powerful enough to express the constraint that <span class="math inline">\(\mathtt{r\_t[j]} \leq \mathtt{n\_t[j]}\)</span>, but this constraint could be checked in the transformed data block.<a href="measurement-error-and-meta-analysis.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>When dividing two integers, the result type is an integer and rounding will ensue if the result is not exact. See the discussion of primitive arithmetic types in the reference manual for more information.<a href="measurement-error-and-meta-analysis.html#fnref13" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mixture-modeling-chapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="latent-discrete-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
