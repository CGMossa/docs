<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Stan User’s Guide</title>
  <meta name="description" content="Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Stan User’s Guide" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stan User’s Guide" />
  
  <meta name="twitter:description" content="Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="part-2-programming-techniques.html">
<link rel="next" href="matrices-vectors-and-arrays.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Stan User's Guide</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 1. Example Models</i></a></li>
<li class="chapter" data-level="1" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>1</b> Regression Models</a></li>
<li class="chapter" data-level="2" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>2</b> Time-Series Models</a></li>
<li class="chapter" data-level="3" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>3</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="4" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>4</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="5" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="6" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>6</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="7" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>7</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="8" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>8</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="9" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>9</b> Clustering Models</a></li>
<li class="chapter" data-level="10" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>10</b> Gaussian Processes</a></li>
<li class="chapter" data-level="11" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>11</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="12" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>12</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="13" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>13</b> Ordinary Differential Equations</a></li>
<li><a href="part-2-programming-techniques.html#part-2.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 2. Programming Techniques</i></a></li>
<li class="chapter" data-level="14" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>14</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="15" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>15</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="16" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>16</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="17" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>17</b> User-Defined Functions</a></li>
<li class="chapter" data-level="18" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>18</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="19" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>19</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="20" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>20</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="21" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>21</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="22" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>22</b> Map-Reduce</a></li>
<li><a href="appendices-part.html#appendices.part"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="23" data-path="stan-program-style-guide.html"><a href="stan-program-style-guide.html"><i class="fa fa-check"></i><b>23</b> Stan Program Style Guide</a></li>
<li class="chapter" data-level="24" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i><b>24</b> Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan User’s Guide</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="floating-point-arithmetic" class="section level1">
<h1><span class="header-section-number">14</span> Floating Point Arithmetic</h1>
<p>Computers approximate real values in <span class="math inline">\(\mathbb{R}\)</span> using a fixed number
of bits. This chapter explains how this is done and why it is
important for writing robust Stan (and other numerical) programs. The
subfield of computer science devoted to studying how real arithmetic
works on computers is called <em>numerical analysis</em>.</p>
<div id="floating-point-representations" class="section level2">
<h2><span class="header-section-number">14.1</span> Floating-point representations</h2>
<p>Stan’s arithmetic is implemented using double-precision arithmetic.
The behavior of most<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> modern computers
follows the floating-point arithmetic, <em>IEEE Standard for
Floating-Point Arithmetic</em> (IEEE 754).</p>
<div id="finite-values" class="section level3">
<h3><span class="header-section-number">14.1.1</span> Finite values</h3>
<p>The double-precision component of the IEEE 754 standard specifies the
representation of real values using a fixed pattern of 64 bits (8
bytes). All values are represented in base two (i.e., binary). The
representation is divided into two signed components:</p>
<ul>
<li><p><em>significand</em> (53 bits): base value representing significant digits</p></li>
<li><p><em>exponent</em> (11 bits): power of two multiplied by the base</p></li>
</ul>
<p>The <em>value</em> of a finite floating point number is</p>
<p><span class="math display">\[
v = (-1)^s \times c \ 2^q
\]</span></p>
</div>
<div id="normality" class="section level3">
<h3><span class="header-section-number">14.1.2</span> Normality</h3>
<p>A <em>normal</em> floating-point value does not use any leading zeros in
its significand; <em>subnormal</em> numbers may use leading zeros. Not all
I/O systems support subnormal numbers.</p>
</div>
<div id="ranges-and-extreme-values" class="section level3">
<h3><span class="header-section-number">14.1.3</span> Ranges and extreme values</h3>
<p>There are some reserved exponent values so that legal exponent values
range between<span class="math inline">\(-(2^10) + 2 = -1022\)</span> and <span class="math inline">\(2^10 - 1 = 1023\)</span>. Legal
significand values are between <span class="math inline">\(-2^52\)</span> and <span class="math inline">\(2^52 - 1\)</span>.
Floating point allows the representation of both really big and really
small values. Some extreme values are</p>
<ul>
<li><p><em>largest normal finite number</em>: <span class="math inline">\(\approx 1.8 \times 10^{308}\)</span></p></li>
<li><p><em>largest subnormal finite number</em>: <span class="math inline">\(\approx 2.2 \times 10^{308}\)</span></p></li>
<li><p><em>smallest positive normal number</em>: <span class="math inline">\(\approx 2.2 \times 10^{-308}\)</span></p></li>
<li><p><em>smallest positive subnormal number</em>: <span class="math inline">\(\approx 4.9 \times 10^{-324}\)</span></p></li>
</ul>
</div>
<div id="signed-zero" class="section level3">
<h3><span class="header-section-number">14.1.4</span> Signed zero</h3>
<p>Because of the sign bit, there are two ways to represent zero, often
called “positive zero” and “negative zero”. This distinction is
irrelevant in Stan (as it is in R), because the two values are equal
(i.e., <code>0 == -0</code> evaluates to true).</p>
</div>
<div id="not-a-number-values" class="section level3">
<h3><span class="header-section-number">14.1.5</span> Not-a-number values</h3>
<p>A specially chosen bit pattern is used for the <em>not-a-number</em> value
(often written as <code>NaN</code> in programming language output, including
Stan’s).</p>
<p>Stan provides a value function <code>nan()</code> that returns this special
not-a-number value. It is meant to represent error conditions, not
missing values. Usually when not-a-number is an argument to a
function, the result will not-a-number if an exception (a rejection in
Stan) is not raised.</p>
<p>Stan also provides a test function <code>is_nan(x)</code> that returns 1 if <code>x</code>
is not-a-number and 0 otherwise.</p>
<p>Not-a-number values propagate under almost all mathematical
operations. For example, all of the built-in binary arithmetic
operations (addition, subtraction, multiplication, division, negation)
return not-a-number if any of their arguments are not-a-number. The
built-in functions such as <code>log</code> and <code>exp</code> hav the same behavior,
propagating not-a-number values.</p>
<p>Most of Stan’s built-in functions will throw exceptions (i.e., reject)
when any of their arguments is not-a-number.</p>
<p>Comparisons with not-a-number always return false, up to and including
comparison with itself. That is, <code>not_a_number() == not_a_number()</code>
somewhat confusingly returns false. That is why there is a built-in
<code>is_not_a_number()</code> function in Stan (and in C++). The only exception
is negation, which remains coherent. This means <code>not_a_number() != not_a_number()</code> returns true.</p>
<p>Undefined operations often return not-a-number values. For example,
<code>sqrt(-1)</code> will evaluate to not-a-number.</p>
</div>
<div id="positive-and-negative-infinity" class="section level3">
<h3><span class="header-section-number">14.1.6</span> Positive and negative infinity</h3>
<p>There are also two special values representing positive infinity
(<span class="math inline">\(\infty)\)</span> and negative infinity (<span class="math inline">\(-\infty\)</span>). These are not
as pathological as not-a-number, but are often used to represent error
conditions such as overflow and underflow. For example, rather than
raising an error or returning not-a-number, <code>log(0)</code> evaluates to
negative infinity. Exponentiating negative infinity leads back to
zero, so that <code>0 == exp(log(0))</code>. Nevertheless, this should not be
done in Stan because the chain rule used to calculate the derivatives
will attempt illegal operations and return not-a-number.</p>
<p>There are value functions <code>positive_infinity()</code> and
<code>negative_infinity()</code> as well as a test function <code>is_infinity()</code>.</p>
<p>Positive and negative infinity have the expected comparison behavior,
so that <code>negative_infinty() &lt; 0</code> evaluates to true (represented with 1
in Stan). Also, negating positive infinity leads to negative infinity
and vice-versa.</p>
<p>Positive infinity added to either itself or a finite value produces
positive infinity. Negative infinity behaves the same way. However,
attempts to subtract positive infinity from itself produce
not-a-number, not zero. Similarly, attempts to divide infinite values
results in a not-a-number value.</p>
</div>
</div>
<div id="literals-decimal-and-scientific-notation" class="section level2">
<h2><span class="header-section-number">14.2</span> Literals: decimal and scientific notation</h2>
<p>In programming languages such as Stan, numbers may be represented in
standard <em>decimal</em> (base 10) notation. For example, <code>2.39</code> or
<code>-1567846.276452</code>. Remember there is no point in writing more than 16
significant digits as they cannot be represented. A number may be
coded in Stan using <em>scientific notation</em>, which consists of a signed
decimal representation of a base and a signed integer decimal
exponent. For example, <code>36.29e-3</code> represents the number <span class="math inline">\(36.29 \times 10^{-3}\)</span>, which is the same number as is represented by <code>0.3629</code>.</p>
</div>
<div id="arithmetic-precision" class="section level2">
<h2><span class="header-section-number">14.3</span> Arithmetic Precision</h2>
<p>The choice of significand provides <span class="math inline">\(\log_10 2^53 \approx 15.95\)</span>
decimal (base 10) digits of <em>arithmetic precision</em>. This is just the
precision of the floating-point representation. After several
operations are chained together, the realized arithmetic precision is
often much lower.</p>
<div id="rounding-and-probabilities" class="section level3">
<h3><span class="header-section-number">14.3.1</span> Rounding and probabilities</h3>
<p>In practice, the finite amount of arithmetic precision leads to
<em>rounding</em>, whereby a number is represented by the closest
floating-point number. For example, with only 16 decimal digits of
accuracy,</p>
<pre><code>1 + 1e-20 == 1</code></pre>
<p>The closest floating point number to <span class="math inline">\(1 + 10^{-20}\)</span> turns out to be
<span class="math inline">\(1\)</span> itself. By contrast, <code>0 + 1e-20 == 1e-20</code>.</p>
<p>This highlights the fact that precision depends on scale. Even though
<code>1 + 1e-20 == 1</code>, we have <code>1e-20 + 1e-20 == 2e-20</code>, as expected.</p>
<p>Rounding also manifests itself in a lack of <em>transitivity</em>. In
particular, it does <em>not</em> usually hold for three floating point numbers
<span class="math inline">\(a, b, c\)</span> that <span class="math inline">\((a + b) + c = a + (b = c)\)</span>.</p>
<p>In statistical applications, problems often manifest in situations
where users expect the usual rules of real-valued arithmetic to hold.
Suppose we have a lower triangular matrix <span class="math inline">\(L\)</span> with strictly positive
diagonal, so that it is the Cholesky factor of a positive-definite
matrix <span class="math inline">\(L \, L^{\top}\)</span>. In practice, rounding and loss of precision
may render the result <span class="math inline">\(L \, L^{\top}\)</span> neither symmetric nor positive
definite.</p>
<p>In practice, care must be taken to defend against rounding. For
example, symmetry may be produced by adding <span class="math inline">\(L \, L^{top}\)</span> with its
transpose and dividing by two, or by copying the lower triangular
portion into the upper portion. Positive definiteness may be
maintained by adding a small quantity to the diagonal.</p>
</div>
<div id="machine-precision-and-the-asymmetry-of-0-and-1" class="section level3">
<h3><span class="header-section-number">14.3.2</span> Machine precision and the asymmetry of 0 and 1</h3>
<p>The smallest number greater than zero is roughly <span class="math inline">\(0 + 10^{-323}\)</span>. The
largest number less than zero is roughly <span class="math inline">\(1 - 10^{-15.95}\)</span>. The
asymmetry is apparent when considering the representation of that
largest number smaller than one—the exponent is of no help, and the
number is represented as the binary equivalent of
<code>0.9999999999999999</code>.</p>
<p>For this reason, the <em>machine precision</em> is said to be roughly
<span class="math inline">\(10^{15.95}\)</span>. This constant is available as <code>machine_precision()</code> in
Stan.</p>
</div>
<div id="complementary-and-epsilon-functions" class="section level3">
<h3><span class="header-section-number">14.3.3</span> Complementary and epsilon functions</h3>
<p>Special operations are available to mitigate this problem with numbers
rounding when they get close to one. For example, consider the
operation <code>log(1 + x)</code> for positive <code>x</code>. When <code>x</code> is small (less than
<span class="math inline">\(10^{-16}\)</span> for double-precision floating point), the sum in the
argument will round to 1 and the result will round to zero. To allow
more granularity, programming languages provide a library function
directly implementing <span class="math inline">\(f(x) = \log (1 + x)\)</span>. In Stan (as in C++),
this operation is written as <code>log1p(x)</code>. Because <code>x</code> itself may be
close to zero, the function <code>log1p(x)</code> can take the logarithm of
values very close to one, the results of which are close to zero.</p>
<p>Similarly, the complementary cumulative distribution functions (CCDF),
defined by <span class="math inline">\(F^{\complement}_Y(y) = 1 - F_Y(y)\)</span>, where <span class="math inline">\(F_Y\)</span> is the
cumulative distribution function (CDF) for the random variable <span class="math inline">\(Y\)</span>.
This allows values very close to one to be represented in
complementary form.</p>
</div>
<div id="catastrophic-cancellation" class="section level3">
<h3><span class="header-section-number">14.3.4</span> Catastrophic cancellation</h3>
<p>Another downside to floating point representations is that
subtraction of two numbers close to each other results in a loss of
precision that depends on how close they are. This is easy to see in
practice. Consider</p>
<pre><code>  1.23456789012345
- 1.23456789012344
= 0.00000000000001</code></pre>
<p>We start with fifteen decimal places of accuracy in the arguments and
are left with a single decimal place of accuracy in the result.</p>
<p>Catastrophic cancellation arises in statistical computations whenever
we calculate variance for a distribution with small standard
deviations relative to its location. When calculating summary
statistics, Stan uses <em>Welford’s algorithm</em> for computing variances.
This avoids catastrophic cancellation and may also be carried out in a
single pass.</p>
</div>
<div id="overflow" class="section level3">
<h3><span class="header-section-number">14.3.5</span> Overflow</h3>
<p>Even though <code>1e200</code> may be represented as a double precision floating
point value, there is no finite value large enough to represent <code>1e200 * 1e200</code>. The result of <code>1e200 * 1e200</code> is said to <em>overflow</em>. The
IEEE 754 standard requires the result to be positive infinity.</p>
<p>Overflow is rarely a problem in statistical computations. If it is,
it’s possible to work on the log scale, just as for underflow as
described below.</p>
</div>
<div id="underflow-and-the-log-scale" class="section level3">
<h3><span class="header-section-number">14.3.6</span> Underflow and the log scale</h3>
<p>When there is no number small enough to represent a result, it is said
to <em>underflow</em>. For instance, <code>1e-200</code> may be represented, but
<code>1e-200 * 1e-200</code> underflows so that the result is zero.</p>
<p>Underflow is a ubiquitous problem in likelihood calculations,
For example, if <span class="math inline">\(p(y_n \mid \theta) &lt; 0.1\)</span>, then</p>
<p><span class="math display">\[
p(y \mid \theta) = \prod_{n=1}^N p(y_n \mid \theta)
\]</span></p>
<p>will underflow as soon as <span class="math inline">\(N &gt; 350\)</span> or so.</p>
<p>To deal with underflow, work on the log scale. Even though <span class="math inline">\(p(y \mid \theta)\)</span> can’t be represented, there is no problem representing</p>
<p><span class="math display">\[
\begin{array}{rcl}
\log p(y \mid \theta)
&amp; = &amp; \log \prod_{n=1}^N p(y_n \mid \theta)
\\[4pt]
&amp; = &amp; \sum_{n = 1}^N \log p(y_n \mid \theta)
\end{array}
\]</span></p>
<p>This is why all of Stan’s probability functions operate on the log
scale.</p>
</div>
<div id="adding-on-the-log-scale" class="section level3">
<h3><span class="header-section-number">14.3.7</span> Adding on the log scale</h3>
<p>If we work on the log scale, multiplication is converted to addition,
<span class="math display">\[
\log (a \times b) = \log a + \log b.
\]</span>
Thus we can just start on the log scale and stay there through
multiplication. But what about addition? If we have <span class="math inline">\(\log a\)</span> and
<span class="math inline">\(\log b\)</span>, how do we get <span class="math inline">\(\log (a + b)\)</span>? Working out the algebra,</p>
<p><span class="math display">\[
\log (a + b)
\ = \
\log (\exp(\log a) + \exp(\log b))
\]</span></p>
<p>The nested log of sum of exponentials is so common, it has its own
name,</p>
<p><span class="math display">\[
\mathrm{log\_sum\_exp}(u, v)
\ = \
\log (\exp(u) + \exp(v)).
\]</span></p>
<p>so that</p>
<p><span class="math display">\[
\log (a + b)
\ = \
\mathrm{log\_sum\_exp}(\log a, \log b).
\]</span></p>
<p>Although it appears this might overflow as soon as exponentiation is
introduced, evaluation does not proceed by evaluating the terms as
written. Instead, with a little algebra, the terms are rearranged
into a stable form,</p>
<p><span class="math display">\[
\mathrm{log\_sum\_exp}(u, v)
\ = \
\max(u, v) + \log\left( \exp(u - \max(u, v)) + \exp(v - \max(u, v)) \right).
\]</span></p>
<p>Because the terms inside the exponentiations are <span class="math inline">\(u - \max(u, v)\)</span> and
<span class="math inline">\(v - \max(u, v)\)</span>, one will be zero, and the other will be negative.
Because the operation is symmetric, it may be assumed without loss of
generality that <span class="math inline">\(u \geq v\)</span>, so that</p>
<p><span class="math display">\[
\mathrm{log\_sum\_exp}(u, v) = u + \log(1 + \exp(v - u)).
\]</span></p>
<p>The inner term may itself be evaluated using <code>log1p</code>, there is only
limited gain because <span class="math inline">\(\exp(v - u)\)</span> is only near zero when <span class="math inline">\(u\)</span> is much
larger than <span class="math inline">\(v\)</span>, meaning the result is likely to round to <span class="math inline">\(u\)</span> anyway.</p>
<p>To conclude, when evaluating <span class="math inline">\(\log (a + b)\)</span> given <span class="math inline">\(\log a\)</span> and <span class="math inline">\(\log b\)</span>, and assuming <span class="math inline">\(\log a &gt; \log b\)</span>, return</p>
<p><span class="math display">\[
\log (a + b) \ = \
\log a + \mathrm{log1p}(\exp(\log b - \log a)).
\]</span></p>
</div>
</div>
<div id="comparing-floating-point-numbers" class="section level2">
<h2><span class="header-section-number">14.4</span> Comparing floating-point numbers</h2>
<p>Because floating-point representations are inexact, it is rarely a
good idea to test exact inequality. The general recommendation is
that rather than testing <code>x == y</code>, an approximate test may be used
given an absolute or relative tolerance.</p>
<p>Given a positive <em>absolute tolerance</em> of <code>epsilon</code>, <code>x</code> can be compared
to <code>y</code> using the conditional</p>
<pre><code>abs(x - y) &lt;= epsilon.</code></pre>
<p>Absolute tolerances work when the scale of <code>x</code> and <code>y</code> and the
relevant comparison is known.</p>
<p>Given a positive <em>relative tolerance</em> of <code>epsilon</code>, a typical
comparison is</p>
<pre><code>2 * abs(x - y) / (abs(x) + abs(y)) &lt;= epsilon.</code></pre>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="25">
<li id="fn25"><p>The notable exception is Intel’s optimizing
compilers under certain optimization settings.<a href="floating-point-arithmetic.html#fnref25" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="part-2-programming-techniques.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="matrices-vectors-and-arrays.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
