<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Stan User’s Guide</title>
  <meta name="description" content="Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Stan User’s Guide" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stan User’s Guide" />
  
  <meta name="twitter:description" content="Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="change-of-variables-chapter.html">
<link rel="next" href="map-reduce-chapter.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Stan User's Guide</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 1. Example Models</i></a></li>
<li class="chapter" data-level="1" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>1</b> Regression Models</a></li>
<li class="chapter" data-level="2" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>2</b> Time-Series Models</a></li>
<li class="chapter" data-level="3" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>3</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="4" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>4</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="5" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="6" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>6</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="7" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>7</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="8" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>8</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="9" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>9</b> Clustering Models</a></li>
<li class="chapter" data-level="10" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>10</b> Gaussian Processes</a></li>
<li class="chapter" data-level="11" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>11</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="12" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>12</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="13" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>13</b> Ordinary Differential Equations</a></li>
<li><a href="part-2-programming-techniques.html#part-2.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 2. Programming Techniques</i></a></li>
<li class="chapter" data-level="14" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>14</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="15" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>15</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="16" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>16</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="17" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>17</b> User-Defined Functions</a></li>
<li class="chapter" data-level="18" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>18</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="19" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>19</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="20" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>20</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="21" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>21</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="22" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>22</b> Map-Reduce</a></li>
<li><a href="appendices-part.html#appendices.part"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="23" data-path="stan-program-style-guide.html"><a href="stan-program-style-guide.html"><i class="fa fa-check"></i><b>23</b> Stan Program Style Guide</a></li>
<li class="chapter" data-level="24" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i><b>24</b> Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan User’s Guide</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="optimization.chapter" class="section level1">
<h1><span class="header-section-number">21</span> Efficiency Tuning</h1>
<p>This chapter provides a grab bag of techniques for optimizing Stan
code, including vectorization, sufficient statistics, and conjugacy.
At a coarse level, efficiency involves both the amount of time
required for a computation and the amount of memory required. For
practical applied statistical modeling, we are mainly concerned with
reducing wall time (how long a program takes as measured by a clock on
the wall) and keeping memory requirements within available bounds.</p>
<div id="what-is-efficiency" class="section level2">
<h2><span class="header-section-number">21.1</span> What is Efficiency?</h2>
<p>The standard algorithm analyses in computer science measure efficiency
asymptotically as a function of problem size (such as data, number of
parameters, etc.) and typically do not consider constant additive
factors like startup times or multiplicative factors like speed of
operations. In practice, the constant factors are important; if run
time can be cut in half or more, that’s a huge gain. This chapter
focuses on both the constant factors involved in efficiency (such as
using built-in matrix operations as opposed to naive loops) and on
asymptotic efficiency factors (such as using linear algorithms instead
of quadratic algorithms in loops).</p>
</div>
<div id="efficiency-for-probabilistic-models-and-algorithms" class="section level2">
<h2><span class="header-section-number">21.2</span> Efficiency for Probabilistic Models and Algorithms</h2>
<p>Stan programs express models which are intrinsically statistical in
nature. The algorithms applied to these models may or may not
themselves be probabilistic. For example, given an initial value for
parameters (which may itself be given deterministically or generated
randomly), Stan’s optimization algorithm (L-BFGS) for penalized
maximum likelihood estimation is purely deterministic. Stan’s
sampling algorithms are based on Markov chain Monte Carlo algorithms,
which are probabilistic by nature at every step. Stan’s variational
inference algorithm (ADVI) is probabilistic despite being an
optimization algorithm; the randomization lies in a nested Monte Carlo
calculation for an expected gradient.</p>
<p>With probabilistic algorithms, there will be variation in run times
(and maybe memory usage) based on the randomization involved. For
example, by starting too far out in the tail, iterative algorithms
underneath the hood, such as the solvers for ordinary differential
equations, may take different numbers of steps. Ideally this
variation will be limited; when there is a lot of variation it can be
a sign that there is a problem with the model’s parameterization in
a Stan program or with initialization.</p>
<p>A well-behaved Stan program will have low variance between runs with
different random initializations and differently seeded random number
generators. But sometimes an algorithm can get stuck in one part of
the posterior, typically due to high curvature. Such sticking almost
always indicates the need to reparameterize the model. Just throwing
away Markov chains with apparently poor behavior (slow, or stuck) can
lead to bias in posterior estimates. This problem with getting stuck
can often be overcome by lowering the initial step size to avoid
getting stuck during adaptation and increasing the target acceptance
rate in order to target a lower step size. This is because smaller
step sizes allow Stan’s gradient-based algorithms to better follow the
curvature in the density or penalized maximum likelihood being fit.</p>
</div>
<div id="statistical-vs.-computational-efficiency" class="section level2">
<h2><span class="header-section-number">21.3</span> Statistical vs.  Computational Efficiency</h2>
<p>There is a difference between pure computational efficiency and
statistical efficiency for Stan programs fit with sampling-based
algorithms. Computational efficiency measures the amount of time or
memory required for a given step in a calculation, such as an
evaluation of a log posterior or penalized likelihood.</p>
<p>Statistical efficiency typically involves requiring fewer steps in
algorithms by making the statistical formulation of a model better
behaved. The typical way to do this is by applying a change of
variables (i.e., reparameterization) so that sampling algorithms mix
better or optimization algorithms require less adaptation.</p>
</div>
<div id="model-conditioning-and-curvature" class="section level2">
<h2><span class="header-section-number">21.4</span> Model Conditioning and Curvature</h2>
<p>Because Stan’s algorithms (other than Riemannian Hamiltonian Monte
Carlo) rely on step-based gradient-based approximations of the density
(or penalized maximum likelihood) being fitted, posterior curvature
not captured by this first-order approximation plays a central role in
determining the statistical efficiency of Stan’s algorithms.</p>
<p>A second-order approximation to curvature is provided by the
Hessian, the matrix of second derivatives of the log density <span class="math inline">\(\log p(\theta)\)</span> with respect to the parameter vector <span class="math inline">\(\theta\)</span>, defined
as
<span class="math display">\[
H(\theta) = \nabla \, \nabla \, \log p(\theta | y),
\]</span>
so that
<span class="math display">\[
H_{i, j}(\theta) = \frac{\partial^2 \log p(\theta | y)}
                {\partial \theta_i \ \partial \theta_j}.
\]</span>
For pure penalized maximum likelihood problems, the posterior log
density <span class="math inline">\(\log p(\theta | y)\)</span> is replaced by the penalized likelihood
function <span class="math inline">\(\mathcal{L}(\theta) = \log p(y | \theta) - \lambda(\theta)\)</span>.</p>
<div id="condition-number-and-adaptation" class="section level3 unnumbered">
<h3>Condition Number and Adaptation</h3>
<p>A good gauge of how difficult a problem the curvature presents is
given by the condition number of the Hessian matrix <span class="math inline">\(H\)</span>, which is the
ratio of the largest to the smallest eigenvalue of <span class="math inline">\(H\)</span> (assuming the
Hessian is positive definite). This essentially measures the
difference between the flattest direction of movement and the most
curved. Typically, the step size of a gradient-based algorithm is
bounded by the most sharply curved direction. With better conditioned
log densities or penalized likelihood functions, it is easier for
Stan’s adaptation, especially the diagonal adaptations that are used
as defaults.</p>
</div>
<div id="unit-scales-without-correlation" class="section level3 unnumbered">
<h3>Unit Scales without Correlation</h3>
<p>Ideally, all parameters should be programmed so that they have unit
scale and so that posterior correlation is reduced; together, these
properties mean that there is no rotation or scaling required for
optimal performance of Stan’s algorithms. For Hamiltonian Monte
Carlo, this implies a unit mass matrix, which requires no adaptation
as it is where the algorithm initializes. Riemannian Hamiltonian
Monte Carlo performs this conditioning on the fly at every step, but
such conditioning is expensive computationally.</p>
</div>
<div id="varying-curvature" class="section level3 unnumbered">
<h3>Varying Curvature</h3>
<p>In all but very simple models (such as multivariate normals), the
Hessian will vary as <span class="math inline">\(\theta\)</span> varies (an extreme example is Neal’s
funnel, as naturally arises in hierarchical models with little or no
data). The more the curvature varies, the harder it is for all of the
algorithms with fixed adaptation parameters (that is, everything but
Riemannian Hamiltonian Monte Carlo) to find adaptations that cover the
entire density well. Many of the variable transforms proposed are
aimed at improving the conditioning of the Hessian and/or making it
more consistent across the relevant portions of the density (or
penalized maximum likelihood function) being fit.</p>
<p>For all of Stan’s algorithms, the curvature along the path from the
initial values of the parameters to the solution is relevant. For
penalized maximum likelihood and variational inference, the solution
of the iterative algorithm will be a single point, so this is all that
matters. For sampling, the relevant “solution” is the typical set,
which is the posterior volume where almost all draws from the
posterior lies; thus, the typical set contains almost all of the
posterior probability mass.</p>
<p>With sampling, the curvature may vary dramatically between the points
on the path from the initialization point to the typical set and
within the typical set. This is why adaptation needs to run long
enough to visit enough points in the typical set to get a good
first-order estimate of the curvature within the typical set. If
adaptation is not run long enough, sampling within the typical set
after adaptation will not be efficient. We generally recommend at
least one hundred iterations after the typical set is reached (and the
first effective draw is ready to be realized). Whether adaptation has
run long enough can be measured by comparing the adaptation parameters
derived from a set of diffuse initial parameter values.</p>
</div>
<div id="reparameterizing-with-a-change-of-variables" class="section level3 unnumbered">
<h3>Reparameterizing with a Change of Variables</h3>
<p>Improving statistical efficiency is achieved by reparameterizing the
model so that the same result may be calculated using a density or
penalized maximum likelihood that is better conditioned. Again, see
the example of reparameterizing Neal’s funnel for an example, and also
the examples in the <a href="change-of-variables-chapter.html#change-of-variables.chapter">change of variables
chapter</a>.</p>
<p>One has to be careful in using change-of-variables reparameterizations
when using maximum likelihood estimation, because they can change the
result if the Jacobian term is inadvertently included in the revised
likelihood model.</p>
</div>
</div>
<div id="well-specified-models" class="section level2">
<h2><span class="header-section-number">21.5</span> Well-Specified Models</h2>
<p>Model misspecification, which roughly speaking means using a model
that doesn’t match the data, can be a major source of slow code. This
can be seen in cases where simulated data according to the model runs
robustly and efficiently, whereas the real data for which it was
intended runs slowly or may even have convergence and mixing issues.
While some of the techniques recommended in the remaining sections of
this chapter may mitigate the problem, the best remedy is a
better model specification.</p>
<p>Counterintuitively, more complicated models often run faster
than simpler models. One common pattern is with a group of parameters
with a wide fixed prior such as <code>normal(0, 1000)</code>). This can fit
slowly due to the mismatch between prior and posterior (the prior has
support for values in the hundreds or even thousands, whereas the
posterior may be concentrated near zero). In such cases, replacing
the fixed prior with a hierarchical prior such as <code>normal(mu,   sigma)</code>, where <code>mu</code> and <code>sigma</code> are new parameters, with
their own hyperpriors.</p>
</div>
<div id="avoiding-validation" class="section level2">
<h2><span class="header-section-number">21.6</span> Avoiding Validation</h2>
<p>Stan validates all of its data structure constraints. For example,
consider a transformed parameter defined to be a covariance matrix and
then used as a covariance parameter in the model block.</p>
<pre><code>transformed parameters {
  cov_matrix[K] Sigma;
  ...
}                               // first validation
model {
  y ~ multi_normal(mu, Sigma);  // second validation
  ...</code></pre>
<p>Becuase <code>Sigma</code> is declared to be a covariance matrix, it will be
factored at the end of the transformed parameter block to ensure that
it is positive definite. The multivariate normal log density function
also validates that <code>Sigma</code> is positive definite. This test is
expensive, having cubic run time (i.e., <span class="math inline">\(\mathcal{O}(N^3)\)</span> for
<span class="math inline">\(N \times N\)</span> matrices), so it should not be done twice.</p>
<p>The test may be avoided by simply declaring <code>Sigma</code> to be a simple
unconstrained matrix.</p>
<pre><code>transformed parameters {
  matrix[K, K] Sigma;
  ...
model {
  y ~ multi_normal(mu, Sigma);  // only validation</code></pre>
<p>Now the only validation is carried out by the multivariate normal.</p>
</div>
<div id="reparameterization.section" class="section level2">
<h2><span class="header-section-number">21.7</span> Reparameterization</h2>
<p>Stan’s sampler can be slow in sampling from distributions with
difficult posterior geometries. One way to speed up such models is
through reparameterization. In some cases, reparameterization can
dramatically increase effective sample size for the same number of
iterations or even make programs that would not converge well
behaved.</p>
<div id="example-neals-funnel" class="section level3 unnumbered">
<h3>Example: Neal’s Funnel</h3>
<p>In this section, we discuss a general transform from a centered to a
non-centered parameterization <span class="citation">(Papaspiliopoulos, Roberts, and Sköld <a href="#ref-papa-et-al:2007">2007</a>)</span>.<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a></p>
<p>This reparameterization is helpful when there is not much data,
because it separates the hierarchical parameters and lower-level
parameters in the prior.</p>
<p><span class="citation">Neal (<a href="#ref-Neal:2003">2003</a>)</span> defines a distribution that exemplifies the difficulties of
sampling from some hierarchical models. Neal’s example is fairly
extreme, but can be trivially reparameterized in such a way as to make
sampling straightforward. Neal’s example has support for <span class="math inline">\(y \in \mathbb{R}\)</span> and <span class="math inline">\(x \in \mathbb{R}^9\)</span> with density</p>
<p><span class="math display">\[
p(y,x) = \mathsf{normal}(y|0,3) * \prod_{n=1}^9
\mathsf{normal}(x_n|0,\exp(y/2)).
\]</span></p>
<p>The probability contours are shaped like ten-dimensional funnels. The
funnel’s neck is particularly sharp because of the exponential
function applied to <span class="math inline">\(y\)</span>. A plot of the log marginal density of <span class="math inline">\(y\)</span>
and the first dimension <span class="math inline">\(x_1\)</span> is shown in the following plot.</p>
<p>The marginal density of Neal’s funnel for the upper-level variable <span class="math inline">\(y\)</span> and one lower-level variable <span class="math inline">\(x_1\)</span> (see the text for the formula). The blue region has log density greater than -8, the yellow region density greater than -16, and the gray background a density less than -16.</p>
<div class="figure">
<img src="img/funnel.png" alt="Neal’s funnel density" />
<p class="caption">Neal’s funnel density</p>
</div>
<p>The funnel can be implemented directly in Stan as follows.</p>
<pre><code>parameters {
  real y;
  vector[9] x;
}
model {
  y ~ normal(0, 3);
  x ~ normal(0, exp(y/2));
}</code></pre>
<p>When the model is expressed this way, Stan has trouble sampling from
the neck of the funnel, where <span class="math inline">\(y\)</span> is small and thus <span class="math inline">\(x\)</span> is constrained
to be near 0. This is due to the fact that the density’s scale
changes with <span class="math inline">\(y\)</span>, so that a step size that works well in the body will
be too large for the neck and a step size that works in the neck will be
inefficient in the body. This can be seen in the following plot.</p>
<p>4000 draws from a run of Stan’s sampler with default settings. Both
plots are restricted to the shown window of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(y\)</span> values; some
draws fell outside of the displayed area as would be expected given
the density. The samples are consistent with the marginal density
<span class="math inline">\(p(y) = \mathsf{normal}(y|0,3)\)</span>, which has mean 0 and standard
deviation 3.</p>
<p><img src="img/funnel-fit.png" /></p>
<p>In this particular instance, because the analytic form of the density
from which samples are drawn is known, the model can be converted to
the following more efficient form.</p>
<pre><code>parameters {
  real y_raw;
  vector[9] x_raw;
}
transformed parameters {
  real y;
  vector[9] x;

  y = 3.0 * y_raw;
  x = exp(y/2) * x_raw;
}
model {
  y_raw ~ std_normal(); // implies y ~ normal(0, 3)
  x_raw ~ std_normal(); // implies x ~ normal(0, exp(y/2))
}</code></pre>
<p>In this second model, the parameters <code>x_raw</code> and <code>y_raw</code> are
sampled as independent standard normals, which is easy for Stan. These
are then transformed into samples from the funnel. In this case, the
same transform may be used to define Monte Carlo samples directly
based on independent standard normal samples; Markov chain Monte Carlo
methods are not necessary. If such a reparameterization were used in
Stan code, it is useful to provide a comment indicating what the
distribution for the parameter implies for the distribution of the
transformed parameter.</p>
</div>
<div id="reparameterizing-the-cauchy" class="section level3 unnumbered">
<h3>Reparameterizing the Cauchy</h3>
<p>Sampling from heavy tailed distributions such as the Cauchy is
difficult for Hamiltonian Monte Carlo, which operates within a
Euclidean geometry.<a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a></p>
<p>The practical problem is that tail of the Cauchy
requires a relatively large step size compared to the trunk. With a
small step size, the No-U-Turn sampler requires many steps when
starting in the tail of the distribution; with a large step size,
there will be too much rejection in the central portion of the
distribution. This problem may be mitigated by defining the
Cauchy-distributed variable as the transform of a uniformly
distributed variable using the Cauchy inverse cumulative distribution
function.</p>
<p>Suppose a random variable of interest <span class="math inline">\(X\)</span> has a Cauchy distribution
with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\tau\)</span>, so that <span class="math inline">\(X \sim \mathsf{Cauchy}(\mu,\tau)\)</span>. The variable <span class="math inline">\(X\)</span> has a cumulative
distribution function <span class="math inline">\(F_X:\mathbb{R} \rightarrow (0,1)\)</span> defined by
<span class="math display">\[
F_X(x) = \frac{1}{\pi} \arctan \left( \frac{x - \mu}{\tau} \right) +
\frac{1}{2}.
\]</span>
The inverse of the cumulative distribution function,
<span class="math inline">\(F_X^{-1}:(0,1) \rightarrow \mathbb{R}\)</span>, is thus</p>
<p><span class="math display">\[
F^{-1}_X(y) = \mu + \tau \tan \left( \pi \left( y - \frac{1}{2} \right) \right).
\]</span>
Thus if the random variable <span class="math inline">\(Y\)</span> has a unit uniform distribution, <span class="math inline">\(Y \sim \mathsf{Uniform}(0,1)\)</span>, then <span class="math inline">\(F^{-1}_X(Y)\)</span> has a Cauchy
distribution with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\tau\)</span>, i.e., <span class="math inline">\(F^{-1}_X(Y) \sim \mathsf{Cauchy}(\mu,\tau)\)</span>.</p>
<p>Consider a Stan program involving a Cauchy-distributed parameter
<code>beta</code>.</p>
<pre><code>parameters {
  real beta;
  ...
}
model {
  beta ~ cauchy(mu, tau);
  ...
}</code></pre>
<p>This declaration of <code>beta</code> as a parameter may be replaced with a
transformed parameter <code>beta</code> defined in terms of a
uniform-distributed parameter <code>beta_unif</code>.</p>
<pre><code>parameters {
  real&lt;lower=-pi()/2, upper=pi()/2&gt; beta_unif;
  ...
}
transformed parameters {
  real beta;
  beta = mu + tau * tan(beta_unif);  // beta ~ cauchy(mu, tau)
}
model {
  beta_unif ~ uniform(-pi()/2, pi()/2);  // not necessary
  ...
}</code></pre>
<p>It is more convenient in Stan to transform a uniform variable on
<span class="math inline">\((-\pi/2, \pi/2)\)</span> than one on <span class="math inline">\((0,1)\)</span>. The Cauchy location and scale
parameters, <code>mu</code> and <code>tau</code>, may be defined as data or may
themselves be parameters. The variable <code>beta</code> could also be
defined as a local variable if it does not need to be included in the
sampler’s output.</p>
<p>The uniform distribution on <code>beta_unif</code> is defined explicitly in
the model block, but it could be safely removed from the program
without changing sampling behavior. This is because <span class="math inline">\(\log \mathsf{Uniform}(\beta_{\mathrm{unif}}|-\pi/2,\pi/2) = -\log \pi\)</span> is a constant and Stan only
needs the total log probability up to an additive constant. Stan will spend
some time checking that that <code>beta_unif</code> is between
<code>-pi()/2</code> and <code>pi()/2</code>, but this condition is guaranteed by
the constraints in the declaration of <code>beta_unif</code>.</p>
</div>
<div id="reparameterizing-a-student-t-distribution" class="section level3 unnumbered">
<h3>Reparameterizing a Student-t Distribution</h3>
<p>One thing that sometimes works when you’re having trouble with the
heavy-tailedness of Student-t distributions is to use the
gamma-mixture representation, which says that you can generate a
Student-t distributed variable <span class="math inline">\(\beta\)</span>,
<span class="math display">\[
\beta \sim \mbox{\sf Student-t}(\nu, 0, 1),
\]</span>
by first generating a gamma-distributed precision (inverse variance)
<span class="math inline">\(\tau\)</span> according to
<span class="math display">\[
\tau \sim \mbox{\sf Gamma}(\nu/2, \nu/2),
\]</span>
and then generating <span class="math inline">\(\beta\)</span> from the normal distribution,
<span class="math display">\[
\beta \sim \mbox{\sf normal}(0,\tau^{-\frac{1}{2}}).
\]</span></p>
<p>Because <span class="math inline">\(\tau\)</span> is precision, <span class="math inline">\(\tau^{-\frac{1}{2}}\)</span> is the scale
(standard deviation), which is the parameterization used by Stan.</p>
<p>The marginal distribution of <span class="math inline">\(\beta\)</span> when you integrate out <span class="math inline">\(\tau\)</span> is
<span class="math inline">\(\mbox{\sf Student-t}(\nu, 0, 1)\)</span>, i.e.,
<span class="math display">\[
\mbox{\sf Student-t}(\beta | \nu, 0, 1).
=
\int_0^{\infty}
\,
\mbox{normal}(\beta | 0, \tau^{-0.5})
*
\mbox{Gamma}(\tau | \nu/2, \nu/2)
\
\mathrm{d} \tau.
\]</span></p>
<p>To go one step further, instead of defining a <span class="math inline">\(\beta\)</span> drawn from a
normal with precision <span class="math inline">\(\tau\)</span>, define <span class="math inline">\(\alpha\)</span> to be drawn from a unit
normal,</p>
<p><span class="math display">\[
\alpha \sim \mbox{normal}(0,1)
\]</span></p>
<p>and rescale by defining</p>
<p><span class="math display">\[
\beta = \alpha \, \tau^{-\frac{1}{2}}.
\]</span></p>
<p>Now suppose <span class="math inline">\(\mu = \beta x\)</span> is the product of <span class="math inline">\(\beta\)</span> with a
regression predictor <span class="math inline">\(x\)</span>. Then the reparameterization <span class="math inline">\(\mu = \alpha \tau^{-\frac{1}{2}} x\)</span> has the same distribution, but in the original, direct
parameterization, <span class="math inline">\(\beta\)</span> has (potentially) heavy tails, whereas in
the second, neither <span class="math inline">\(\tau\)</span> nor <span class="math inline">\(\alpha\)</span> have heavy tails.</p>
<p>To translate into Stan notation, this reparameterization replaces</p>
<pre><code>parameters {
  real&lt;lower=0&gt; nu;
  real beta;
  ...
model {
  beta ~ student_t(nu, 0, 1);
  ...</code></pre>
<p>with</p>
<pre><code>parameters {
  real&lt;lower=0&gt; nu;
  real&lt;lower=0&gt; tau;
  real alpha;
  ...
transformed parameters {
  real beta;
  beta = alpha / sqrt(tau);
  ...
model {
  real half_nu;
  half_nu = 0.5 * nu;
  tau ~ gamma(half_nu, half_nu);
  alpha ~ std_normal();
  ...</code></pre>
<p>Although set to <code>0</code> here, in most cases, the lower bound for the
degrees of freedom parameter <code>nu</code> can be set to <code>1</code> or
higher; when <code>nu</code> is 1, the result is a Cauchy distribution with
fat tails and as <code>nu</code> approaches infinity, the Student-t
distribution approaches a normal distribution. Thus the parameter
<code>nu</code> characterizes the heaviness of the tails of the model.</p>
</div>
<div id="hierarchical-models-and-the-non-centered-parameterization" class="section level3 unnumbered">
<h3>Hierarchical Models and the Non-Centered Parameterization</h3>
<p>Unfortunately, the usual situation in applied Bayesian modeling
involves complex geometries and interactions that are not known
analytically. Nevertheless, reparameterization can still be
effective for separating parameters.</p>
<div id="centered-parameterization" class="section level4 unnumbered">
<h4>Centered parameterization</h4>
<p>For example, a vectorized hierarchical model might draw a vector of
coefficients <span class="math inline">\(\beta\)</span> with definitions as follows. The so-called
centered parameterization is as follows.</p>
<pre><code>parameters {
  real mu_beta;
  real&lt;lower=0&gt; sigma_beta;
  vector[K] beta;
  ...
model {
  beta ~ normal(mu_beta, sigma_beta);
  ...</code></pre>
<p>Although not shown, a full model will have priors on both
<code>mu_beta</code> and <code>sigma_beta</code> along with data modeled based on
these coefficients. For instance, a standard binary logistic
regression with data matrix <code>x</code> and binary outcome vector
<code>y</code> would include a likelihood statement such as form
<code>y ~ bernoulli_logit(x * beta)</code>, leading to an analytically
intractable posterior.</p>
<p>A hierarchical model such as the above will suffer from the same kind
of inefficiencies as Neal’s funnel, because the values of <code>beta</code>,
<code>mu_beta</code> and <code>sigma_beta</code> are highly correlated in the
posterior. The extremity of the correlation depends on the amount of
data, with Neal’s funnel being the extreme with no data. In these
cases, the non-centered parameterization, discussed in the next
section, is preferable; when there is a lot of data, the centered
parameterization is more efficient. See
<span class="citation">Betancourt and Girolami (<a href="#ref-Betancourt-Girolami:2013">2013</a>)</span> for more information on the effects of
centering in hierarchical models fit with Hamiltonian Monte Carlo.</p>
</div>
</div>
<div id="non-centered-parameterization" class="section level3 unnumbered">
<h3>Non-Centered Parameterization</h3>
<p>Sometimes the group-level effects do not constrain the hierarchical
distribution tightly. Examples arise when there is not many groups,
or when the inter-group variation is high. In such cases,
hierarchical models can be made much more efficient by shifting the
data’s correlation with the parameters to the hyperparameters. Similar
to the funnel example, this will be much more efficient in terms of
effective sample size when there is not much data (see
<span class="citation">Betancourt and Girolami (<a href="#ref-Betancourt-Girolami:2013">2013</a>)</span>), and in more extreme cases will be
necessary to achieve convergence.</p>
<pre><code>parameters {
  vector[K] beta_raw;
  ...
transformed parameters {
  vector[K] beta;
  // implies: beta ~ normal(mu_beta, sigma_beta)
  beta = mu_beta + sigma_beta * beta_raw;
model {
  beta_raw ~ std_normal();
  ...</code></pre>
<p>Any priors defined for <code>mu_beta</code> and <code>sigma_beta</code> remain as
defined in the original model.</p>
<p>Reparameterization of hierarchical models is not limited to the normal
distribution, although the normal distribution is the best candidate
for doing so. In general, any distribution of parameters in the
location-scale family is a good candidate for reparameterization. Let
<span class="math inline">\(\beta = l + s\alpha\)</span> where <span class="math inline">\(l\)</span> is a location parameter and <span class="math inline">\(s\)</span> is a
scale parameter. The parameter <span class="math inline">\(l\)</span> need not be the mean, <span class="math inline">\(s\)</span> need not
be the standard deviation, and neither the mean nor the standard
deviation need to exist. If <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are from the same
distributional family but <span class="math inline">\(\alpha\)</span> has location zero and unit scale,
while <span class="math inline">\(\beta\)</span> has location <span class="math inline">\(l\)</span> and scale <span class="math inline">\(s\)</span>, then that distribution
is a location-scale distribution. Thus, if <span class="math inline">\(\alpha\)</span> were a parameter
and <span class="math inline">\(\beta\)</span> were a transformed parameter, then a prior distribution
from the location-scale family on <span class="math inline">\(\alpha\)</span> with location zero and unit
scale implies a prior distribution on <span class="math inline">\(\beta\)</span> with location <span class="math inline">\(l\)</span> and
scale <span class="math inline">\(s\)</span>. Doing so would reduce the dependence between <span class="math inline">\(\alpha\)</span>,
<span class="math inline">\(l\)</span>, and <span class="math inline">\(s\)</span>.</p>
<p>There are several univariate distributions in the location-scale
family, such as the Student t distribution, including its special
cases of the Cauchy distribution (with one degree of freedom) and the
normal distribution (with infinite degrees of freedom). As shown above,
if <span class="math inline">\(\alpha\)</span> is distributed standard normal, then <span class="math inline">\(\beta\)</span> is distributed
normal with mean <span class="math inline">\(\mu = l\)</span> and standard deviation <span class="math inline">\(\sigma = s\)</span>. The
logistic, the double exponential, the generalized extreme value
distributions, and the stable distribution are also in the
location-scale family.</p>
<p>Also, if <span class="math inline">\(z\)</span> is distributed standard normal, then <span class="math inline">\(z^2\)</span> is distributed
chi-squared with one degree of freedom. By summing the squares of <span class="math inline">\(K\)</span>
independent standard normal variates, one can obtain a single variate
that is distributed chi-squared with <span class="math inline">\(K\)</span> degrees of freedom. However,
for large <span class="math inline">\(K\)</span>, the computational gains of this reparameterization may
be overwhelmed by the computational cost of specifying <span class="math inline">\(K\)</span> primitive
parameters just to obtain one transformed parameter to use in a model.</p>
</div>
<div id="multivariate-reparameterizations" class="section level3 unnumbered">
<h3>Multivariate Reparameterizations</h3>
<p>The benefits of reparameterization are not limited to univariate
distributions. A parameter with a multivariate normal prior distribution
is also an excellent candidate for reparameterization. Suppose you intend
the prior for <span class="math inline">\(\beta\)</span> to be multivariate normal with mean vector <span class="math inline">\(\mu\)</span>
and covariance matrix <span class="math inline">\(\Sigma\)</span>. Such a belief is reflected by the
following code.</p>
<pre><code>data {
  int&lt;lower=2&gt; K;
  vector[K] mu;
  cov_matrix[K] Sigma;
  ...
parameters {
  vector[K] beta;
  ...
model {
  beta ~ multi_normal(mu, Sigma);
  ...</code></pre>
<p>In this case <code>mu</code> and <code>Sigma</code> are fixed data, but they could
be unknown parameters, in which case their priors would be unaffected
by a reparameterization of <code>beta</code>.</p>
<p>If <span class="math inline">\(\alpha\)</span> has the same dimensions as <span class="math inline">\(\beta\)</span> but the elements of
<span class="math inline">\(\alpha\)</span> are independently and identically distributed standard normal
such that <span class="math inline">\(\beta = \mu + L\alpha\)</span>, where <span class="math inline">\(LL^\top = \Sigma\)</span>, then
<span class="math inline">\(\beta\)</span> is distributed multivariate normal with mean vector <span class="math inline">\(\mu\)</span> and
covariance matrix <span class="math inline">\(\Sigma\)</span>. One choice for <span class="math inline">\(L\)</span> is the Cholesky factor
of <span class="math inline">\(\Sigma\)</span>. Thus, the model above could be reparameterized as follows.</p>
<pre><code>data {
  int&lt;lower=2&gt; K;
  vector[K] mu;
  cov_matrix[K] Sigma;
  ...
transformed data {
  matrix[K, K] L;
  L = cholesky_decompose(Sigma);
}
parameters {
  vector[K] alpha;
  ...
transformed parameters {
  vector[K] beta;
  beta = mu + L * alpha;
}
model {
  alpha ~ std_normal();
  // implies: beta ~ multi_normal(mu, Sigma)
  ...</code></pre>
<p>This reparameterization is more efficient for two reasons. First, it
reduces dependence among the elements of <code>alpha</code> and second, it
avoids the need to invert <code>Sigma</code> every time <code>multi_normal</code>
is evaluated.</p>
<p>The Cholesky factor is also useful when a covariance matrix is
decomposed into a correlation matrix that is multiplied from both
sides by a diagonal matrix of standard deviations, where either the
standard deviations or the correlations are unknown parameters. The
Cholesky factor of the covariance matrix is equal to the product of
a diagonal matrix of standard deviations and the Cholesky factor of
the correlation matrix. Furthermore, the product of a diagonal matrix
of standard deviations and a vector is equal to the elementwise
product between the standard deviations and that vector. Thus, if for
example the correlation matrix <code>Tau</code> were fixed data but the
vector of standard deviations <code>sigma</code> were unknown parameters,
then a reparameterization of <code>beta</code> in terms of <code>alpha</code>
could be implemented as follows.</p>
<pre><code>data {
  int&lt;lower=2&gt; K;
  vector[K] mu;
  corr_matrix[K] Tau;
  ...
transformed data {
  matrix[K, K] L;
  L = cholesky_decompose(Tau);
}
parameters {
  vector[K] alpha;
  vector&lt;lower=0&gt;[K] sigma;
  ...
transformed parameters {
  vector[K] beta;
  // This equals mu + diag_matrix(sigma) * L * alpha;
  beta = mu + sigma .* (L * alpha);
}
model {
  sigma ~ cauchy(0, 5);
  alpha ~ std_normal();
  // implies: beta ~ multi_normal(mu,
  //  diag_matrix(sigma) * L * L&#39; * diag_matrix(sigma)))
  ...</code></pre>
<p>This reparameterization of a multivariate normal distribution in
terms of standard normal variates can be extended to other multivariate
distributions that can be conceptualized as contaminations of the
multivariate normal, such as the multivariate Student t and the skew
multivariate normal distribution.</p>
<p>A Wishart distribution can also be reparameterized in terms of standard
normal variates and chi-squared variates. Let <span class="math inline">\(L\)</span> be the Cholesky factor
of a <span class="math inline">\(K \times K\)</span> positive definite scale matrix <span class="math inline">\(S\)</span> and let <span class="math inline">\(\nu\)</span> be
the degrees of freedom. If</p>
<p><span class="math display">\[\begin{equation*}
A = \left( \begin{array}{cccc}
\sqrt{c_{1}} &amp; 0 &amp; \cdots &amp; 0\\
z_{21} &amp; \sqrt{c_{2}} &amp; \ddots &amp; \vdots\\
\vdots &amp; \ddots &amp; \ddots &amp; 0\\
z_{K1} &amp; \cdots &amp; z_{K\left(K-1\right)} &amp; \sqrt{c_{K}}
 \end{array} \right),
\end{equation*}\]</span></p>
<p>where each <span class="math inline">\(c_i\)</span> is distributed chi-squared with <span class="math inline">\(\nu - i + 1\)</span> degrees
of freedom and each <span class="math inline">\(z_{ij}\)</span> is distributed standard normal, then
<span class="math inline">\(W = LAA^{\top}L^{\top}\)</span> is distributed Wishart with scale matrix
<span class="math inline">\(S = LL^{\top}\)</span> and degrees of freedom <span class="math inline">\(\nu\)</span>. Such a reparameterization
can be implemented by the following Stan code:</p>
<pre><code>data {
  int&lt;lower=1&gt; N;
  int&lt;lower=1&gt; K;
  int&lt;lower=K+2&gt; nu
  matrix[K, K] L; // Cholesky factor of scale matrix
  vector[K] mu;
  matrix[N, K] y;
  ...
parameters {
  vector&lt;lower=0&gt;[K] c;
  vector[0.5 * K * (K - 1)] z;
  ...
model {
  matrix[K, K] A;
  int count = 1;
  for (j in 1:(K-1)) {
    for (i in (j+1):K) {
      A[i, j] = z[count];
      count += 1;
    }
    for (i in 1:(j - 1)) {
      A[i, j] = 0.0;
    }
    A[j, j] = sqrt(c[j]);
  }
  for (i in 1:(K-1))
    A[i, K] = 0;
  A[K, K] = sqrt(c[K]);

  for (i in 1:K)
    c[i] ~ chi_square(nu - i + 1);

  z ~ std_normal();
  // implies: L * A * A&#39; * L&#39; ~ wishart(nu, L * L&#39;)
  y ~ multi_normal_cholesky(mu, L * A);
  ...</code></pre>
<p>This reparameterization is more efficient for three reasons. First, it
reduces dependence among the elements of <code>z</code> and second, it
avoids the need to invert the covariance matrix, <span class="math inline">\(W\)</span> every time
<code>wishart</code> is evaluated. Third, if <span class="math inline">\(W\)</span> is to be used with a
multivariate normal distribution, you can pass <span class="math inline">\(L A\)</span> to the more
efficient <code>multi_normal_cholesky</code> function, rather than passing
<span class="math inline">\(W\)</span> to <code>multi_normal</code>.</p>
<p>If <span class="math inline">\(W\)</span> is distributed Wishart with scale matrix <span class="math inline">\(S\)</span> and degrees of
freedom <span class="math inline">\(\nu\)</span>, then <span class="math inline">\(W^{-1}\)</span> is distributed inverse Wishart with inverse
scale matrix <span class="math inline">\(S^{-1}\)</span> and degrees of freedom <span class="math inline">\(\nu\)</span>. Thus, the previous
result can be used to reparameterize the inverse Wishart distribution.
Since <span class="math inline">\(W = L * A * A^{\top} * L^{\top}\)</span>,
<span class="math inline">\(W^{-1} = L^{{\top}^{-1}} A^{{\top}^{-1}} A^{-1} L^{-1}\)</span>, where all four
inverses exist, but
<span class="math inline">\(L^{{-1}^{\top}} = L^{{\top}^{-1}}\)</span> and <span class="math inline">\(A^{{-1}^{\top}} = A^{{\top}^{-1}}\)</span>.
We can slightly modify the above Stan code for this case:</p>
<pre><code>data {
  int&lt;lower=1&gt; K;
  int&lt;lower=K+2&gt; nu
  matrix[K, K] L; // Cholesky factor of scale matrix
  ...
transformed data {
  matrix[K, K] eye;
  matrix[K, K] L_inv;
  for (j in 1:K) {
    for (i in 1:K) {
      eye[i, j] = 0.0;
    }
    eye[j, j] = 1.0;
  }
  L_inv = mdivide_left_tri_low(L, eye);
}
parameters {
  vector&lt;lower=0&gt;[K] c;
  vector[0.5 * K * (K - 1)] z;
  ...
model {
  matrix[K, K] A;
  matrix[K, K] A_inv_L_inv;
  int count;
  count = 1;
  for (j in 1:(K-1)) {
    for (i in (j+1):K) {
      A[i, j] = z[count];
      count += 1;
    }
    for (i in 1:(j - 1)) {
      A[i, j] = 0.0;
    }
    A[j, j] = sqrt(c[j]);
  }
  for (i in 1:(K-1))
    A[i, K] = 0;
  A[K, K] = sqrt(c[K]);

  A_inv_L_inv = mdivide_left_tri_low(A, L_inv);
  for (i in 1:K)
    c[i] ~ chi_square(nu - i + 1);

  z ~ std_normal(); // implies: crossprod(A_inv_L_inv) ~
  // inv_wishart(nu, L_inv&#39; * L_inv)
  ...</code></pre>
<p>Another candidate for reparameterization is the Dirichlet distribution
with all <span class="math inline">\(K\)</span> shape parameters equal. <span class="citation">Zyczkowski and Sommers (<a href="#ref-ZyczkowskiSommers:2001">2001</a>)</span> shows
that if <span class="math inline">\(\theta_i\)</span> is equal to the sum of <span class="math inline">\(\beta\)</span> independent squared
standard normal variates and <span class="math inline">\(\rho_i = \frac{\theta_i}{\sum \theta_i}\)</span>,
then the <span class="math inline">\(K\)</span>-vector <span class="math inline">\(\rho\)</span> is distributed Dirichlet with all shape
parameters equal to <span class="math inline">\(\frac{\beta}{2}\)</span>. In particular, if <span class="math inline">\(\beta = 2\)</span>,
then <span class="math inline">\(\rho\)</span> is uniformly distributed on the unit simplex. Thus, we can
make <span class="math inline">\(\rho\)</span> be a transformed parameter to reduce dependence, as in:</p>
<pre><code>data {
  int&lt;lower=1&gt; beta;
  ...
parameters {
  vector[beta] z[K];
  ...
transformed parameters {
  simplex[K] rho;
  for (k in 1:K)
    rho[k] = dot_self(z[k]); // sum-of-squares
  rho = rho / sum(rho);
}
model {
  for (k in 1:K)
    z[k] ~ std_normal();
  // implies: rho ~ dirichlet(0.5 * beta * ones)
  ...</code></pre>
</div>
</div>
<div id="vectorization" class="section level2">
<h2><span class="header-section-number">21.8</span> Vectorization</h2>
<div id="gradient-bottleneck" class="section level3 unnumbered">
<h3>Gradient Bottleneck</h3>
<p>Stan spends the vast majority of its time computing the gradient of
the log probability function, making gradients the obvious target for
optimization. Stan’s gradient calculations with algorithmic
differentiation require a template expression to be allocated
and constructed for each subexpression of a Stan program involving
parameters or transformed parameters.<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a> This section defines optimization strategies based on vectorizing these subexpressions to reduce the work done during algorithmic differentiation.</p>
</div>
<div id="vectorizing-summations" class="section level3 unnumbered">
<h3>Vectorizing Summations</h3>
<p>Because of the gradient bottleneck described in the previous section,
it is more efficient to collect a sequence of summands into a vector
or array and then apply the <code>sum()</code> operation than it is to
continually increment a variable by assignment and addition. For
example, consider the following code snippet, where <code>foo()</code> is
some operation that depends on <code>n</code>.</p>
<pre><code>for (n in 1:N)
  total += foo(n,...);</code></pre>
<p>This code has to create intermediate representations for each
of the <code>N</code> summands.</p>
<p>A faster alternative is to copy the values into a vector, then
apply the <code>sum()</code> operator, as in the following refactoring.</p>
<pre><code>{
  vector[N] summands;
  for (n in 1:N)
    summands[n] = foo(n,...);
  total = sum(summands);
}</code></pre>
<p>Syntactically, the replacement is a statement block delineated
by curly brackets (<code>{</code>, <code>}</code>), starting with the definition
of the local variable <code>summands</code>.</p>
<p>Even though it involves extra work to allocate the <code>summands</code>
vector and copy <code>N</code> values into it, the savings in
differentiation more than make up for it. Perhaps surprisingly,
it will also use substantially less memory overall than incrementing
<code>total</code> within the loop.</p>
</div>
<div id="vectorization-through-matrix-operations" class="section level3 unnumbered">
<h3>Vectorization through Matrix Operations</h3>
<p>The following program directly encodes a linear regression with fixed
unit noise using a two-dimensional array <code>x</code> of predictors, an
array <code>y</code> of outcomes, and an array <code>beta</code> of regression
coefficients.</p>
<pre><code>data {
  int&lt;lower=1&gt; K;
  int&lt;lower=1&gt; N;
  real x[K, N];
  real y[N];
}
parameters {
  real beta[K];
}
model {
  for (n in 1:N) {
    real gamma = 0;
    for (k in 1:K)
      gamma += x[n, k] * beta[k];
    y[n] ~ normal(gamma, 1);
  }
}</code></pre>
<p>The following model computes the same log probability function as the
previous model, even supporting the same input files for data and
initialization.</p>
<pre><code>data {
  int&lt;lower=1&gt; K;
  int&lt;lower=1&gt; N;
  vector[K] x[N];
  real y[N];
}
parameters {
  vector[K] beta;
}
model {
  for (n in 1:N)
    y[n] ~ normal(dot_product(x[n], beta), 1);
}</code></pre>
<p>Although it produces equivalent results, the dot product should not be
replaced with a transpose and multiply, as in</p>
<pre><code>        y[n] ~ normal(x[n]&#39; * beta, 1);</code></pre>
<p>The relative inefficiency of the transpose and multiply approach is
that the transposition operator allocates a new vector into which the
result of the transposition is copied. This consumes both time
and memory.<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></p>
<p>The inefficiency of transposition could itself be mitigated by
reordering the product and pulling the transposition out of the loop,
as follows.</p>
<pre><code>...
transformed parameters {
  row_vector[K] beta_t;
  beta_t = beta&#39;;
}
model {
  for (n in 1:N)
    y[n] ~ normal(beta_t * x[n], 1);
}</code></pre>
<p>The problem with transposition could be completely solved by directly
encoding the <code>x</code> as a row vector, as in the
following example.</p>
<pre><code>data {
  ...
  row_vector[K] x[N];
  ...
}
parameters {
  vector[K] beta;
}
model {
  for (n in 1:N)
    y[n] ~ normal(x[n] * beta, 1);
}</code></pre>
<p>Declaring the data as a matrix and then computing all the predictors
at once using matrix multiplication is more efficient still, as in the
example discussed in the next section.</p>
<p>Having said all this, the most efficient way to code this model is
with direct matrix multiplication, as in</p>
<pre><code>data {
  matrix[N, K] x;
  vector[N] y;
}
parameters {
  vector[K] beta;
}
model {
  y ~ normal(x * beta, 1);</code></pre>
<p>In general, encapsulated single operations that do the work of loops
will be more efficient in their encapsulated forms. Rather than
performing a sequence of row-vector/vector multipliations, it is
better to encapsulate it as a single matrix/vector multiplication.</p>
</div>
<div id="vectorized-probability-functions" class="section level3 unnumbered">
<h3>Vectorized Probability Functions</h3>
<p>The final and most efficient version replaces the loops and
transformed parameters by using the vectorized form of the normal
probability function, as in the following example.</p>
<pre><code>data {
  int&lt;lower=1&gt; K;
  int&lt;lower=1&gt; N;
  matrix[N, K] x;
  vector[N] y;
}
parameters {
  vector[K] beta;
}
model {
  y ~ normal(x * beta, 1);
}</code></pre>
<p>The variables are all declared as either matrix or vector types.
The result of the matrix-vector multiplication <code>x * beta</code> in the
model block is a vector of the same length as <code>y</code>.</p>
<p>The probability function documentation in the function reference
manual indicates which of Stan’s probability functions support
vectorization; see the function reference manual for full details.
Vectorized probability functions accept either vector or scalar inputs
for all arguments, with the only restriction being that all vector
arguments are the same dimensionality. In the example above, <code>y</code> is a
vector of size <code>N</code>, <code>x * beta</code> is a vector of size <code>N</code>, and <code>1</code> is a
scalar.</p>
</div>
<div id="reshaping-data-for-vectorization" class="section level3 unnumbered">
<h3>Reshaping Data for Vectorization</h3>
<p>Sometimes data does not arrive in a shape that is ideal for
vectorization, but can be put into such shape with some munging
(either inside Stan’s transformed data block or outside).</p>
<p>John Hall provided a simple example on the Stan users group.
Simplifying notation a bit, the original model had a sampling
statement in a loop, as follows.</p>
<pre><code>for (n in 1:N)
  y[n] ~ normal(mu[ii[n]], sigma);</code></pre>
<p>The brute force vectorization would build up a mean vector and then
vectorize all at once.</p>
<pre><code>{
  vector[N] mu_ii;
  for (n in 1:N)
    mu_ii[n] = mu[ii[n]];
  y ~ normal(mu_ii, sigma);</code></pre>
<p>If there aren’t many levels (values <code>ii[n]</code> can take), then it
behooves us to reorganize the data by group in a case like this.
Rather than having a single observation vector <code>y</code>, there are K of them.
And because Stan doesn’t support ragged arrays, it means K
declarations. For instance, with 5 levels, we have</p>
<pre><code>  y_1 ~ normal(mu[1], sigma);
  ...
  y_5 ~ normal(mu[5], sigma);</code></pre>
<p>This way, both the <code>mu</code> and <code>sigma</code> parameters are shared.
Which way works out to be more efficient will depend on the shape of
the data; if the sizes are small, the simple vectorization may be
faster, but for moderate to large sized groups, the full expansion
should be faster.</p>
</div>
</div>
<div id="exploiting-sufficient-statistics" class="section level2">
<h2><span class="header-section-number">21.9</span> Exploiting Sufficient Statistics</h2>
<p>In some cases, models can be recoded to exploit sufficient statistics
in estimation. This can lead to large efficiency gains compared to an
expanded model. For example, consider the following Bernoulli
sampling model.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  int&lt;lower=0, upper=1&gt; y[N];
  real&lt;lower=0&gt; alpha;
  real&lt;lower=0&gt; beta;
}
parameters {
  real&lt;lower=0, upper=1&gt; theta;
}
model {
  theta ~ beta(alpha, beta);
  for (n in 1:N)
    y[n] ~ bernoulli(theta);
}</code></pre>
<p>In this model, the sum of positive outcomes in <code>y</code> is a
sufficient statistic for the chance of success <code>theta</code>. The
model may be recoded using the binomial distribution as follows.</p>
<pre><code>    theta ~ beta(alpha, beta);
    sum(y) ~ binomial(N, theta);</code></pre>
<p>Because truth is represented as one and falsehood as zero, the sum
<code>sum(y)</code> of a binary vector <code>y</code> is equal to the number of
positive outcomes out of a total of <code>N</code> trials.</p>
<p>This can be generalized to other discrete cases (one wouldn’t expect
continuous observations to be duplicated if they are random). Suppose
there are only <span class="math inline">\(K\)</span> possible discrete outcomes, <span class="math inline">\(z_1, \ldots, z_K\)</span>, but
there are <span class="math inline">\(N\)</span> observations, where <span class="math inline">\(N\)</span> is much larger than <span class="math inline">\(K\)</span>. If
<span class="math inline">\(f_k\)</span> is the frequency of outcome <span class="math inline">\(z_k\)</span>, then the entire likelihood
with distribution <code>foo</code> can be coded as follows.</p>
<pre><code>for (k in 1:K)
  target += f[k] * foo_lpmf(z[k] | ...);</code></pre>
<p>where the ellipses are the parameters of the log probability mass
function for distribution <code>foo</code> (there’s no distribution called
``foo&quot;; this is just a placeholder for any discrete distribution
name).</p>
<p>The resulting program looks like a “weighted” regression, but here
the weights <code>f[k]</code> are counts and thus sufficient statistics for
the pmf and simply amount to an alternative, more efficient coding of
the same likelihood. For efficiency, the frequencies <code>f[k]</code>
should be counted once in the transformed data block and stored.</p>
</div>
<div id="aggregating-common-subexpressions" class="section level2">
<h2><span class="header-section-number">21.10</span> Aggregating Common Subexpressions</h2>
<p>If an expression is calculated once, the value should be saved and
reused wherever possible. That is, rather than using
<code>exp(theta)</code> in multiple places, declare a local variable to
store its value and reuse the local variable.</p>
<p>Another case that may not be so obvious is with two multilevel
parameters, say <code>a[ii[n]] + b[jj[n]]</code>. If <code>a</code> and <code>b</code>
are small (i.e., do not have many levels), then a table <code>a_b</code> of
their sums can be created, with</p>
<pre><code>matrix[size(a), size(b)] a_b;
for (i in 1:size(a))
  for (j in 1:size(b))
    a_b[i, j] = a[i] + b[j];</code></pre>
<p>Then the sum can be replaced with <code>a_b[ii[n], jj[n]]</code>.</p>
</div>
<div id="exploiting-conjugacy" class="section level2">
<h2><span class="header-section-number">21.11</span> Exploiting Conjugacy</h2>
<p>Continuing the model from the previous section, the conjugacy of the
beta prior and binomial sampling distribution allow the model to be
further optimized to the following equivalent form.</p>
<pre><code>    theta ~ beta(alpha + sum(y), beta + N - sum(y));</code></pre>
<p>To make the model even more efficient, a transformed data variable
defined to be <code>sum(y)</code> could be used in the place of <code>sum(y)</code>.</p>
</div>
<div id="standardizing-predictors-and-outputs" class="section level2">
<h2><span class="header-section-number">21.12</span> Standardizing Predictors and Outputs</h2>
<p>Stan programs will run faster if the input is standardized to have a
zero sample mean and unit sample variance. This section illustrates
the principle with a simple linear regression.</p>
<p>Suppose that <span class="math inline">\(y = (y_1,\ldots,y_N)\)</span> is a sequence of <span class="math inline">\(N\)</span> outcomes and
<span class="math inline">\(x = (x_1,\ldots,x_N)\)</span> a parallel sequence of <span class="math inline">\(N\)</span> predictors. A
simple linear regression involving an intercept coefficient <span class="math inline">\(\alpha\)</span>
and slope coefficient <span class="math inline">\(\beta\)</span> can be expressed as
<span class="math display">\[
y_n = \alpha + \beta x_n + \epsilon_n,
\]</span>
where
<span class="math display">\[
\epsilon_n \sim \mathsf{normal}(0,\sigma).
\]</span></p>
<p>If either vector <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span> has very large or very small values or if the
sample mean of the values is far away from 0 (on the scale of the values),
then it can be more efficient to standardize the outputs <span class="math inline">\(y_n\)</span> and
predictors <span class="math inline">\(x_n\)</span>. The data are first centered by subtracting the
sample mean, and then scaled by dividing by the sample deviation.
Thus a data point <span class="math inline">\(u\)</span> is standardized with respect to
a vector <span class="math inline">\(y\)</span> by the function <span class="math inline">\(\mbox{z}_y\)</span>, defined by
<span class="math display">\[
\mbox{z}_y(u) = \frac{u - \bar{y}}{\mbox{sd}(y)}
\]</span>
where the sample mean of <span class="math inline">\(y\)</span> is
<span class="math display">\[
\bar{y}
= \frac{1}{N} \sum_{n=1}^N y_n,
\]</span>
and the sample standard deviation of <span class="math inline">\(y\)</span> is
<span class="math display">\[
\mbox{sd}(y)
= \left(
\frac{1}{N} \sum_{n=1}^N (y_n - \bar{y})^2
\right)^{1/2}.
\]</span>
The inverse transform is
defined by reversing the two normalization steps, first rescaling by
the same deviation and relocating by the sample mean,
<span class="math display">\[
\mbox{z}_y^{-1}(v) = \mbox{sd}(y) v + \bar{y}.
\]</span></p>
<p>To standardize a regression problem, the predictors and outcomes are
standardized. This changes the scale of the variables, and hence
changes the scale of the priors. Consider the following initial
model.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
  vector[N] x;
}
parameters {
  real alpha;
  real beta;
  real&lt;lower=0&gt; sigma;
}
model {
  // priors
  alpha ~ normal(0, 10);
  beta ~ normal(0, 10);
  sigma ~ cauchy(0, 5);
  // likelihood
  for (n in 1:N)
    y[n] ~ normal(alpha + beta * x[n], sigma);
}</code></pre>
<p>The data block for the standardized model is identical. The
standardized predictors and outputs are defined in the transformed
data block.</p>
<pre><code>data {
  int&lt;lower=0&gt; N;
  vector[N] y;
  vector[N] x;
}
transformed data {
  vector[N] x_std;
  vector[N] y_std;
  x_std = (x - mean(x)) / sd(x);
  y_std = (y - mean(y)) / sd(y);
}
parameters {
  real alpha_std;
  real beta_std;
  real&lt;lower=0&gt; sigma_std;
}
model {
  alpha_std ~ normal(0, 10);
  beta_std ~ normal(0, 10);
  sigma_std ~ cauchy(0, 5);
  for (n in 1:N)
    y_std[n] ~ normal(alpha_std + beta_std * x_std[n],
                      sigma_std);
}</code></pre>
<p>The parameters are renamed to indicate that they aren’t the
``natural&quot; parameters, but the model is otherwise identical. In
particular, the fairly diffuse priors on the coefficients and error
scale are the same. These could have been transformed as well, but
here they are left as is, because the scales make sense as
diffuse priors for standardized data; the priors could be made more
informative. For instance, because the outputs <span class="math inline">\(y\)</span> have been
standardized, the error <span class="math inline">\(\sigma\)</span> should not be greater than 1, because
that’s the scale of the noise for predictors <span class="math inline">\(\alpha = \beta = 0\)</span>.</p>
<p>The original regression
<span class="math display">\[
y_n
= \alpha + \beta x_n + \epsilon_n
\]</span>
has been transformed to a regression on the standardized variables,
<span class="math display">\[
\mbox{z}_y(y_n)
= \alpha&#39;
+ \beta&#39; \mbox{z}_x(x_n)
+ \epsilon&#39;_n.
\]</span>
The original parameters can be recovered with a little algebra,</p>
<p><span class="math display">\[
\begin{array}{rcl}
y_n
&amp; = &amp; \mbox{z}_y^{-1}(\mbox{z}_y(y_n))
\\[4pt]
&amp; = &amp;
\mbox{z}_y^{-1}
\left(
\alpha&#39;
+ \beta&#39; \mbox{z}_x(x_n)
+ \epsilon_n&#39;
\right)
\\[4pt]
&amp; = &amp;
\mbox{z}_y^{-1}
\left(
\alpha&#39;
+ \beta&#39;
    \left(
      \frac{x_n - \bar{x}}{\mbox{sd}(x)}
    \right)
+ \epsilon_n&#39;
\right)
\\[4pt]
&amp; = &amp;
\mbox{sd}(y)
\left(
\alpha&#39;
+ \beta&#39;
    \left(
      \frac{x_n - \bar{x}}{\mbox{sd}(x)}
    \right)
+ \epsilon_n&#39;
\right)
+ \bar{y}
\\[4pt]
&amp; = &amp;
\left(
  \mbox{sd}(y)
      \left(
          \alpha&#39;
          - \beta&#39; \frac{\bar{x}}{\mbox{sd}(x)}
      \right)
  + \bar{y}
\right)
+ \left(
      \beta&#39; \frac{\mbox{sd}(y)}{\mbox{sd}(x)}
  \right) x_n
+ \mbox{sd}(y) \epsilon&#39;_n,
\end{array}
\]</span></p>
<p>from which the original scale parameter values can be read off,
<span class="math display">\[
\alpha
=
\mbox{sd}(y)
      \left(
          \alpha&#39;
          - \beta&#39; \frac{\bar{x}}{\mbox{sd}(x)}
      \right)
  + \bar{y};
\ \ \ \ \
\beta = \beta&#39; \frac{\mbox{sd}(y)}{\mbox{sd}(x)};
\ \ \ \ \
\sigma = \mbox{sd}(y) \sigma&#39;.
\]</span></p>
<p>These recovered parameter values on the original scales can be
calculated within Stan using a generated quantities block following
the model block,</p>
<pre><code>generated quantities {
  real alpha;
  real beta;
  real&lt;lower=0&gt; sigma;
  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x))
           + mean(y);
  beta = beta_std * sd(y) / sd(x);
  sigma = sd(y) * sigma_std;
}</code></pre>
<p>It is inefficient to compute all of the means and standard
deviations every iteration; for more efficiency, these can be
calculated once and stored as transformed data. Furthermore, the
model sampling statement can be easily vectorized, for instance, in
the transformed model, to</p>
<pre><code>    y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);</code></pre>
<div id="standard-normal-distribution" class="section level3 unnumbered">
<h3>Standard Normal Distribution</h3>
<p>For many applications on the standard scale, normal distributions with
location zero and scale one will be used. In these cases, it is more
efficient to use</p>
<pre><code>y ~ std_normal();</code></pre>
<p>than to use</p>
<pre><code>y ~ normal(0, 1);</code></pre>
<p>because the subtraction of the location and division by the scale
cancel, as does subtracting the log of the scale.</p>
</div>
</div>
<div id="using-map-reduce" class="section level2">
<h2><span class="header-section-number">21.13</span> Using Map-Reduce</h2>
<p>The map-reduce operation, even without multi-core MPI support, can be
used to make programs more scalable and also more efficient. See the
<a href="map-reduce-chapter.html#map-reduce.chapter">map-reduce chapter</a> for more information on
implementing map-reduce operations.</p>
<p>Map-reduce allows greater scalability because only the Jacobian of the
mapped function for each shard is stored. The Jacobian consists of
all of the derivatives of the outputs with respect to the parameters.
During execution, the derivatives of the shard are evaluated using
nested automatic differentiation. As often happens with modern CPUs,
reduced memory overhead leads to increased memory locality and faster
execution. The Jacobians are all computed with local memory and their
outputs stored contiguously in memory.</p>

</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-papa-et-al:2007">
<p>Papaspiliopoulos, Omiros, Gareth O. Roberts, and Martin Sköld. 2007. “A General Framework for the Parametrization of Hierarchical Models.” <em>Statistical Science</em> 22 (1): 59–73.</p>
</div>
<div id="ref-Neal:2003">
<p>Neal, Radford M. 2003. “Slice Sampling.” <em>Annals of Statistics</em> 31 (3): 705–67.</p>
</div>
<div id="ref-Betancourt-Girolami:2013">
<p>Betancourt, Michael, and Mark Girolami. 2013. “Hamiltonian Monte Carlo for Hierarchical Models.” <em>arXiv</em> 1312.0906. <a href="http://arxiv.org/abs/1312.0906" class="uri">http://arxiv.org/abs/1312.0906</a>.</p>
</div>
<div id="ref-ZyczkowskiSommers:2001">
<p>Zyczkowski, K., and H.J. Sommers. 2001. “Induced Measures in the Space of Mixed Quantum States.” <em>Journal of Physics A: Mathematical and General</em> 34 (35). IOP Publishing: 7111.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="38">
<li id="fn38"><p>This parameterization came to be known on our mailing lists as the “Matt trick” after Matt Hoffman, who independently came up with it while fitting hierarchical models in Stan.<a href="optimization-chapter.html#fnref38" class="footnote-back">↩</a></p></li>
<li id="fn39"><p>Riemannian Manifold Hamiltonian Monte Carlo (RMHMC) overcomes this difficulty by simulating the Hamiltonian dynamics in a space with a position-dependent metric; see <span class="citation">Girolami and Calderhead (<a href="#ref-GirolamiCalderhead:2011">2011</a>)</span> and <span class="citation">Betancourt (<a href="#ref-Betancourt:2012">2012</a>)</span>.<a href="optimization-chapter.html#fnref39" class="footnote-back">↩</a></p></li>
<li id="fn40"><p>Stan uses its own arena-based allocation, so allocation and deallocation are faster than with a raw call to <code>new</code>.<a href="optimization-chapter.html#fnref40" class="footnote-back">↩</a></p></li>
<li id="fn41"><p>Future versions of Stan may remove this inefficiency by more fully exploiting expression templates inside the Eigen C++ matrix library. This will require enhancing Eigen to deal with mixed-type arguments, such as the type <code>double</code> used for constants and the algorithmic differentiation type <code>stan::math::var</code> used for variables.<a href="optimization-chapter.html#fnref41" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="change-of-variables-chapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="map-reduce-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
